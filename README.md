# ğŸ¤– Hands-On Machine Learning Practice

*A collection of practical notebooks, exercises, and projects from my journey through*  
**ğŸ“˜ â€œHands-On Machine Learning with Scikit-Learn, Keras & TensorFlowâ€ (AurÃ©lien GÃ©ron)**

---

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)]()
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Jupyter](https://img.shields.io/badge/Notebook-Jupyter-orange.svg)]()
[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-ML-blue.svg)]()
[![TensorFlow](https://img.shields.io/badge/TensorFlow-Deep%20Learning-orange.svg)]()

---

### ğŸ§­ Overview
This repository documents my **hands-on learning journey** as I work through *Hands-On Machine Learning* by AurÃ©lien GÃ©ron.  
Each chapter folder includes:
- Annotated Jupyter notebooks  
- My own notes, experiments, and reflections  
- Small standalone projects inspired by the chapter content  

> ğŸš€ The goal is to learn deeply by building, testing, and explaining everything from scratch.

---

## ğŸ“š Chapters & Notebooks

| Chapter | Title | Description | Resources |
|:--------:|--------|--------------|----------------|
| 1 | The Machine Learning Landscape | Overview of ML types, challenges, and workflow foundations. | [ğŸ““ Notebook](./notebooks/chapter_01_the_machine_learning_landscape/chapter_01_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_01_the_machine_learning_landscape/README.md) |
| 2 | End-to-End Machine Learning Project ğŸ  | Full ML workflow on housing data â€” data cleaning, feature engineering, model building. | ğŸŒ&nbsp;[Project&nbsp;Repo](https://github.com/umbutun/real-estate-price-predictor)&nbsp;â€¢&nbsp;<br>[ğŸ—’ï¸&nbsp;ReadMe](./notebooks/chapter_02_end_to_end_project/README.md) |(./notebooks/chapter_02_end_to_end_project/README.md) |(./notebooks/chapter_02_end_to_end_project/README.md) |
| 3 | Classification | Intro to classification using MNIST dataset. Logistic regression, precision/recall, ROC, and multiclass methods. | [ğŸ““ Notebook](./notebooks/chapter_03_classification/chapter_03_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_03_classification/README.md) |
| 4 | Training Models | Linear regression, gradient descent, regularization, and early stopping. | [ğŸ““ Notebook](./notebooks/chapter_04_training_models/chapter_04_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_04_training_models/README.md) |
| 5 | Support Vector Machines (SVMs) | Linear and nonlinear classification/regression, kernels, margins, and C parameter. | [ğŸ““ Notebook](./notebooks/chapter_05_support_vector_machines/chapter_05_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_05_support_vector_machines/README.md) |
| 6 | Decision Trees | Tree structure, impurity measures, and visualization techniques. | [ğŸ““ Notebook](./notebooks/chapter_06_decision_trees/chapter_06_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_06_decision_trees/README.md) |
| 7 | Ensemble Learning & Random Forests | Bagging, boosting, stacking, and Random Forests. | [ğŸ““ Notebook](./notebooks/chapter_07_ensemble_learning/chapter_07_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_07_ensemble_learning/README.md) |
| 8 | Dimensionality Reduction | PCA, Kernel PCA, and LLE for reducing data complexity. | [ğŸ““ Notebook](./notebooks/chapter_08_dimensionality_reduction/chapter_08_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_08_dimensionality_reduction/README.md) |
| 9 | Unsupervised Learning Techniques | Clustering (K-Means, DBSCAN, GMM) and anomaly detection. | [ğŸ““ Notebook](./notebooks/chapter_09_unsupervised_learning/chapter_09_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_09_unsupervised_learning/README.md) |
| 10 | Introduction to Artificial Neural Networks | Basics of ANNs, perceptrons, multilayer perceptrons, and backpropagation. | [ğŸ““ Notebook](./notebooks/chapter_10_introduction_to_anns/chapter_10_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_10_introduction_to_anns/README.md) |
| 11 | Training Deep Neural Networks | Optimization, batch normalization, dropout, and adaptive optimizers. | [ğŸ““ Notebook](./notebooks/chapter_11_training_deep_neural_networks/chapter_11_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_11_training_deep_neural_networks/README.md) |
| 12 | Custom Models and Training with TensorFlow | Custom training loops and low-level APIs. | [ğŸ““ Notebook](./notebooks/chapter_12_custom_models_tensorflow/chapter_12_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_12_custom_models_tensorflow/README.md) |
| 13 | Data Preprocessing with TensorFlow | Efficient data ingestion using tf.data API. | [ğŸ““ Notebook](./notebooks/chapter_13_data_preprocessing_tensorflow/chapter_13_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_13_data_preprocessing_tensorflow/README.md) |
| 14 | Deep Computer Vision (CNNs) | Convolutions, pooling, and CNN architectures for image data. | [ğŸ““ Notebook](./notebooks/chapter_14_convolutional_neural_networks/chapter_14_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_14_convolutional_neural_networks/README.md) |
| 15 | Processing Sequences (RNNs & CNNs) | RNNs, LSTMs, GRUs, and 1D convolutions for sequence data. | [ğŸ““ Notebook](./notebooks/chapter_15_recurrent_neural_networks/chapter_15_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_15_recurrent_neural_networks/README.md) |
| 16 | NLP with RNNs and Attention | Attention mechanisms, encoder-decoder models, and sequence-to-sequence learning. | [ğŸ““ Notebook](./notebooks/chapter_16_nlp_attention/chapter_16_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_16_nlp_attention/README.md) |
| 17 | Representation Learning & Autoencoders | Autoencoders and generative representations. | [ğŸ““ Notebook](./notebooks/chapter_17_autoencoders/chapter_17_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_17_autoencoders/README.md) |
| 18 | Generative Adversarial Networks (GANs) | Adversarial training and creative image generation. | [ğŸ““ Notebook](./notebooks/chapter_18_gans/chapter_18_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_18_gans/README.md) |
| 19 | Reinforcement Learning | Agents, rewards, environments, and policy learning. | [ğŸ““ Notebook](./notebooks/chapter_19_reinforcement_learning/chapter_19_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_19_reinforcement_learning/README.md) |
| 20 | Deploying TensorFlow Models | Model serving, TensorFlow Lite, and deployment workflows. | [ğŸ““ Notebook](./notebooks/chapter_20_deployment/chapter_20_notebook.ipynb) â€¢ [ğŸ—’ï¸ ReadMe](./notebooks/chapter_20_deployment/README.md) |

---

### ğŸ§  Key Learning Goals
- Build, train, and evaluate ML models with Scikit-Learn  
- Design reproducible ML workflows  
- Understand feature engineering and data preprocessing  
- Explore deep learning and neural networks with TensorFlow/Keras  
- Deploy and scale models for real-world use  

---

### âš™ï¸ Setup & Usage

```bash
# Clone the repository
git clone https://github.com/umbutun/hands-on-machine-learning-practice.git
cd hands-on-machine-learning-practice

# Create environment (if using Conda)
conda env create -f environment.yml
conda activate hands-on-ml

# Or install dependencies via pip
pip install -r requirements.txt

# Launch Jupyter
jupyter notebook
```
---
### ğŸ§© Dependencies
	â€¢	Python 3.10+
	â€¢	Scikit-Learn
	â€¢	NumPy, Pandas, Matplotlib, Seaborn
	â€¢	TensorFlow / Keras
	â€¢	JupyterLab

(See requirements.txt for full list.)

---

### ğŸ† Highlights
	â€¢	âœ… Modular structure by chapter
	â€¢	âœ… Real projects linked separately (e.g. Real Estate Price Predictorï¿¼)
	â€¢	âœ… Reproducible environments
	â€¢	âœ… Learning-first, project-based approach

---

### ğŸ§‘â€ğŸ’» Author

â€¢ Umut BÃ¼tÃ¼n
ğŸ“ Machine Learning Enthusiast | Python Developer
ğŸ”— [GitHub Profile](https://github.com/umbutun)ï¿¼

---

### ğŸ“œ License

This repository is licensed under the MIT Licenseï¿¼.

---

> _â€œLearning by doing â€” one model, one notebook at a time.â€_
