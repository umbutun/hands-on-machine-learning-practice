# ğŸ° Chapter 5 â€” Support Vector Machines


### â…€ Overview
This notebook introduces **Support Vector Machines (SVMs)**, a family of robust margin-based algorithms for classification and regression.  
Youâ€™ll learn how kernel methods project data into higher dimensions to make it linearly separable.

---

### â‡ Key Topics
- Hard-margin vs soft-margin SVM  
- Polynomial and RBF kernels  
- Kernel trick and feature space intuition  
- Hyperparameters `C` and `gamma`  
- SVM Regression (SVR)  

---

### ğŸ•¯ï¸ Notebook Highlights
- Visualized decision boundaries under different kernels  
- Compared SVC and SVR results  
- Explored how margin width affects generalization  
- Performed grid-search hyperparameter tuning  

---

### ğŸ““ Notebook
[Open Notebook](./chapter_05_notebook.ipynb)

---

### ğŸ“Š Preview
<p align="center">
  <img src="../../assets/charts/chapter_05_svm_decision_boundaries.png" width="65%" alt="SVM Decision Boundaries"/>
</p>

*Figure 1 â€” SVM classifier with non-linear decision boundaries.*

---

### âš™ï¸ Dependencies
- Python â‰¥ 3.10  
- NumPy â€¢ Pandas â€¢ Matplotlib â€¢ Scikit-Learn  
- Jupyter Notebook  

---

### â›“ Resources
- [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
- [Scikit-Learn SVM Guide](https://scikit-learn.org/stable/modules/svm.html)  
- [Kernel Tricks Explained â€“ Medium](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-and-implementation-c-324befe0a0d3)  

---

> _â€œSupport Vectors define the boundary between order and chaos.â€_ â€” Machine Learning Proverb
