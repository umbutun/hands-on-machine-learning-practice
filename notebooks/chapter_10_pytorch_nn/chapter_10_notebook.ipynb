{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbutun/hands-on-machine-learning-practice/blob/main/notebooks/chapter_10_pytorch_nn/chapter_10_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "002YVyk7L5DR"
      },
      "source": [
        "**Chapter 10 – Building Neural Networks with PyTorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2myuwJ5bL5DT"
      },
      "source": [
        "_This notebook contains all the sample code and solutions to the exercises in chapter 10._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhxsEWVRL5DT"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvQOikaQL5DT"
      },
      "source": [
        "This project requires Python 3.10 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cNPUDTOvL5DT"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLwoLxZuL5DU"
      },
      "source": [
        "It also requires Scikit-Learn ≥ 1.6.1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2e1LIhgcL5DU"
      },
      "outputs": [],
      "source": [
        "from packaging.version import Version\n",
        "import sklearn\n",
        "\n",
        "assert Version(sklearn.__version__) >= Version(\"1.6.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub4Akov_L5DU"
      },
      "source": [
        "Are we using Colab or Kaggle?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gdewA7GpL5DU"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrNr5Lz3L5DU"
      },
      "source": [
        "If using Colab, a couple libraries are not pre-installed so we must install them manually:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_xJocwuBL5DU",
        "outputId": "db483f48-a22b-4bb0-fafd-55a441b0d591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/404.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m983.0/983.2 kB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "if IS_COLAB:\n",
        "    %pip install -q optuna torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_38x2TbL5DU"
      },
      "source": [
        "And of course we need PyTorch, specifically PyTorch ≥ 2.6.0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fnusV0BOL5DU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "assert Version(torch.__version__) >= Version(\"2.6.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoCEsLKVL5DU"
      },
      "source": [
        "As we did in earlier chapters, let's define the default font sizes to make the figures prettier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d74oI1_vL5DU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's  define the `save_fig()` function which is used through this notebook to save the figures in high-res for the book:"
      ],
      "metadata": {
        "id": "DXqxP7hEMci4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "IMAGES_PATH = Path(\"/content/drive/My Drive/Colab Notebooks/hands-on-ml/ch10-images\")\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfAMaAHSMbPk",
        "outputId": "ef45d6e0-3c97-4b62-87a1-862a92b65d67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5hRw0srL5DU"
      },
      "source": [
        "# PyTorch Fundamentals\n",
        "## PyTorch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Cd1fLp8aL5DV",
        "outputId": "bbc2ee63-66d3-4260-b23d-0be5f4803f12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 4., 7.],\n",
              "        [2., 3., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "X = torch.tensor([[1.0, 4.0, 7.0], [2.0, 3.0, 6.0]])\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C7rHVUQrL5DV",
        "outputId": "63b87f7a-6ba1-4c20-e364-8efd164720cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nCv9D-SpL5DV",
        "outputId": "c2f39978-cce9-4443-b0f6-2321b68585a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AsZrCTD8L5DV",
        "outputId": "a96b5190-9c9f-41b1-b1ff-426d500ae4c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X[0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-7ZoL7tOL5DV",
        "outputId": "08c956e4-3a41-40ee-b9c0-783757fc7a3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ED4AdtY5L5DV",
        "outputId": "de5d9fc6-092e-4da0-c4bb-fee5d4cba842",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20., 50., 80.],\n",
              "        [30., 40., 70.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "10 * (X + 1.0)  # item-wise addition and multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aFFmRYK5L5DV",
        "outputId": "760429c2-94e6-4596-f077-407e3eba0fa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   2.7183,   54.5981, 1096.6332],\n",
              "        [   7.3891,   20.0855,  403.4288]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X.exp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-D1wtvwcL5DV",
        "outputId": "eb9e750f-47ef-48ac-c6a4-6a54561a0414",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8333)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jgYYQ2sIL5DV",
        "outputId": "1043de37-8762-424a-cd7d-25301c5b3d03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([2., 4., 7.]),\n",
              "indices=tensor([1, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X.max(dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "urq84f7iL5DV",
        "outputId": "8fe852ce-9377-49cb-8998-e7b4bf8b17cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[66., 56.],\n",
              "        [56., 49.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X @ X.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AhUOFvfjL5DV",
        "outputId": "0be09a2a-ae71-4ae5-da6c-9a6431e7bf46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 4., 7.],\n",
              "       [2., 3., 6.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "49vdjz0xL5DV",
        "outputId": "ec40b670-a5d7-4e98-e7bb-44a017aecfc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 4., 7.],\n",
              "        [2., 3., 6.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vOFNL9aSL5DV",
        "outputId": "c3ccd904-0101-4c59-979f-9a77cd15de0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 4., 7.],\n",
              "        [2., 3., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]), dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qGl8hPquL5DV",
        "outputId": "fb121c9c-a91c-42e8-a9d6-144d303f7be0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 4., 7.],\n",
              "        [2., 3., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "torch.FloatTensor(np.array([[1., 4., 7.], [2., 3., 6]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "E-kdcbazL5DV",
        "outputId": "add235f0-960a-45df-fa26-313cd6dc38a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., 88.,  7.],\n",
              "        [ 2.,  3.,  6.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# extra code: demonstrate torch.from_numpy()\n",
        "X2_np = np.array([[1., 4., 7.], [2., 3., 6]])\n",
        "X2 = torch.from_numpy(X2_np)  # X2_np and X2 share the same data in memory\n",
        "X2_np[0, 1] = 88\n",
        "X2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gcE5WOZSL5DV",
        "outputId": "65d84901-1b15-4ac2-e00d-baf40116ebc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1., -99.,   7.],\n",
              "        [  2., -99.,   6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "X[:, 1] = -99\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In-Place Operation (easily spot with _ suffix):"
      ],
      "metadata": {
        "id": "5IH0wBKAAdYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LOAdLHYSL5DV",
        "outputId": "d2cba234-e279-4084-a620-5ef95a7c452d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 7.],\n",
              "        [2., 0., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X.relu_()\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out-Of-Place Operation (no suffix):"
      ],
      "metadata": {
        "id": "kahW1oQ-Aizd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = X.relu()\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFSvE-P7AifG",
        "outputId": "76febbd1-7898-4b9b-f04c-1bfe264f6b9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 7.],\n",
              "        [2., 0., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUlQVQUEL5DV"
      },
      "source": [
        "PyTorch tensors really resemble NumPy arrays. In fact, they have over 200 common functions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mmA0ADsHL5DV",
        "outputId": "99acb5ef-75fb-4e01-e72d-82553892d8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'__getattr__, abs, absolute, acos, acosh, add, all, allclose, amax, amin, angle, any, arange, arccos, arccosh, arcsin, arcsinh, arctan, arctan2, arctanh, argmax, argmin, argsort, argwhere, asarray, asin, asinh, atan, atan2, atanh, atleast_1d, atleast_2d, atleast_3d, bincount, bitwise_and, bitwise_left_shift, bitwise_not, bitwise_or, bitwise_right_shift, bitwise_xor, broadcast_shapes, broadcast_to, can_cast, ceil, clip, column_stack, concat, concatenate, conj, copysign, corrcoef, cos, cosh, count_nonzero, cov, cross, cumprod, cumsum, deg2rad, diag, diagflat, diagonal, diff, divide, dot, dsplit, dstack, dtype, einsum, empty, empty_like, equal, exp, exp2, expm1, eye, finfo, fix, flip, fliplr, flipud, float_power, floor, floor_divide, fmax, fmin, fmod, frexp, from_dlpack, frombuffer, full, full_like, gcd, gradient, greater, greater_equal, heaviside, histogram, histogramdd, hsplit, hstack, hypot, i0, iinfo, imag, inner, isclose, isfinite, isin, isinf, isnan, isneginf, isposinf, isreal, kron, lcm, ldexp, less, less_equal, linspace, load, log, log10, log1p, log2, logaddexp, logaddexp2, logical_and, logical_not, logical_or, logical_xor, logspace, matmul, max, maximum, mean, median, meshgrid, min, minimum, moveaxis, multiply, nan_to_num, nanmean, nanmedian, nanquantile, nansum, negative, nextafter, nonzero, not_equal, ones, ones_like, outer, positive, pow, prod, promote_types, put, quantile, rad2deg, ravel, real, reciprocal, remainder, reshape, result_type, roll, rot90, round, row_stack, save, searchsorted, select, set_printoptions, sign, signbit, sin, sinc, sinh, sort, split, sqrt, square, squeeze, stack, std, subtract, sum, swapaxes, take, tan, tanh, tensordot, tile, trace, transpose, trapezoid, trapz, tril, tril_indices, triu, triu_indices, true_divide, trunc, typename, unique, unravel_index, vander, var, vdot, vsplit, vstack, where, zeros, zeros_like'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# extra code: list functions that appear both in NumPy and PyTorch\n",
        "functions = lambda mod: set(f for f in dir(mod) if callable(getattr(mod, f)))\n",
        "\", \".join(sorted(functions(torch) & functions(np)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_NKZod1L5DV"
      },
      "source": [
        "## Hardware Acceleration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "x1-9hPGXL5DV",
        "outputId": "f0c0ceae-364e-48e3-fad1-eb568491386b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WoNW-YMrL5DW",
        "outputId": "37441cf7-72cf-4902-9b6c-53b5d1e2c26d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
        "M = M.to(device)\n",
        "M.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yRIRGWSXL5Dc"
      },
      "outputs": [],
      "source": [
        "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]], device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "AZdK2KhlL5Dc",
        "outputId": "22633394-07e3-4066-9e66-31b183aa7748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14., 32.],\n",
              "        [32., 77.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "R = M @ M.T  # run some operations on the GPU\n",
        "R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hzFJXMrhL5Dc",
        "outputId": "44f873e5-99ab-42ea-bcc7-33125bd3850e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16.2 ms ± 3.33 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "559 µs ± 15.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "M = torch.rand((1000, 1000))  # on the CPU\n",
        "M @ M.T  # warmup\n",
        "%timeit M @ M.T\n",
        "\n",
        "M = M.to(device)\n",
        "M @ M.T  # warmup\n",
        "%timeit M @ M.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJnn6GjoL5Dc"
      },
      "source": [
        "## Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaxgLuEQL5Dc"
      },
      "source": [
        "Consider a simple function, $f(x) = x^2$.\n",
        "Calculus tells us that the derivative of this function is $f'(x)=2x$. Let's evaluate $f(5)$ and the derivative $f'(5)$ using autograd. We expect to find $f(5)=5^2=25$ and $f'(5)=2*5=10$. Let's see!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eIownRLzL5Dc",
        "outputId": "724a095c-33a4-4261-b359-ae47a69d0803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(25., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "f = x ** 2\n",
        "f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7Am2NuvhL5Dc",
        "outputId": "2b06958a-d29c-4508-c3a4-795f829ea9dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "f.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "oN0GAwN9L5Dc"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "with torch.no_grad():\n",
        "    x -= learning_rate * x.grad  # gradient descent step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-MVEUWLFL5Dc",
        "outputId": "6cadeec0-1741-447c-9d00-b77dbbc62b2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybse5VxdL5Dc"
      },
      "source": [
        "Alternatively, we could have used this code for the gradient descent step (but using `no_grad()` is more common for this):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pwppcmdrL5Dc"
      },
      "outputs": [],
      "source": [
        "x_detached = x.detach()\n",
        "x_detached -= learning_rate * x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cMdbDFp-L5Dc",
        "outputId": "370a66a9-da8e-45d0-f02f-7d31db2e510f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "x.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm_24e3xL5Dc"
      },
      "source": [
        "Let's put everything together to get our training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8uE29gLkL5Dc"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "for iteration in range(100):\n",
        "    f = x ** 2  # forward pass\n",
        "    f.backward()  # backward pass\n",
        "    with torch.no_grad():\n",
        "        x -= learning_rate * x.grad  # gradient descent step\n",
        "    x.grad.zero_()  # reset the gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amfNHdx-L5Dc"
      },
      "source": [
        "The variable `x` gets pushed towards 0, since that's the value that minimizes $f(x) = x^2$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dHmv1FzmL5Dc",
        "outputId": "a346f640-b208-4d49-93a1-7b4a7877b924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0185e-09, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgy6UB-nL5Dc"
      },
      "source": [
        "# Implementing Linear Regression\n",
        "## Linear Regression Using Tensors & Autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "lRVhr_lhL5Dc"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37ea3e08"
      },
      "source": [
        "Let's say you have a tensor `X` like this, where each row represents a sample and each column represents a feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b1e13ed",
        "outputId": "fb15af9f-4514-4d6d-e9ab-e7c644811dd9"
      },
      "source": [
        "X_example = torch.tensor([[10., 20., 30.],    # Sample 1\n",
        "                            [1.,  2.,  3.],     # Sample 2\n",
        "                            [5.,  15., 25.]])  # Sample 3\n",
        "\n",
        "print(\"Original tensor X_example:\")\n",
        "print(X_example)\n",
        "print(\"Shape of X_example:\", X_example.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor X_example:\n",
            "tensor([[10., 20., 30.],\n",
            "        [ 1.,  2.,  3.],\n",
            "        [ 5., 15., 25.]])\n",
            "Shape of X_example: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4360b6a"
      },
      "source": [
        "When you calculate `X_example.mean(dim=0)`, you are telling PyTorch to compute the average for each column (feature) independently, considering all the rows (samples). This means:\n",
        "\n",
        "*   **For the first column:** (10 + 1 + 5) / 3 = 16 / 3 = 5.33\n",
        "*   **For the second column:** (20 + 2 + 15) / 3 = 37 / 3 = 12.33\n",
        "*   **For the third column:** (30 + 3 + 25) / 3 = 58 / 3 = 19.33\n",
        "\n",
        "The `keepdims=True` argument ensures that the output tensor retains the original number of dimensions, making it easy to broadcast during operations like `(X_train - means) / stds`. Without `keepdims=True`, the result would be a 1D tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33911080",
        "outputId": "9b3b47ae-1946-43e5-da00-2ba823e53541"
      },
      "source": [
        "means_example = X_example.mean(dim=0, keepdims=True)\n",
        "\n",
        "print(\"Mean across rows (dim=0) with keepdims=True:\")\n",
        "print(means_example)\n",
        "print(\"Shape of means_example:\", means_example.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean across rows (dim=0) with keepdims=True:\n",
            "tensor([[ 5.3333, 12.3333, 19.3333]])\n",
            "Shape of means_example: torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0804599"
      },
      "source": [
        "For a 3-dimensional tensor, often represented as `(dim0, dim1, dim2)` or `(batches, rows, columns)` or `(batches, sequence_length, features)`:\n",
        "\n",
        "*   **`dim=0`**: When you calculate `mean(dim=0)`, you are computing the average across the **first dimension**. If you imagine a stack of 2D matrices, `dim=0` averages values at the same `(row, column)` position across all matrices in the stack.\n",
        "    *   *Example Interpretation*: If your tensor is `(batch_size, height, width)`, then `mean(dim=0)` will give you a single `(height, width)` tensor where each element is the average of that `(height, width)` position across all samples in the batch.\n",
        "\n",
        "*   **`dim=1`**: Calculating `mean(dim=1)` means you're averaging across the **second dimension**. For each `(dim0, dim2)` slice, you're averaging the elements along `dim1`.\n",
        "    *   *Example Interpretation*: If your tensor is `(batch_size, height, width)`, then `mean(dim=1)` will give you a `(batch_size, width)` tensor where each element is the average of that column across all rows for each batch.\n",
        "\n",
        "*   **`dim=2`**: When you compute `mean(dim=2)`, you're averaging across the **third dimension**. For each `(dim0, dim1)` slice, you're averaging the elements along `dim2`.\n",
        "    *   *Example Interpretation*: If your tensor is `(batch_size, height, width)`, then `mean(dim=2)` will give you a `(batch_size, height)` tensor where each element is the average of that row across all columns for each batch.\n",
        "\n",
        "Using `keepdims=True` is just as important here as in the 2D case, as it preserves the number of dimensions, making the output compatible for broadcasting with the original tensor (or other tensors of appropriate shape)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eef06be9",
        "outputId": "6d915fa4-a5cd-4579-c78f-3ab5d1ed1f35"
      },
      "source": [
        "# Let's create a 3D tensor, imagine it as 2 batches of 3x4 matrices\n",
        "X_3d = torch.arange(24).reshape(2, 3, 4).float()\n",
        "print(\"Original 3D tensor X_3d (shape: \", X_3d.shape, \")\\n\", X_3d)\n",
        "\n",
        "print(\"\\n--- mean(dim=0) ---\")\n",
        "mean_dim0 = X_3d.mean(dim=0)\n",
        "print(\"Mean along dim=0 (averaging across batches) (shape: \", mean_dim0.shape, \")\\n\", mean_dim0)\n",
        "\n",
        "print(\"\\n--- mean(dim=1) ---\")\n",
        "mean_dim1 = X_3d.mean(dim=1)\n",
        "print(\"Mean along dim=1 (averaging across rows for each batch) (shape: \", mean_dim1.shape, \")\\n\", mean_dim1)\n",
        "\n",
        "print(\"\\n--- mean(dim=2) ---\")\n",
        "mean_dim2 = X_3d.mean(dim=2)\n",
        "print(\"Mean along dim=2 (averaging across columns for each row and batch) (shape: \", mean_dim2.shape, \")\\n\", mean_dim2)\n",
        "\n",
        "print(\"\\n--- mean(dim=0, keepdims=True) ---\")\n",
        "mean_dim0_keepdims = X_3d.mean(dim=0, keepdims=True)\n",
        "print(\"Mean along dim=0 with keepdims=True (shape: \", mean_dim0_keepdims.shape, \")\\n\", mean_dim0_keepdims)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original 3D tensor X_3d (shape:  torch.Size([2, 3, 4]) )\n",
            " tensor([[[ 0.,  1.,  2.,  3.],\n",
            "         [ 4.,  5.,  6.,  7.],\n",
            "         [ 8.,  9., 10., 11.]],\n",
            "\n",
            "        [[12., 13., 14., 15.],\n",
            "         [16., 17., 18., 19.],\n",
            "         [20., 21., 22., 23.]]])\n",
            "\n",
            "--- mean(dim=0) ---\n",
            "Mean along dim=0 (averaging across batches) (shape:  torch.Size([3, 4]) )\n",
            " tensor([[ 6.,  7.,  8.,  9.],\n",
            "        [10., 11., 12., 13.],\n",
            "        [14., 15., 16., 17.]])\n",
            "\n",
            "--- mean(dim=1) ---\n",
            "Mean along dim=1 (averaging across rows for each batch) (shape:  torch.Size([2, 4]) )\n",
            " tensor([[ 4.,  5.,  6.,  7.],\n",
            "        [16., 17., 18., 19.]])\n",
            "\n",
            "--- mean(dim=2) ---\n",
            "Mean along dim=2 (averaging across columns for each row and batch) (shape:  torch.Size([2, 3]) )\n",
            " tensor([[ 1.5000,  5.5000,  9.5000],\n",
            "        [13.5000, 17.5000, 21.5000]])\n",
            "\n",
            "--- mean(dim=0, keepdims=True) ---\n",
            "Mean along dim=0 with keepdims=True (shape:  torch.Size([1, 3, 4]) )\n",
            " tensor([[[ 6.,  7.,  8.,  9.],\n",
            "         [10., 11., 12., 13.],\n",
            "         [14., 15., 16., 17.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a5d8425"
      },
      "source": [
        "The next cell prepares your `X_train`, `X_valid`, and `X_test` datasets for use with PyTorch by converting them into `torch.FloatTensor` tensors. This is necessary because PyTorch operations work directly with its own tensor type.\n",
        "\n",
        "After conversion, the code performs **standardization** (also known as Z-score normalization) on the features. This is a common preprocessing step in machine learning to scale numerical features so they have a mean of 0 and a standard deviation of 1. Standardization helps gradient-based optimization algorithms converge faster and can improve model performance. Here's how it works:\n",
        "\n",
        "1.  **`X_train = torch.FloatTensor(X_train)`**:\n",
        "    *   Converts the NumPy array `X_train` into a PyTorch `FloatTensor`. This is done for `X_valid` and `X_test` as well.\n",
        "\n",
        "2.  **`means = X_train.mean(dim=0, keepdims=True)`**:\n",
        "    *   Calculates the mean of each feature (column) in the `X_train` dataset. `dim=0` means the mean is computed across rows, and `keepdims=True` ensures the resulting `means` tensor retains its dimensionality, making it easy to broadcast during subtraction.\n",
        "\n",
        "3.  **`stds = X_train.std(dim=0, keepdims=True)`**:\n",
        "    *   Calculates the standard deviation of each feature in `X_train`, similar to how `means` were calculated.\n",
        "\n",
        "4.  **`X_train = (X_train - means) / stds`**:\n",
        "    *   Applies the standardization formula: `(value - mean) / standard_deviation`. Each feature in `X_train` is transformed using the calculated `means` and `stds` from the training data. It's crucial to use the means and standard deviations *from the training set* to transform the validation and test sets to prevent data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OGZQWnAEL5Dc"
      },
      "outputs": [],
      "source": [
        "X_train = torch.FloatTensor(X_train)\n",
        "X_valid = torch.FloatTensor(X_valid)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "means = X_train.mean(dim=0, keepdims=True)\n",
        "stds = X_train.std(dim=0, keepdims=True)\n",
        "X_train = (X_train - means) / stds\n",
        "X_valid = (X_valid - means) / stds\n",
        "X_test = (X_test - means) / stds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6swHyXyLL5Dc"
      },
      "source": [
        "PyTorch expects the targets to have one row per sample, so let's reshape the targets to be column vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "c1ZtzjqSL5Dc"
      },
      "outputs": [],
      "source": [
        "y_train = torch.FloatTensor(y_train).view(-1, 1)\n",
        "y_valid = torch.FloatTensor(y_valid).view(-1, 1)\n",
        "y_test = torch.FloatTensor(y_test).view(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acaaddef"
      },
      "source": [
        "This code cell initializes the parameters for a simple linear regression model that will be trained using PyTorch. Let's go through each line:\n",
        "\n",
        "*   **`torch.manual_seed(42)`**:\n",
        "    *   This line sets the random seed for PyTorch operations. Setting a manual seed ensures that any random operations (like initializing tensors with random values) will produce the same results every time you run the code. This is crucial for reproducibility, allowing you to get the same experimental outcomes across different runs.\n",
        "\n",
        "*   **`n_features = X_train.shape[1]`**:\n",
        "    *   This determines the number of input features in your training data. `X_train.shape` returns a tuple representing the dimensions of the `X_train` tensor. Since `X_train` is typically `(number_of_samples, number_of_features)`, `X_train.shape[1]` extracts the number of features (columns).\n",
        "\n",
        "*   **`w = torch.randn((n_features, 1), requires_grad=True)`**:\n",
        "    *   This initializes the **weight vector (`w`)** for the linear regression model. `torch.randn` creates a tensor filled with random numbers drawn from a standard normal distribution (mean 0, variance 1).\n",
        "    *   The shape `(n_features, 1)` means it's a column vector, with one weight for each input feature.\n",
        "    *   `requires_grad=True` is a critical PyTorch setting. It tells PyTorch to track all operations performed on this tensor so that gradients can be computed during the backward pass (backpropagation). This is essential for optimization algorithms like gradient descent to update the weights.\n",
        "\n",
        "*   **`b = torch.tensor(0., requires_grad=True)`**:\n",
        "    *   This initializes the **bias term (`b`)** for the linear regression model. It's set to a single floating-point value of `0.0`.\n",
        "    *   Similar to `w`, `requires_grad=True` is set to ensure that PyTorch tracks operations on `b` so its gradient can also be computed and updated during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5xvBM7lhL5Dc"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "n_features = X_train.shape[1]  # there are 8 input features\n",
        "w = torch.randn((n_features, 1), requires_grad=True)\n",
        "b = torch.tensor(0., requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID_T5CjsL5Dc"
      },
      "source": [
        "**Note**: in the next section, we will build an almost identical model using PyTorch's high-level API. Its results will be slightly different because it will use a different parameter initialization method: it will use a uniform random distribution from $-\\frac{1}{2\\sqrt 2}$ to $+\\frac{1}{2\\sqrt 2}$ to initialize both the weights and the bias term. If you want to get exactly the same result here as in the next section, you can uncomment and run the initialization code in the following cell, instead of the code in the previous cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "It-8QicHL5Dc"
      },
      "outputs": [],
      "source": [
        "# torch.manual_seed(42)\n",
        "# n_features = X_train.shape[1]  # there are 8 input features\n",
        "# r = 2 ** -1.5  # this is equal to 1 / 2√2\n",
        "# w = torch.empty(n_features, 1).uniform_(-r, r)\n",
        "# b = torch.empty(1).uniform_(-r, r)\n",
        "# w.requires_grad_(True)\n",
        "# b.requires_grad_(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17018db0"
      },
      "source": [
        "This code cell implements a basic training loop for the linear regression model you just initialized. It uses **batch gradient descent** to iteratively adjust the model's weights (`w`) and bias (`b`) to minimize the prediction error. Let's break down each step:\n",
        "\n",
        "*   **`learning_rate = 0.4`**:\n",
        "    *   This sets the `learning_rate` for the optimization algorithm. The learning rate is a hyperparameter that determines the size of the steps taken during gradient descent. A larger learning rate can converge faster but might overshoot the minimum, while a smaller one can be more precise but slower.\n",
        "\n",
        "*   **`n_epochs = 20`**:\n",
        "    *   This defines the number of `epochs`, which is the number of times the entire training dataset will be passed forward and backward through the neural network.\n",
        "\n",
        "*   **`for epoch in range(n_epochs):`**:\n",
        "    *   This loop iterates through each epoch of the training process.\n",
        "\n",
        "*   **`y_pred = X_train @ w + b`**:\n",
        "    *   This is the **forward pass**. It calculates the predicted `y` values (`y_pred`) using the current `X_train` data, the weight vector `w`, and the bias `b`. This is the linear regression equation: `y = Xw + b`.\n",
        "\n",
        "*   **`loss = ((y_pred - y_train) ** 2).mean()`**:\n",
        "    *   This calculates the **Mean Squared Error (MSE)**, which is a common loss function for regression tasks. It measures the average squared difference between the predicted values (`y_pred`) and the actual target values (`y_train`). The goal of training is to minimize this loss.\n",
        "\n",
        "*   **`loss.backward()`**:\n",
        "    *   This is the **backward pass**. It triggers PyTorch's autograd engine to compute the gradients of the `loss` with respect to all tensors that have `requires_grad=True` (in this case, `w` and `b`). These gradients indicate how much each parameter contributes to the error.\n",
        "\n",
        "*   **`with torch.no_grad():`**:\n",
        "    *   This context manager temporarily disables gradient tracking. This is crucial during the parameter update step because you don't want these updates to be considered part of the computational graph for subsequent gradient calculations. The optimizer's step should not have its own gradients calculated.\n",
        "\n",
        "*   **`b -= learning_rate * b.grad`** **`w -= learning_rate * w.grad`**: These lines perform the **gradient descent step**. The parameters (`w` and `b`) are updated by subtracting a fraction of their respective gradients. The `learning_rate` controls the size of this step, moving the parameters in the direction that reduces the loss.\n",
        "\n",
        "*   **`b.grad.zero_()`** **`w.grad.zero_()`**:\n",
        "    These lines **reset the gradients to zero**. After each optimization step, the gradients must be explicitly zeroed out. If not, the gradients from previous backward passes would accumulate, leading to incorrect updates in subsequent epochs.\n",
        "\n",
        "*   **`print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")`**:\n",
        "    *   This line prints the current epoch number and the loss value, allowing you to monitor the training progress. `loss.item()` retrieves the scalar value of the loss tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "T0mY8W9LL5Dc",
        "outputId": "af531c90-5b98-48e9-ccfa-3fa3114ad411",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 16.158456802368164\n",
            "Epoch 2/20, Loss: 4.8793745040893555\n",
            "Epoch 3/20, Loss: 2.255225419998169\n",
            "Epoch 4/20, Loss: 1.3307634592056274\n",
            "Epoch 5/20, Loss: 0.9680691957473755\n",
            "Epoch 6/20, Loss: 0.8142675757408142\n",
            "Epoch 7/20, Loss: 0.7417045831680298\n",
            "Epoch 8/20, Loss: 0.7020701169967651\n",
            "Epoch 9/20, Loss: 0.6765918731689453\n",
            "Epoch 10/20, Loss: 0.6577965021133423\n",
            "Epoch 11/20, Loss: 0.6426151990890503\n",
            "Epoch 12/20, Loss: 0.6297222971916199\n",
            "Epoch 13/20, Loss: 0.6184942126274109\n",
            "Epoch 14/20, Loss: 0.6085968613624573\n",
            "Epoch 15/20, Loss: 0.5998216867446899\n",
            "Epoch 16/20, Loss: 0.592018723487854\n",
            "Epoch 17/20, Loss: 0.5850691795349121\n",
            "Epoch 18/20, Loss: 0.578873336315155\n",
            "Epoch 19/20, Loss: 0.573345422744751\n",
            "Epoch 20/20, Loss: 0.5684100389480591\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.4\n",
        "n_epochs = 20\n",
        "for epoch in range(n_epochs):\n",
        "    y_pred = X_train @ w + b\n",
        "    loss = ((y_pred - y_train) ** 2).mean()\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        b -= learning_rate * b.grad\n",
        "        w -= learning_rate * w.grad\n",
        "        b.grad.zero_()\n",
        "        w.grad.zero_()\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "A5J4ett7L5Dd"
      },
      "outputs": [],
      "source": [
        "X_new = X_test[:3]  # pretend these are new instances\n",
        "with torch.no_grad():\n",
        "    y_pred = X_new @ w + b  # use the trained parameters to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "D-Knxj1_L5Dd",
        "outputId": "08694af9-4111-4961-b240-f1506dc566be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8916],\n",
              "        [1.6480],\n",
              "        [2.6577]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIWSozi_L5Dd"
      },
      "source": [
        "## Linear Regression Using PyTorch's High-Level API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "7E0kwL7sL5Dd"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(42)  # to get reproducible results\n",
        "model = nn.Linear(in_features=n_features, out_features=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our model has a single neuron (out_features=1), the bias vector contains a single bias term, and a weight matrix contains a single row."
      ],
      "metadata": {
        "id": "beMPhsB2xYBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSnbAdMNm0oc",
        "outputId": "bad2b2c0-b73b-4175-f6b2-3de543202bda"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.3117], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "LgYdAlT4L5Dd",
        "outputId": "c60e6e3f-8d7c-4495-f722-cd06d862b449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model.weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n699V4wHorVT",
        "outputId": "03c018b2-e751-4e7a-e2a8-aa3ff2e94576"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "sCXl1_yIL5Dd",
        "outputId": "3b3e9f09-66e7-4146-91c7-d6ae37fc3de0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.3117], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for param in model.parameters():\n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.named_parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztp4Tr1ppjus",
        "outputId": "31a3a992-db3d-49ff-cc47-bd750a7a2853"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', Parameter containing:\n",
            "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
            "       requires_grad=True))\n",
            "('bias', Parameter containing:\n",
            "tensor([0.3117], requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68fd52bd"
      },
      "source": [
        "The line `model(X_train[:2])` is essentially calling the `forward()` method of your `model` instance. When you define a `nn.Module` in PyTorch, making an instance of it callable like `model(...)` automatically triggers its `forward()` method.\n",
        "\n",
        "In this specific case:\n",
        "\n",
        "*   `model`: This refers to your instantiated PyTorch model (which, based on the preceding cells, is likely the `nn.Linear` model for linear regression).\n",
        "*   `X_train[:2]`: This selects the first two samples (rows) from your `X_train` tensor. This is a common practice to quickly test the model's output shape and initial behavior without processing the entire dataset.\n",
        "\n",
        "So, `model(X_train[:2])` takes these two training samples as input, passes them through the model's layers (in this case, just a linear transformation), and returns the model's predictions (or intermediate activations, depending on the model's definition) for those two samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "JuGFLnH2L5Dd",
        "outputId": "a24c35eb-7edc-4546-ef77-f5f308817316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4718],\n",
              "        [ 0.1131]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "model(X_train[:2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dummy_hook_fn(module, input, output):\n",
        "    print(\"Forward hook activated!\")\n",
        "    # You can inspect input/output here\n",
        "\n",
        "# Instantiate a fresh model to avoid any state issues from previous reassignments\n",
        "# using n_features from earlier to keep it compatible with our data\n",
        "model_for_hook_demo = nn.Linear(in_features=n_features, out_features=1).to(device)\n",
        "\n",
        "hook_handle = model_for_hook_demo.register_forward_hook(dummy_hook_fn)\n",
        "\n",
        "# Now, let's call the model once to see the hook activate\n",
        "# Use a small slice of X_train, ensuring it's on the correct device\n",
        "model_for_hook_demo(X_train[:1].to(device)) # Pass data to activate the hook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObSKTaw3sq6T",
        "outputId": "44aab98f-9d74-4759-aac1-20c3e1eb20ab"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward hook activated!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8178]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To remove the hook, simply call its .remove() method\n",
        "hook_handle.remove()\n",
        "print(\"Hook removed. Calling model again should not activate the hook.\")\n",
        "\n",
        "# Use the same model_for_hook_demo for consistency\n",
        "model_for_hook_demo(X_train[:1].to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKb-Jvg2tDbX",
        "outputId": "f7f21dc1-c616-48d0-d52e-0dd240bdc3c5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hook removed. Calling model again should not activate the hook.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8178]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b4aecef"
      },
      "source": [
        "This code cell initializes two fundamental components required for training a PyTorch model:\n",
        "\n",
        "1.  **`optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)`**:\n",
        "    *   **`torch.optim.SGD`**: This creates an optimizer object using the Stochastic Gradient Descent (SGD) algorithm. Optimizers are responsible for updating the model's weights and biases during training based on the calculated gradients.\n",
        "    *   **`model.parameters()`**: This tells the optimizer *which* parameters (weights and biases) of your `model` it should optimize. This method automatically collects all tensors in the model that have `requires_grad=True`.\n",
        "    *   **`lr=learning_rate`**: This sets the `learning_rate` for the optimizer. The learning rate is a crucial hyperparameter that determines the step size at each iteration while moving towards a minimum of the loss function.\n",
        "\n",
        "2.  **`mse = nn.MSELoss()`**:\n",
        "    *   **`nn.MSELoss()`**: This initializes the Mean Squared Error (MSE) loss function. Loss functions quantify how far off your model's predictions are from the true target values. During training, the optimizer aims to minimize this loss value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "L92wadx1L5Dd"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "mse = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "284f38e6"
      },
      "source": [
        "This code cell defines the `train_bgd` function, which orchestrates the training process of a PyTorch model using **Batch Gradient Descent**.\n",
        "\n",
        "*   **`def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):`**:\n",
        "    *   This line defines the function signature, taking the `model`, `optimizer`, `criterion` (loss function), training data (`X_train`, `y_train`), and number of epochs (`n_epochs`) as inputs.\n",
        "\n",
        "*   **`for epoch in range(n_epochs):`**:\n",
        "    *   This outer loop iterates through the specified number of `n_epochs`. Each epoch represents one full pass over the entire training dataset.\n",
        "\n",
        "*   **`y_pred = model(X_train)`**:\n",
        "    *   **Forward Pass**: The entire `X_train` dataset is passed through the `model` to get predictions (`y_pred`). Since `X_train` contains all training samples, this is a batch gradient descent step.\n",
        "\n",
        "*   **`loss = criterion(y_pred, y_train)`**:\n",
        "    *   **Loss Calculation**: The `criterion` (e.g., `nn.MSELoss` in regression) is used to compute the difference between the model's predictions (`y_pred`) and the actual target values (`y_train`).\n",
        "\n",
        "*   **`loss.backward()`**:\n",
        "    *   **Backward Pass**: This is where PyTorch's autograd engine kicks in. It computes the gradients of the `loss` with respect to all parameters in the `model` that have `requires_grad=True`.\n",
        "\n",
        "*   **`optimizer.step()`**:\n",
        "    *   **Parameter Update**: The `optimizer` (e.g., `torch.optim.SGD`) uses the calculated gradients to update the model's parameters (weights and biases) in the direction that minimizes the `loss`.\n",
        "\n",
        "*   **`optimizer.zero_grad()`**:\n",
        "    *   **Zero Gradients**: After updating the parameters, the gradients are reset to zero. This is crucial because PyTorch accumulates gradients by default. If you don't zero them out, the gradients from previous batches/epochs would interfere with the current one, leading to incorrect updates.\n",
        "\n",
        "*   **`print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")`**:\n",
        "    *   This line prints the current epoch number and the corresponding loss value, allowing you to monitor the training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "g03PNcadL5Dd"
      },
      "outputs": [],
      "source": [
        "def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):\n",
        "    for epoch in range(n_epochs):\n",
        "        y_pred = model(X_train)\n",
        "        loss = criterion(y_pred, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "_ujeondtL5Dd",
        "outputId": "048a38a6-0507-4144-a298-5654e5a5db85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 4.3378496170043945\n",
            "Epoch 2/20, Loss: 0.7802939414978027\n",
            "Epoch 3/20, Loss: 0.6253842115402222\n",
            "Epoch 4/20, Loss: 0.6060433983802795\n",
            "Epoch 5/20, Loss: 0.5956299304962158\n",
            "Epoch 6/20, Loss: 0.587356686592102\n",
            "Epoch 7/20, Loss: 0.5802990794181824\n",
            "Epoch 8/20, Loss: 0.5741382837295532\n",
            "Epoch 9/20, Loss: 0.5687101483345032\n",
            "Epoch 10/20, Loss: 0.5639079809188843\n",
            "Epoch 11/20, Loss: 0.5596511363983154\n",
            "Epoch 12/20, Loss: 0.5558737516403198\n",
            "Epoch 13/20, Loss: 0.5525194406509399\n",
            "Epoch 14/20, Loss: 0.5495392084121704\n",
            "Epoch 15/20, Loss: 0.5468900203704834\n",
            "Epoch 16/20, Loss: 0.544533908367157\n",
            "Epoch 17/20, Loss: 0.5424376726150513\n",
            "Epoch 18/20, Loss: 0.5405716300010681\n",
            "Epoch 19/20, Loss: 0.5389097332954407\n",
            "Epoch 20/20, Loss: 0.5374288558959961\n"
          ]
        }
      ],
      "source": [
        "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae039ada"
      },
      "source": [
        "This code block shows how to use your trained PyTorch model to make predictions on new, unseen data, which is often referred to as **inference** or **prediction time**. It also introduces `torch.no_grad()`, a crucial context manager for this phase.\n",
        "\n",
        "*   **`X_new = X_test[:3]`**:\n",
        "    *   This line simply creates a small subset of your `X_test` data, taking the first three samples. This `X_new` tensor represents the \"new instances\" on which you want your trained model to make predictions.\n",
        "\n",
        "*   **`with torch.no_grad():`**:\n",
        "    *   This is a context manager provided by PyTorch that temporarily sets all of PyTorch's `requires_grad` flags to `False` within its block. This means that, for any computations performed inside this block:\n",
        "        *   **No gradients will be computed or stored.** PyTorch's autograd engine will not build a computation graph to track operations.\n",
        "        *   **Why is this important for predictions?** During inference, you are not trying to learn or update the model's parameters. Therefore, there's no need to compute gradients. Disabling gradient computation offers several benefits:\n",
        "            *   **Reduced Memory Usage**: Not storing intermediate activations and gradient information significantly reduces memory consumption.\n",
        "            *   **Faster Computation**: Operations are faster because PyTorch doesn't need to perform the overhead of building the computation graph.\n",
        "            *   **Prevents Accidental Updates**: It ensures that no model parameters are accidentally modified if an operation within the block were to somehow trigger gradient calculations.\n",
        "\n",
        "*   **`y_pred = model(X_new)`**:\n",
        "    *   Inside the `torch.no_grad()` block, this line performs the forward pass: the `X_new` data is passed through the `model` to obtain its predictions (`y_pred`). Since the model was trained for regression, `y_pred` will contain the predicted continuous values for each of the `X_new` instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "5NmpkatML5Dd",
        "outputId": "1d3de942-e2ba-4d1e-c814-5b6d1c34c69f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8061],\n",
              "        [1.7116],\n",
              "        [2.6973]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "X_new = X_test[:3]  # pretend these are new instances\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_new)  # use the trained model to make predictions\n",
        "\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-mIBt5LL5Dd"
      },
      "source": [
        "# Implementing a Regression MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Fw3LPhnsL5Dd"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 50),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(50, 40),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(40, 1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "yOqYvw4dL5Dd",
        "outputId": "e9339d45-ad6b-42fe-f85d-4229d42fa345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 5.045480251312256\n",
            "Epoch 2/20, Loss: 2.0523123741149902\n",
            "Epoch 3/20, Loss: 1.0039883852005005\n",
            "Epoch 4/20, Loss: 0.8570139408111572\n",
            "Epoch 5/20, Loss: 0.7740675210952759\n",
            "Epoch 6/20, Loss: 0.7225847244262695\n",
            "Epoch 7/20, Loss: 0.6893726587295532\n",
            "Epoch 8/20, Loss: 0.6669032573699951\n",
            "Epoch 9/20, Loss: 0.6507738828659058\n",
            "Epoch 10/20, Loss: 0.6383934020996094\n",
            "Epoch 11/20, Loss: 0.6281993389129639\n",
            "Epoch 12/20, Loss: 0.6193399429321289\n",
            "Epoch 13/20, Loss: 0.6113173365592957\n",
            "Epoch 14/20, Loss: 0.6038705706596375\n",
            "Epoch 15/20, Loss: 0.5968307852745056\n",
            "Epoch 16/20, Loss: 0.5901119112968445\n",
            "Epoch 17/20, Loss: 0.5836468935012817\n",
            "Epoch 18/20, Loss: 0.5774063467979431\n",
            "Epoch 19/20, Loss: 0.5713554620742798\n",
            "Epoch 20/20, Loss: 0.565444827079773\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "mse = nn.MSELoss()\n",
        "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpCDbd18L5Dd"
      },
      "source": [
        "# Implementing Mini-Batch Gradient Descent using DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b346878"
      },
      "source": [
        "This code cell leverages PyTorch's data utilities to prepare your training data for efficient processing, for mini-batch gradient descent:\n",
        "\n",
        "*   **`from torch.utils.data import TensorDataset, DataLoader`**:\n",
        "    *   This line imports two key classes from PyTorch's `data` utility module:\n",
        "        *   **`TensorDataset`**: A `Dataset` wrapper that takes multiple tensors (like your `X_train` and `y_train`) and combines them. It ensures that when you query for an item (e.g., `train_dataset[0]`), it returns the corresponding slice from each tensor. It's useful for datasets where all features and labels can be stored in memory as PyTorch tensors.\n",
        "        *   **`DataLoader`**: This class is an iterator that provides efficient access to your dataset. It handles aspects like batching, shuffling, and multi-process data loading, making training much smoother and faster.\n",
        "\n",
        "*   **`train_dataset = TensorDataset(X_train, y_train)`**:\n",
        "    *   Here, your `X_train` (input features) and `y_train` (target labels) tensors are wrapped into a `TensorDataset` object. This dataset will now yield pairs of `(features, label)` when iterated over.\n",
        "\n",
        "*   **`train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)`**:\n",
        "    *   This creates a `DataLoader` instance from your `train_dataset`.\n",
        "        *   **`batch_size=32`**: Specifies that the `DataLoader` should yield data in batches of 32 samples. This is a common practice for mini-batch gradient descent.\n",
        "        *   **`shuffle=True`**: Instructs the `DataLoader` to randomly shuffle the data at the beginning of each epoch. Shuffling is essential to prevent the model from learning patterns based on the order of samples and helps improve generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "CBPRDScdL5Dd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff9b3ce9"
      },
      "source": [
        "This code cell re-initializes and configures the neural network model, along with its optimizer and loss function. It's often done when you want to train a new architecture or restart training with different settings.\n",
        "\n",
        "*   **`model = nn.Sequential(...)`**:\n",
        "    *   This line defines a new neural network using `nn.Sequential`. `nn.Sequential` is a convenient way to build models by stacking layers sequentially. The model defined here is a Multi-Layer Perceptron (MLP) for regression:\n",
        "        *   `nn.Linear(n_features, 50)`: The input layer, mapping `n_features` to 50 neurons.\n",
        "        *   `nn.ReLU()`: A ReLU activation function after the first linear layer.\n",
        "        *   `nn.Linear(50, 40)`: A hidden layer, mapping 50 to 40 neurons.\n",
        "        *   `nn.ReLU()`: Another ReLU activation.\n",
        "        *   `nn.Linear(40, 1)`: The output layer, mapping 40 neurons to a single output (suitable for regression).\n",
        "\n",
        "*   **`model = model.to(device)`**:\n",
        "    *   This is a crucial step that moves the entire model (all its parameters and buffers) from the CPU to the specified `device` (which is typically a GPU like 'cuda' if available). This enables faster computations by leveraging GPU acceleration.\n",
        "\n",
        "*   **`learning_rate = 0.02`**:\n",
        "    *   The learning rate for the optimizer is set to `0.02`. Notice this is different from previous examples, indicating a hyperparameter change.\n",
        "\n",
        "*   **`optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)`**:\n",
        "    *   A new Stochastic Gradient Descent (SGD) optimizer is initialized. It's configured to optimize the parameters of the *newly defined* `model`.\n",
        "    *   `momentum=0`: The momentum term is set to 0, meaning standard SGD is used without any momentum accumulation.\n",
        "\n",
        "*   **`mse = nn.MSELoss()`**:\n",
        "    *   The Mean Squared Error (MSE) loss function is re-initialized, which will be used to calculate the difference between the model's predictions and the true target values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "OudXqfiHL5Dd"
      },
      "outputs": [],
      "source": [
        "# extra code – build the model just like earlier\n",
        "torch.manual_seed(42)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 50), nn.ReLU(),\n",
        "    nn.Linear(50, 40), nn.ReLU(),\n",
        "    nn.Linear(40, 1)\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# extra code – build the optimizer and loss function, as earlier\n",
        "learning_rate = 0.02\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "084636c5"
      },
      "source": [
        "This code cell defines the `train` function, which is an enhanced version of the training loop designed for **mini-batch gradient descent**. It processes data in smaller batches, which is generally more efficient and allows for training on larger datasets that might not fit entirely into memory. Let's break down its components:\n",
        "\n",
        "*   **`def train(model, optimizer, criterion, train_loader, n_epochs):`**: This defines the function signature, taking the `model`, `optimizer`, `criterion` (loss function), `train_loader` (for iterating over mini-batches), and `n_epochs` as inputs.\n",
        "\n",
        "*   **`model.train()`**: This sets the model to training mode. It's crucial because certain layers, like `Dropout` and `BatchNorm`, behave differently during training (e.g., `Dropout` layers are active, and `BatchNorm` layers update their running statistics).\n",
        "\n",
        "*   **`for epoch in range(n_epochs):`**: This outer loop iterates through the specified number of `n_epochs`, making multiple passes over the entire training dataset.\n",
        "\n",
        "*   **`total_loss = 0.`**: Initializes a variable to accumulate the loss for the current epoch.\n",
        "\n",
        "*   **`for X_batch, y_batch in train_loader:`**: This inner loop iterates through the `train_loader`, which yields mini-batches of data (`X_batch`, `y_batch`). This is the core of mini-batch gradient descent.\n",
        "\n",
        "*   **`X_batch, y_batch = X_batch.to(device), y_batch.to(device)`**: Crucially, this line moves the current mini-batch of features (`X_batch`) and labels (`y_batch`) to the specified computing `device` (e.g., GPU). This ensures that computations happen on the correct hardware.\n",
        "\n",
        "*   **`y_pred = model(X_batch)`**:\n",
        "    *   **Forward Pass**: The model takes the `X_batch` as input and produces predictions (`y_pred`).\n",
        "\n",
        "*   **`loss = criterion(y_pred, y_batch)`**:\n",
        "    *   **Loss Calculation**: The `criterion` (loss function, e.g., `nn.MSELoss`) calculates the difference between the model's predictions and the true labels for the current mini-batch.\n",
        "\n",
        "*   **`total_loss += loss.item()`**: Adds the loss of the current mini-batch to the `total_loss` for the epoch.\n",
        "\n",
        "*   **`loss.backward()`**:\n",
        "    *   **Backward Pass**: Computes the gradients of the `loss` with respect to all trainable parameters in the `model`.\n",
        "\n",
        "*   **`optimizer.step()`**:\n",
        "    *   **Parameter Update**: The `optimizer` uses these computed gradients to update the model's parameters.\n",
        "\n",
        "*   **`optimizer.zero_grad()`**:\n",
        "    *   **Zero Gradients**: Resets the gradients to zero. This is vital because PyTorch accumulates gradients by default; failing to zero them out would lead to gradients from previous mini-batches affecting the current update.\n",
        "\n",
        "*   **`mean_loss = total_loss / len(train_loader)`**: After iterating through all mini-batches, the average loss for the epoch is calculated.\n",
        "\n",
        "*   **`print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_loss:.4f}\")`**: Prints the current epoch number and the average loss for that epoch, allowing you to monitor the training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "m-QkdMBwL5Dd"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "0dOg94o8L5Dd",
        "outputId": "8ff5d0bc-ca02-4299-d9cf-09ee0571a265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.5900\n",
            "Epoch 2/20, Loss: 0.4046\n",
            "Epoch 3/20, Loss: 0.3801\n",
            "Epoch 4/20, Loss: 0.3629\n",
            "Epoch 5/20, Loss: 0.3529\n",
            "Epoch 6/20, Loss: 0.3520\n",
            "Epoch 7/20, Loss: 0.3408\n",
            "Epoch 8/20, Loss: 0.3427\n",
            "Epoch 9/20, Loss: 0.3406\n",
            "Epoch 10/20, Loss: 0.3378\n",
            "Epoch 11/20, Loss: 0.3304\n",
            "Epoch 12/20, Loss: 0.3267\n",
            "Epoch 13/20, Loss: 0.3244\n",
            "Epoch 14/20, Loss: 0.3221\n",
            "Epoch 15/20, Loss: 0.3186\n",
            "Epoch 16/20, Loss: 0.3149\n",
            "Epoch 17/20, Loss: 0.3123\n",
            "Epoch 18/20, Loss: 0.3111\n",
            "Epoch 19/20, Loss: 0.3088\n",
            "Epoch 20/20, Loss: 0.3072\n"
          ]
        }
      ],
      "source": [
        "train(model, optimizer, mse, train_loader, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYDNl_4eL5Dd"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "447e0356"
      },
      "source": [
        "This code cell defines the `evaluate` function, which is responsible for assessing the performance of a trained PyTorch model on a given dataset, such as a validation or test set. It's designed for **inference** rather than training.\n",
        "\n",
        "*   **`def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):`**:\n",
        "    *   This defines the function signature. It takes the `model` to be evaluated, a `data_loader` (which could be `valid_loader` or `test_loader`), a `metric_fn` (a function to calculate a metric, like MSE or RMSE, for each batch), and an optional `aggregate_fn` (defaults to `torch.mean` to combine batch metrics).\n",
        "\n",
        "*   **`model.eval()`**:\n",
        "    *   This is a crucial step that sets the model to evaluation mode. In contrast to `model.train()`, this disables specific layers like `Dropout` and ensures that `BatchNorm` layers use their learned running statistics instead of batch statistics. This is essential for consistent and accurate evaluation results.\n",
        "\n",
        "*   **`metrics = []`**:\n",
        "    *   Initializes an empty list to store the metric calculated for each mini-batch.\n",
        "\n",
        "*   **`with torch.no_grad():`**:\n",
        "    *   As we discussed earlier, this context manager disables gradient calculation. During evaluation, we don't need to compute gradients because we're not updating the model's weights. Disabling autograd saves memory and speeds up computations.\n",
        "\n",
        "*   **`for X_batch, y_batch in data_loader:`**:\n",
        "    *   This loop iterates through the provided `data_loader`, yielding mini-batches of features (`X_batch`) and labels (`y_batch`).\n",
        "\n",
        "*   **`X_batch, y_batch = X_batch.to(device), y_batch.to(device)`**:\n",
        "    *   Moves the current mini-batch to the specified computing `device` (e.g., GPU), ensuring consistency with the model's device.\n",
        "\n",
        "*   **`y_pred = model(X_batch)`**:\n",
        "    *   **Forward Pass**: The model takes the `X_batch` as input and generates predictions (`y_pred`).\n",
        "\n",
        "*   **`metric = metric_fn(y_pred, y_batch)`**:\n",
        "    *   The `metric_fn` is applied to the model's predictions (`y_pred`) and the true labels (`y_batch`) to compute the desired performance metric for the current batch.\n",
        "\n",
        "*   **`metrics.append(metric)`**:\n",
        "    *   The calculated metric for the current batch is added to the `metrics` list.\n",
        "\n",
        "*   **`return aggregate_fn(torch.stack(metrics))`**:\n",
        "    *   After processing all batches, `torch.stack(metrics)` combines all individual batch metrics into a single tensor. Then, the `aggregate_fn` (by default, `torch.mean`) is applied to this tensor to compute the overall metric (e.g., average MSE or RMSE) across the entire dataset. This final value represents the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "q9gBuN5tL5Dd"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
        "    model.eval()\n",
        "    metrics = []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            metric = metric_fn(y_pred, y_batch)\n",
        "            metrics.append(metric)\n",
        "    return aggregate_fn(torch.stack(metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b5155d2"
      },
      "source": [
        "This code block demonstrates how to set up the validation data and then use the previously defined `evaluate` function to assess the model's performance on it.\n",
        "\n",
        "*   **`valid_dataset = TensorDataset(X_valid, y_valid)`**:\n",
        "    *   Similar to how `train_dataset` was created, this line wraps your validation features (`X_valid`) and validation labels (`y_valid`) into a `TensorDataset`. This prepares the data to be easily batched and loaded for evaluation.\n",
        "\n",
        "*   **`valid_loader = DataLoader(valid_dataset, batch_size=32)`**:\n",
        "    *   A `DataLoader` is created for the validation dataset. This `DataLoader` will yield mini-batches of 32 samples from `valid_dataset` during evaluation.\n",
        "    *   Note that `shuffle=True` is typically *not* used for validation or test data loaders, as the order of evaluation does not affect the results and shuffling adds unnecessary overhead.\n",
        "\n",
        "*   **`valid_mse = evaluate(model, valid_loader, mse)`**:\n",
        "    *   This line calls the `evaluate` function. It passes:\n",
        "        *   The trained `model`.\n",
        "        *   The `valid_loader` to provide batches of validation data.\n",
        "        *   The `mse` (Mean Squared Error) loss function as the `metric_fn` to compute the error.\n",
        "    *   The result, which is the mean MSE across all validation batches, is stored in the `valid_mse` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "P2PpYMXvL5Dd",
        "outputId": "7a5111c0-0e72-47ad-d1dd-dc1838b23b1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4080, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "valid_dataset = TensorDataset(X_valid, y_valid)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
        "valid_mse = evaluate(model, valid_loader, mse)\n",
        "valid_mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a63cbf9"
      },
      "source": [
        "This code block defines a custom function for calculating **Root Mean Squared Error (RMSE)** and then uses it to evaluate the model on the validation set.\n",
        "\n",
        "*   **`def rmse(y_pred, y_true):`**:\n",
        "    *   This defines a new function called `rmse` that takes two arguments: `y_pred` (the model's predictions) and `y_true` (the actual target values).\n",
        "\n",
        "*   **`evaluate(model, valid_loader, rmse)`**:\n",
        "    *   This line calls the `evaluate` function (which we discussed earlier). Instead of passing `mse` as the `metric_fn`, it now passes our newly defined `rmse` function. The `evaluate` function will then use this `rmse` function to calculate the RMSE for each batch in the `valid_loader` and return the aggregated (mean) RMSE for the entire validation set.\n",
        "\n",
        "This demonstrates how you can easily define and use custom metrics with your `evaluate` function to get different perspectives on your model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ig6gWno-L5Dd",
        "outputId": "995df7d6-e40f-4c2f-8bba-d748f17ce21d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5668, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "def rmse(y_pred, y_true):\n",
        "    return ((y_pred - y_true) ** 2).mean().sqrt()\n",
        "\n",
        "evaluate(model, valid_loader, rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "QZLvb-WaL5Dd",
        "outputId": "82c6b216-289f-43cf-cb87-f84c67bfedad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6388, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "valid_mse.sqrt()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47aeeae3"
      },
      "source": [
        "The difference you observe between `valid_mse.sqrt()` and `evaluate(model, valid_loader, rmse)` stems from the order of operations when aggregating metrics across batches:\n",
        "\n",
        "1.  **`valid_mse` and `valid_mse.sqrt()`**:\n",
        "    *   Recall that `valid_mse = evaluate(model, valid_loader, mse)`. Our `evaluate` function, when given `mse` as the `metric_fn`, calculates the Mean Squared Error for *each batch*, then computes the **mean of these batch MSEs** (`aggregate_fn=torch.mean`). So, `valid_mse` is essentially `Mean(Batch_MSE_1, Batch_MSE_2, ..., Batch_MSE_N)`.\n",
        "    *   When you then call `valid_mse.sqrt()`, you are taking the square root of this **overall average MSE**.\n",
        "\n",
        "2.  **`evaluate(model, valid_loader, rmse)`**:\n",
        "    *   In contrast, when you pass our custom `rmse` function as the `metric_fn` to `evaluate`, the `evaluate` function calculates the **Root Mean Squared Error for *each batch***. So, it computes `Batch_RMSE_1, Batch_RMSE_2, ..., Batch_RMSE_N`.\n",
        "    *   Then, it computes the **mean of these batch RMSEs** (`Mean(Batch_RMSE_1, Batch_RMSE_2, ..., Batch_RMSE_N)`).\n",
        "\n",
        "**Why are they different?**\n",
        "\n",
        "Mathematically, the square root of an average is generally not equal to the average of square roots. That is:\n",
        "\n",
        "$\\sqrt{\\text{Mean}(\\text{Squared Errors})}$ &ne; $\\text{Mean}(\\sqrt{\\text{Squared Errors}})$\n",
        "\n",
        " Both are valid ways to aggregate, but they measure slightly different things. `valid_mse.sqrt()` (or just taking the RMSE on the entire dataset without batching) gives you a single RMSE value that represents the overall error. Calculating the mean of batch RMSEs (`evaluate(model, valid_loader, rmse)`) is an average of individual batch performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "5B3DdyKHL5Dd",
        "outputId": "b01878ce-4f49-4ff5-ea99-55c8e5a1b2b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6388, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "evaluate(model, valid_loader, mse,\n",
        "         aggregate_fn=lambda metrics: torch.sqrt(torch.mean(metrics)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a120e8a"
      },
      "source": [
        "This code cell defines the `evaluate_tm` function, which is designed to evaluate a PyTorch model using metrics from the `torchmetrics` library. `torchmetrics` provides a convenient and efficient way to calculate metrics, especially when dealing with data that comes in batches.\n",
        "\n",
        "*   **`import torchmetrics`**:\n",
        "    *   Imports the `torchmetrics` library, which offers a wide range of optimized metric implementations.\n",
        "\n",
        "*   **`def evaluate_tm(model, data_loader, metric):`**:\n",
        "    *   This function takes the `model` to evaluate, a `data_loader` (like `valid_loader` or `test_loader`), and a `metric` object (an instance of a `torchmetrics.Metric` class, such as `torchmetrics.MeanSquaredError`).\n",
        "\n",
        "*   **`model.eval()`**:\n",
        "    *   As with the previous `evaluate` function, this sets the model to evaluation mode, which is important for layers like `Dropout` and `BatchNorm` to behave correctly during inference.\n",
        "\n",
        "*   **`metric.reset()`**:\n",
        "    *   This is a crucial step specific to `torchmetrics`. Before starting a new evaluation run, `metric.reset()` clears any internal state or accumulated values from previous computations. This ensures that the metric calculation starts fresh for the current evaluation.\n",
        "\n",
        "*   **`with torch.no_grad():`**:\n",
        "    *   This context manager disables gradient calculation, just as before. It's essential for evaluation to save memory and speed up computations, as we are not updating model weights.\n",
        "\n",
        "*   **`for X_batch, y_batch in data_loader:`**:\n",
        "    *   The function iterates through mini-batches provided by the `data_loader`.\n",
        "\n",
        "*   **`X_batch, y_batch = X_batch.to(device), y_batch.to(device)`**:\n",
        "    *   Moves the current batch of data to the specified `device` (e.g., GPU).\n",
        "\n",
        "*   **`y_pred = model(X_batch)`**:\n",
        "    *   The model performs a forward pass to get predictions for the current batch.\n",
        "\n",
        "*   **`metric.update(y_pred, y_batch)`**:\n",
        "    *   Instead of manually computing the metric for each batch and appending it to a list, `torchmetrics` allows you to `update` the metric object with predictions and true labels from each batch. The `metric` object intelligently accumulates the necessary information (e.g., sums of squared errors, counts) across all batches.\n",
        "\n",
        "*   **`return metric.compute()`**:\n",
        "    *   After all batches have been processed and the `metric` object has accumulated data from the entire `data_loader`, `metric.compute()` calculates the final aggregated metric value (e.g., the overall RMSE or MSE) for the entire dataset. This is a more memory-efficient and often faster way to calculate metrics compared to storing all individual batch metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "xdp2jU_RL5Dd"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "\n",
        "def evaluate_tm(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()  # reset the metric at the beginning\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
        "    return metric.compute()  # compute the final result at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "wMiVq0tqL5De",
        "outputId": "e3658eaf-6c57-4b40-c1ee-a5da75a3fc26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6388, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "evaluate_tm(model, valid_loader, rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e568541"
      },
      "source": [
        "This code cell defines the `train2` function, which is an advanced training loop that not only tracks the training loss but also monitors a specified metric (like RMSE) for both the training and validation sets throughout the training process. It also sets up a new model and visualizes the learning curves.\n",
        "\n",
        "### Explanation of the `train2` Function:\n",
        "\n",
        "*   **`def train2(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs):`**:\n",
        "    *   This function signature is similar to `train`, but it now explicitly takes a `metric` object (a `torchmetrics` instance) and a `valid_loader`.\n",
        "\n",
        "*   **`history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}`**:\n",
        "    *   A dictionary is initialized to store the loss and metric values for each epoch, for both training and validation. This is crucial for plotting learning curves later.\n",
        "\n",
        "*   **Outer `for epoch in range(n_epochs):` loop**: Iterates through each epoch of training.\n",
        "\n",
        "*   **`total_loss = 0.`** and **`metric.reset()`**: `total_loss` is reset for the current epoch. The `torchmetrics` `metric` is also reset to clear any accumulated state from previous epochs, ensuring accurate calculation for the current epoch.\n",
        "\n",
        "*   **Inner `for X_batch, y_batch in train_loader:` loop**:\n",
        "    *   This loop processes data in mini-batches, just like in the `train` function.\n",
        "    *   **`model.train()`**: Sets the model to training mode.\n",
        "    *   **Device transfer, forward pass, loss calculation, backward pass, optimizer step, zero gradients**: These steps are identical to the `train` function.\n",
        "    *   **`metric.update(y_pred, y_batch)`**: This is where `torchmetrics` comes in for the training metric. Instead of manually accumulating values, the `metric` object is updated with the predictions and true labels of the current batch.\n",
        "\n",
        "*   **After the inner loop (end of epoch calculations)**:\n",
        "    *   **`mean_loss = total_loss / len(train_loader)`**: Calculates the average loss for the training set in the current epoch.\n",
        "    *   **`history[\"train_losses\"].append(mean_loss)`**: Stores the mean training loss.\n",
        "    *   **`history[\"train_metrics\"].append(metric.compute().item())`**: Computes the final training metric for the epoch (using all updates from `metric.update()`) and stores it. `item()` retrieves the scalar value from the tensor.\n",
        "    *   **`history[\"valid_metrics\"].append(evaluate_tm(model, valid_loader, metric).item())`**: Calls the `evaluate_tm` function (defined in a previous cell) to calculate the metric on the validation set. This provides insight into how well the model generalizes to unseen data. The `metric` object is passed by reference, and `evaluate_tm` handles its own `reset`, `update`, and `compute` cycle internally for the validation data.\n",
        "    *   **`print(...)`**: Prints the training loss, training metric, and validation metric for the current epoch, providing real-time feedback on model performance.\n",
        "\n",
        "*   **`return history`**: The function returns the `history` dictionary containing all recorded metrics.\n",
        "\n",
        "### Model Initialization and Training Execution:\n",
        "\n",
        "*   **`torch.manual_seed(42)`**: Ensures reproducibility.\n",
        "*   A new `model` is defined using `nn.Sequential` with three `nn.Linear` layers interspersed with `nn.ReLU` activations, and an output layer. This is a slightly deeper architecture than previous examples (`40 -> 30` neurons added).\n",
        "*   **`model = model.to(device)`**: Moves the newly created model to the GPU.\n",
        "*   `learning_rate`, `optimizer` (SGD with `momentum=0`), `mse` (loss function), and `rmse` (metric for `torchmetrics`) are re-initialized for this new training run.\n",
        "*   **`history = train2(...)`**: The `train2` function is called with the newly configured model, optimizer, loss, metric, and data loaders.\n",
        "\n",
        "### Plotting Learning Curves:\n",
        "\n",
        "*   The `matplotlib.pyplot` library is used to plot the training and validation RMSE (from the `history` dictionary) against the epochs. This visualization, known as learning curves, helps to diagnose issues like overfitting (when training performance keeps improving but validation performance plateaus or worsens) or underfitting (when training and validation performance are poor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Yc3GICy9L5De",
        "outputId": "86b16fb4-c697-4a8e-c979-8b6be0582ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, train loss: 0.7826, train metric: 0.8847, valid metric: 0.6690\n",
            "Epoch 2/20, train loss: 0.4362, train metric: 0.6605, valid metric: 0.6099\n",
            "Epoch 3/20, train loss: 0.3930, train metric: 0.6269, valid metric: 0.6145\n",
            "Epoch 4/20, train loss: 0.3759, train metric: 0.6132, valid metric: 0.5963\n",
            "Epoch 5/20, train loss: 0.3649, train metric: 0.6040, valid metric: 0.5911\n",
            "Epoch 6/20, train loss: 0.3598, train metric: 0.5999, valid metric: 0.5965\n",
            "Epoch 7/20, train loss: 0.3530, train metric: 0.5941, valid metric: 0.6061\n",
            "Epoch 8/20, train loss: 0.3495, train metric: 0.5911, valid metric: 0.6043\n",
            "Epoch 9/20, train loss: 0.3455, train metric: 0.5877, valid metric: 0.5723\n",
            "Epoch 10/20, train loss: 0.3416, train metric: 0.5846, valid metric: 0.6043\n",
            "Epoch 11/20, train loss: 0.3401, train metric: 0.5831, valid metric: 0.5882\n",
            "Epoch 12/20, train loss: 0.3362, train metric: 0.5799, valid metric: 0.5738\n",
            "Epoch 13/20, train loss: 0.3352, train metric: 0.5788, valid metric: 0.5873\n",
            "Epoch 14/20, train loss: 0.3310, train metric: 0.5754, valid metric: 0.5884\n",
            "Epoch 15/20, train loss: 0.3291, train metric: 0.5736, valid metric: 0.5608\n",
            "Epoch 16/20, train loss: 0.3272, train metric: 0.5721, valid metric: 0.5747\n",
            "Epoch 17/20, train loss: 0.3264, train metric: 0.5714, valid metric: 0.5839\n",
            "Epoch 18/20, train loss: 0.3238, train metric: 0.5691, valid metric: 0.5661\n",
            "Epoch 19/20, train loss: 0.3207, train metric: 0.5663, valid metric: 0.5556\n",
            "Epoch 20/20, train loss: 0.3190, train metric: 0.5649, valid metric: 0.5617\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHNCAYAAAAOvD9aAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAeR1JREFUeJzt3Xd4VFXixvHvzCSZNJIQAgEChN4hFKkqRQIoiGADZaWpWHF1seIqRVexIqtr+7kUlVVBRRFREJCignSULj2UFCAkgYQkk8z9/TFkYJhkSEJ63s/zzEPmzrl3zpmZZF7OPfcck2EYBiIiIiKSK3NpV0BERESkLFNYEhEREfFAYUlERETEA4UlEREREQ8UlkREREQ8UFgSERER8UBhSURERMQDhSURERERDxSWRERERDxQWBKRMqVXr16YTKbSroaIiJPCkkg5dOjQIUwmE9dff31pV0VEpMLzKu0KiIhc7JNPPiEtLa20qyEi4qSwJCJlSr169Uq7CiIiLnQaTqQSOHPmDJMmTaJVq1b4+fkREhJC//79+fXXX93Kbtq0iXHjxtG6dWuCg4Px8/OjTZs2vPLKK9hsNrfy9evXp379+iQlJTFu3Djq1q2Ll5cXs2fPdp4uHD16NPv27ePmm2+matWqBAQEEB0dzR9//OF2vNzGLM2ePRuTycTs2bP56aef6N69O/7+/lSrVo1Ro0Zx6tSpXNv94Ycf0qpVK3x9falbty5PPfUU6enpmEwmevXqle/XzzAMZs2axbXXXktISAj+/v40adKE+++/n5iYGLfXIje5tWvy5MmYTCZWrlzJ7Nmz6dChA/7+/vTq1YtPP/0Uk8nECy+8kOvxNm/ejMlk4m9/+5vL9oSEBP7xj3/QuHFjrFYrYWFh3HrrrWzfvt3tGHv37mXMmDE0aNAAq9VKaGgoUVFRPPbYYxiGke/XR6SiU8+SSAWXmJhIjx492LFjB1dffTUPPPAAKSkpLFiwgN69e/Pll18yZMgQZ/mPPvqIhQsX0qNHDwYMGEBaWhorV65kwoQJbNiwga+//trtOTIyMrjuuus4e/YsN910E15eXoSHhzsfP3ToEF27dqVVq1bcfffd7N+/3/n8u3btcinryXfffceiRYsYNGgQ3bt3Z/Xq1XzyySfs37/fLfhNnDiRF198kfDwcMaOHYu3tzfz5s1j9+7dBXr97HY7w4YN46uvviIiIoI777yToKAgDh06xLx587jhhhuuuDfs9ddfZ8WKFQwePJh+/fphsVi45ZZbePDBB/nf//7HxIkT3fb59NNPARgxYoRz2/79++nVqxdHjx6lX79+DBkyhISEBL7++muWLFnC8uXL6dKlCwDHjx+nc+fOpKamMnDgQIYNG0Zqaip79+7lvffe44033sDLS18RIgAYIlLuHDx40ACM/v37X7bs8OHDDcD46KOPXLbHx8cbdevWNapXr26cO3fOuf3w4cNGVlaWS1m73W7cfffdBmD8+uuvLo9FRkY665KWlpZrPQHjlVdecXnsueeeMwBj6tSpLtt79uxpXPqnadasWQZgeHl5uTx/VlaW0atXLwMw1q5d69y+Z88ew2KxGBEREUZ8fLxze0pKitGyZUsDMHr27JnXS+binXfeMQCjT58+bu1LS0szTp065fJaREZG5nqc3No1adIkAzACAgKMP//8022fu+66ywCMdevWuWzPysoywsPDjZo1a7q8V927dzcsFouxePFil/J79uwxqlSpYrRp08a57e233zYAY/r06W7Pe3GbRMQwdBpOpAI7efIkc+fO5brrruPee+91eaxGjRo8+eSTnDhxgmXLljm316tXD4vF4lLWZDLx8MMPA7iUvdhrr72Gn59fro81aNCAJ5980mXbPffcA8CGDRvy3Z7hw4dz9dVXO+9bLBZGjRrldpzPP/+c7OxsHn/8cWrUqOHcXqVKFZ577rl8Px/Ae++9h8Vi4f3333drn5+fH6GhoQU6Xm7uu+8+2rRp47Y9p9dozpw5Ltt/+ukn4uPjueOOO5zv1ZYtW1izZg2jRo2if//+LuWbNm3K2LFj2bZtm9vpuNzes6Jok0hFoj5WkQpsw4YNZGdnk5GRweTJk90e37t3LwC7d+/mxhtvBCAzM5P//Oc/fPHFF+zevZuzZ8+6jF85fvy423F8fX1z/bLP0a5dO8xm1/+b1alTB4CkpKR8t6djx45u23I7Ts5YqGuuucat/MVh63LOnj3Lrl27aNy4MU2aNMn3fgXVuXPnXLf36dOHWrVq8cUXXzBt2jTnabGc8HTxKbjff/8dgPj4+Fzf65zTj7t376Z169YMGjSICRMm8PDDD7N8+XKuv/56evbsScOGDYuyaSIVgsKSSAWWmJgIwG+//cZvv/2WZ7nU1FTnz7fddhsLFy6kadOmDBs2jBo1auDt7U1SUhL//ve/ycjIcNu/Ro0aHieSDAoKctuW88WfnZ2d7/bk9zgpKSnOel0qv+OjAJKTkwGIiIjI9z6FkVedLBYLw4cP580332TJkiUMHDiQs2fP8u2339KyZUs6dOjgLJvzXi9atIhFixbl+Vw573X9+vX5/fffmTx5Mj/88APz5s0DoHnz5rzwwgvcfvvtRdU8kXJPp+FEKrCccPH4449jGEaet0mTJgGOnqiFCxfSv39/du7cyUcffcRLL73E5MmTueOOO/J8nrI243ZOuxMSEtwei4+Pz/dxgoODATh27Fi+ypvNZrKysnJ9LCd45cbT63fpqbivv/6atLQ0l14luNDmd955x+N7nXPaEqB169Z89dVXJCYmsnbtWiZOnEhcXBzDhg3zGK5FKhuFJZEKrFOnTphMJtauXZuv8vv37wdg4MCBbuOWfvnllyKvX3GJiooCyPULf82aNfk+TmBgIC1btuTgwYPOU5aeVK1alYSEBLfAlHOVWWFERUXRpk0bFixYwJkzZ5gzZ06uUwbkXOWW3/f6Yt7e3nTt2pUpU6bw9ttvYxgG33//faHqK1IRKSyJVGA1a9Zk6NChrFmzhtdffz3XuXPWrVvnnDE7MjISwO0y/B07djB16tTir3ARueOOOzCbzbz55pucPHnSuT01NZWXXnqpQMd6+OGHyc7O5qGHHuLcuXMuj6WnpztPf4EjnNpsNv73v/85txmGwYQJE1xOdRbUiBEjOHfuHG+//TY///wzPXv2pG7dui5lOnfuTJcuXfj888+ZO3eu2zHsdjurVq1y3t+0aZPzdOXFcnrefH19C11fkYpGY5ZEyrFt27YxevToXB9r3rw5zzzzDO+99x579uzhqaee4tNPP6Vbt26EhIRw5MgRNm7cyN69e4mNjcXf35/OnTvTuXNn5s2bR2xsLF27diUmJobvvvuOgQMH8tVXX5VsAwupWbNmPPPMM7z88su0adOGoUOH4uXlxfz582nTpg3bt293G3CelwcffJBVq1Yxb948mjRpwk033URQUBAxMTEsWbKEGTNmOOepGjduHLNmzeLee+9l6dKlVK9enV9++YWkpCSioqJynYQzP4YPH84zzzzDlClTsNvtbqfgcnz++ef07t2bO+64g+nTp9OhQwf8/PyIiYlh7dq1nDhxgvT0dMAxT9OHH35Ijx49aNSoEUFBQezcuZMffviB0NBQxowZU6i6ilRIJT1XgYhcuYvnL8rrdvE8QmlpacZrr71mdOzY0QgICDD8/PyMBg0aGEOGDDE++eQTw2azOcsmJCQYd999t1G7dm3D19fXaNOmjfHuu+8aBw4cMABj1KhRLnXxNLdQTj0v3SfHpfU0DM/zLM2aNcvtGCtWrDAAY9KkSW6Pvffee0aLFi0MHx8fo06dOsYTTzxhHDlyxACMwYMH51qn3NjtduO///2v0bVrVyMgIMDw9/c3mjRpYjzwwANGTEyMS9mff/7Z6NKli2G1Wo1q1aoZI0aMMOLj4z3Os7RixYrL1iE6OtoADF9fXyM5OTnPcomJicZzzz1ntG7d2vDz8zMCAwONJk2aGMOHDzfmz5/vLPf7778b999/v9G6dWsjJCTE8PPzM5o0aWKMGzfOOHz4cL5fG5HKwGQYmtNeRCqPZcuW0bdvX5566ileffXV0q6OiJQDGrMkIhXSiRMn3KYlSEpKYsKECQAuS7yIiHiiMUsiUiH973//44033uC6666jdu3axMbGsnjxYhISEhg9ejTdunUr7SqKSDmhsCQiFVL37t3p2LEjy5YtIzExEYvFQosWLXj++ed56KGHSrt6IlKOlLnTcKtXr2bQoEHUrl0bk8nEt99+e9l9Vq5cSYcOHbBarTRu3JjZs2cXez1FpGzr3LkzCxYs4Pjx46Snp5OamsrGjRsZN25cvq+EExGBMhiWUlNTiYqK4t13381X+YMHDzJw4EB69+7N1q1beeyxx7j33ntZsmRJMddUREREKoMyfTWcyWTim2++8TgQ8+mnn2bRokUuK2nfcccdJCUlsXjx4hKopYiIiFRk5X7M0tq1a4mOjnbZ1r9/fx577LE898nIyHBZDNRut5OYmEi1atXK3BpXIiIikjvDMDhz5gy1a9cu1tPr5T4sxcXFua3YHR4eTkpKCufOncPPz89tn6lTpzJlypSSqqKIiIgUoyNHjlCnTp1iO365D0uFMWHCBMaPH++8n5ycTL169Th48CBVqlQpxZpdOZvNxooVK+jduzfe3t6lXZ0SV5nbX5nbDmp/ZW5/ZW47VO72JyYm0rRp02L/7i73YalmzZrOhR9zxMfHExQUlGuvEoDVasVqtbptDw0NJSgoqFjqWVJsNhv+/v5Uq1at0v3SQOVuf2VuO6j9lbn9lbntoPYDxT6EpsxdDVdQ3bp1Y/ny5S7bli5dqgnnREREpEiUubB09uxZtm7dytatWwHH1ABbt24lJiYGcJxCGzlypLP8Aw88wIEDB3jqqafYvXs37733HvPmzeMf//hHaVRfREREKpgyF5Y2btxI+/btad++PQDjx4+nffv2TJw4EYDY2FhncAJo0KABixYtYunSpURFRfHmm2/y3//+l/79+5dK/UVERKRiKXNjlnr16oWnqZ9ym527V69ebNmypRhrJSIiIpVVmetZEhERESlLFJZEREREPChzp+FERKT02Gw2srOzS7saBWKz2fDy8iI9Pb3c1b0oVLT2WyyWMjcFgsKSiIiQkpLCyZMnXZaCKi8Mw6BmzZocOXKkUi5ZVRHbb7VaCQsLKzNzHyosiYhUcikpKRw7dozAwEDCwsLw9vYuV1+6druds2fPEhgYWKzrg5VVFan9hmFgs9lITk7m2LFjAGUiMCksiYhUcidPniQwMJA6deqUq5CUw263k5mZia+vb7kPC4VR0drv5+dHlSpVOHr0KCdPniwTYan8v6oiIlJoNpuNjIwMgoODy2VQkorJZDIRHBxMRkYGNputtKujsCQiUpnlDAguawNqRXI+k2Vh0LrCkoiIqFdJypyy9JlUWBIRERHxQGFJRERExAOFJRERkRJmMpno1avXFR1j5cqVmEwmpkyZUjSVkjxp6gAREamUCjomxtMi71KxKSyJiEilNGnSJLdt06dPJzk5OdfHitKuXbvw9/e/omN07tyZXbt2ERoaWkS1krwoLImISKU0efJkt22zZ88mOTk518eKUvPmza/4GP7+/jRv3hy73U5KSkoR1EryojFLIiIiHhw6dAiTycTo0aPZtWsXN998M9WqVcNkMnHo0CEAvvnmG+68804aN26Mv78/wcHBXHvttXz99de5HjO3MUujR4/GZDJx8OBB3n77bZo3b47VaiUyMpIpU6Zgt9tdyuc1Zql+/frUr1+fs2fP8uijj1K7dm2sVitt27blq6++yrONw4YNIzQ0lMDAQHr27Mnq1auZPHkyJpOJlStXFuq1qyjUsyQiIiUiNvkcB0+m0iAsgFrBfqVdnQLbt28fXbt2pU2bNowePZpTp07h4+MDwIQJE/Dx8eGaa66hVq1anDhxgu+++47bbruNt99+m0ceeSTfz/Pkk0+yatUqbrzxRvr378+3337L5MmTyczM5KWXXsrXMWw2G/369eP06dPceuutpKWl8cUXXzB06FAWL15Mv379nGWPHTtG9+7diY2N5frrr6d9+/bs2bOHvn37ct111xXsRaqgFJZERMSjtMysPB8zm0z4elsuW/brTUeZ9N0O7AaYTTD1ljYMiqqd7+Oey8zGwH2Atb9PyX2N/fbbb0ycODHXq89++OEHGjZs6LLt7NmzdO/eneeff5577rkn32OUNm/ezJ9//kmtWrUAeP7552nSpAnvvPMOkyZNcgY0T44fP06nTp1YuXKls/zw4cOJjo5m2rRpLmHpmWeeITY2lpdeeolnn33WuX3mzJncc889+apzRaewJCIiHrWcuCTPx3o3q86sMZ2d9zu+uIxzNs/LU9gNeHb+dqb+sJukc7mv+9W2TjDfjbvGeT962iqOJZ1zK3folYGXq36RqVmzJv/85z9zfezSoAQQGBjI6NGjefzxx9mwYQM9e/bM1/M8//zzzqAEEBYWxuDBg/n444/Zs2cPbdq0yddx3nrrLZdg1adPHyIjI9mwYYNzW0ZGBl9++SU1atTg8ccfd9l/zJgxvPbaa+zZsydfz1eRacySiIiUuGzDILucXYofFRWVZ69OQkIC48ePp0WLFvj7+2MymTCZTM4Acvz48Xw/T8eOHd221alTB4CkpKR8HSMkJIQGDRrkepyLj7Fnzx4yMjK46qqrsFqtLmVNJhPdu3fPd70rMvUsiYiIRztf6J/nY+ZL5ira9Hy0W5m45HSip63CflE2sphMLHj4amoG++bruMvG98z1NFxJCg8Pz3V7YmIinTp1IiYmhquvvpro6GhCQkKwWCxs3bqVBQsWkJGRke/nCQoKctvm5eX4us7vorLBwcG5bvfy8nIZKJ5zFV2NGjVyLZ9XmysbhSUREfGoIOOCcivbsHogU29pw7Pzt5NtGFhMJl6+pTUNqwfm+7h+PpbLFypmeU1iOWPGDGJiYnjxxRd57rnnXB575ZVXWLBgQUlUr1BygllCQkKuj8fHx5dkdcoshSURESl2wzrVo0fT6hw6mUb9MP9yeTVcXvbv3w/A4MGD3R775ZdfSro6BdKsWTOsViubNm0iIyPD5VScYRisXbu2FGtXdmjMkoiIlIhawX50a1StQgUlgMjISAB+/fVXl+2fffYZP/zwQ2lUKd+sViu33XYb8fHxTJ8+3eWxTz75hN27d5dOxcoY9SyJiIhcgREjRvDqq6/yyCOPsGLFCiIjI/njjz9Yvnw5t9xyC/Pnzy/tKno0depUli1bxjPPPMOqVauc8yx9//33XH/99SxevBizuXL3rVTu1ouIiFyhOnXqsGrVKvr06cOyZcv48MMPyczM5KeffmLQoEGlXb3Lqlu3LmvXruX2229nzZo1TJ8+nYSEBH766ScaN24M5D7ovDJRz5KIiMh5OcuXXKx+/foYl5nmICoqiiVLcp+PavTo0W7bcjve7NmzmT17dq7HmDx5stt6db169cIwDLe14XJrQ468li1p0KAB8+bNc9v+7LPPYjabnaGpslLPkoiISCUXGxvrtm3OnDn89ttvREdHExiY/ysXKyL1LImIiFRyrVu3pn379rRs2dI5P9TKlSupUqUKb7zxRmlXr9QpLImIiFRyDzzwAAsXLmTjxo2kpqZSvXp1hg8fzvPPP0/z5s1Lu3qlTmFJRESkknvppZd46aWXSrsaZZbGLImIiIh4oLAkIiIi4oHCkoiIiIgHCksiIiIiHigsiYiIiHigsCQiIiLigcKSiIiIiAcKSyIiIiIeKCyJiIiIeKCwJCIiUkxmz56NyWRi9uzZLtvr169P/fr1r/g4RWny5MmYTCZWrlxZbM9RXiksiYhIpTV8+HBMJhOff/65x3IpKSn4+/sTEhLCuXPnSqh2RWvlypWYTCYmT55c2lUpdxSWRESk0rrnnnsAmDlzpsdyn3/+OefOnePOO+/Ez8/vip93+fLlLF++/IqPU5TGjRvHrl276Ny5c2lXpczRQroiIlJpXXfddTRo0ICff/6ZmJgY6tWrl2u5nDCVE66uVKNGjYrkOEUpLCyMsLCw0q5GmaSeJRERqbRMJhNjxozBbrcza9asXMvs2LGD9evX07ZtW5o0acKrr75Kz549qV27Nj4+PtSuXZuRI0eyf//+fD9vXmOWEhMTeeCBBwgPD8ff359OnTrxzTff5HmcmTNnMmTIENq2bYu/vz+hoaH079+fFStWuJSbPHkyvXv3BmDKlCmYTCbn7dChQ84yeY1ZWrhwIb179yY4OBg/Pz+ioqKYNm0aWVlZLuUOHTqEyWRi9OjR7Nu3j5tvvpmqVasSEBBAdHQ0f/zxR75fo7JEPUsiIlIyko9B4n4IbQTBEaVdG6fRo0czefJkZs+ezcSJEzGZTC6P54Soe+65h127djFx4kR69+7NzTffTEBAALt37+azzz5j0aJFbN68mcjIyELVIy0tjV69erFt2za6detGz549OXLkCMOGDaNfv3657vPwww8TFRVFr169qF27NsePH+fbb78lOjqa+fPnM3jwYAB69erFoUOH+Pjjj+nZsye9evVyHiMkJMRjvaZNm8bjjz9OaGgow4cPJyAggO+++47HH3+cX375hfnz57u9ZocOHaJr1660atWKu+++m/3797NgwQJ69+7Nrl27CA8PL9RrVFoUlkREJHeGAba0ojnW1s/gx6fAsIPJDDe8Bu2GF82xLb5XtHvdunXp168fixcv5ueff6ZPnz7Ox7KyspgzZw5Wq5W77roLi8VCbGwsoaGhLsdYsWIF0dHR/Otf/+Kjjz4qVD1ee+01tm3bxtixY/m///s/5/YRI0Zw/fXX57rPzp07iYyMJCUlhaCgIMxmM7GxsVx11VU8+eSTLmEJ4OOPP6ZXr175HuS9f/9+nn76aWrUqMHGjRupW7cuAC+99BLR0dF8++23zJkzhxEjRrjst2rVKl555RWefvpp57bnn3+ef/3rX8yaNYtnnnkmvy9LmaCwJCIiubOlwcu1i/64hh1+eMJxKwrPHL3iQ9xzzz0sXryYmTNnuoSl77//nvj4eIYOHeoWkC7Wu3dvWrVqxbJlywpdh08++QQfHx9eeOEFl+39+/enT58+uQ4Ib9CgAXa73WVbrVq1uPXWW3nnnXc4fPhwoXu6AD777DOysrJ4/PHHnUEJwGq18uqrr3L11Vcze/Zst7DUoEEDnnzySZdt99xzD//617/YsGFDoetTWjRmSUREKr3BgwdTvXp1vvnmG5KTk53bcxvYvXLlSoYMGUKtWrXw9vZ2jv3Ztm0bx48fL9Tzp6SkcPDgQRo3bkzNmjXdHr/22mtz3e/AgQPcd999tG/fHn9/f2dd3nnnHYBC1yfHli1bAFxO2+Xo1q0bvr6+bN261e2xdu3aYTa7Row6deoAkJSUdEV1Kg3qWRIRkdx5+8OzV/ZlC0DKcXi3s6NHKYfJAg+vg6Ai6Lmy+EL6mSs6hLe3NyNGjGDatGl89tlnPPjgg8TFxfHjjz9Sr149oqOjAfjyyy8ZNmwYgYGB9O/fn/r16ztDyuzZszl8+HChnj8lJQWAGjVq5Pp4bmN89u3bR+fOnUlJSeHaa6/lpptuIjg4GLPZzMqVK1m1ahUZGRmFqs+l9crt+U0mE+Hh4Rw7dsztsaCgILdtXl6OyJGdnX1FdSoNZTIsvfvuu7z++uvExcURFRXFO++8k+e8DzabjalTp/Lxxx9z7NgxmjVrxquvvprn+V0REcknkwl8Aq78OGFNYNC/YeFjYGQ7gtKg6Y7tReGS01CFdc899zBt2jRmzJjBgw8+yKeffkpWVhZjxoxx9pJMnjwZX19fNm3aRJMmrvX/4osvCv3cOeEiISEh18fj4+Pdtr311lucPn2ajz/+mJtuusk5ZgnggQceYNWqVYWuz6X1io+PdzudZxgG8fHxuQajiqbMnYabO3cu48ePZ9KkSWzevJmoqCj69++f5wfoueee48MPP+Sdd95h586dPPDAA9x8883OrkMRESkDOoyEx7bBqO8d/3YYWdo1ctOyZUu6du3Kpk2b+PPPP5k1a5ZzaoEc+/fvp0WLFm5BKTY2lgMHDhT6uYOCgmjQoAH79u0jLi7O7fFffvnFbVvOVAU5g7hzGIbBb7/95lbeYrEABevZad++PUCu0wmsW7eO9PR02rVrl+/jlVdlLixNmzaNsWPHMmbMGFq2bMkHH3yAv79/nrOrfvrppzz77LMMGDCAhg0b8uCDDzJgwADefPPNEq65iIh4FBwBDa4tU9MGXCpnbNJDDz3Erl27iI6OdulRiYyMZN++fS49Penp6Tz44IPYbLYreu4RI0aQmZnJxIkTXbb/9NNPuQ7uzqnXr7/+6rL9lVdeYfv27W7lcwaoHzlyJN91Gj58OF5eXkybNs1l/FNmZqbzSrfRo0fn+3jlVZk6DZeZmcmmTZuYMGGCc5vZbCY6Opq1a9fmuk9GRga+vq6Xjfr5+bl9eERERC5n2LBhPPbYY86emUtn7H7kkUd45JFHaN++PbfddhtZWVksXboUwzCIioq6okkXn3rqKebPn89HH33Ejh076NGjB0eOHGHevHkMHDiQRYsWuZR/4IEHmDVrFrfffjtDhgyhZs2arFu3js2bN+davnnz5tSuXZsvvvgCq9VKnTp1MJlMPPLIIwQHB+dap0aNGvHqq6/y+OOP07ZtW4YOHUpAQAALFy5kz549DB48mLvuuqvQbS4vylRYOnnyJNnZ2W4DycLDw9m9e3eu+/Tv359p06bRo0cPGjVqxPLly5k/f77HbsaMjAyXQW85A9hsNtsV/8+gtOXUv7y3o7Aqc/src9tB7S9s+202G4ZhYLfb3S5BLy8Mw3D+e6VtCAgI4Pbbb2f27NmEhoZy0003uRzzwQcfxGKx8O677/LRRx8REhLCgAEDePnllxk2bBiAS/mcn/N6fS/e5ufnx4oVK3j22Wf59ttv2bx5M61ateLzzz8nOTmZRYsWuRwnKiqKxYsX8/zzz/P9999jsVjo1q0bv/zyCwsXLnQrbzKZ+Oqrr5gwYQKff/45Z844BsUPHz6cKlWqOF/HS+v62GOP0bBhQ6ZPn86cOXPIzMykadOmvPHGGzzyyCMYhuGyb37ei/y8T3a7HcMwsNlszlOIlyqp33eTkdPCMuD48eNERESwZs0aunXr5tz+1FNPsWrVKtatW+e2z4kTJxg7diwLFy7EZDLRqFEjoqOjmTlzZp4rQ0+ePJkpU6a4bf/ss8/w9/cvugaJiJRxXl5e1KxZk7p16+Lj41Pa1RFxyszM5MiRI8TFxbktq5IjLS2N4cOHk5ycXKwDzctUz1JYWBgWi8Vt1H98fHyu804AVK9enW+//Zb09HROnTpF7dq1eeaZZ2jYsGGezzNhwgTGjx/vvJ+SkuKcwbW8j+q32WwsXbqUvn374u3tXdrVKXGVuf2Vue2g9he2/enp6Rw5coTAwEC3IQ3lhWEYnDlzhipVqrgtu1EZVNT2p6en4+fnR48ePfL8bJ46dapE6lKmwpKPjw8dO3Zk+fLlDBkyBHB0wy1fvpxx48Z53NfX15eIiAhsNhtff/01Q4cOzbOs1WrFarW6bff29q4wf2QrUlsKozK3vzK3HdT+grY/Ozsbk8mE2Wx2m0SwvLj4NFN5bcOVqKjtN5vNmEwmj5/pkvpdL1NhCWD8+PGMGjWKq666is6dOzN9+nRSU1Odl26OHDmSiIgIpk6dCjguXTx27Bjt2rXj2LFjTJ48GbvdzlNPPVWazRAREZEKosyFpWHDhnHixAkmTpxIXFwc7dq1Y/Hixc5B3zExMS7JOT09neeee44DBw4QGBjIgAED+PTTTy+7irKIiIhIfpS5sAQwbty4PE+7XToxVs+ePdm5c2cJ1EpEREQqo4pzcrMIxCXnfvWciIiIVF4KSxfp99Zq5m6IKe1qiIiUuDI0i4wIULY+kwpLF7Eb8Oz87cSqh0lEKomcyf4q62SeUnblfCbzmpCyJCksXSLbMDh0Mq20qyEiUiK8vb2xWq0kJyeXqf/JS+VmGAbJyclYrdYyMRVImRzgXZosJhP1wzSLt4hUHmFhYRw7doyjR48SHByMt7d3uZrc0G63k5mZSXp6eoWaZyi/KlL7c5Y3SU5O5uzZs0RElI1FlxWWLvHyLa2pFexX2tUQESkxOSsXnDx5kmPHjpVybQrOMAzOnTuHn59fuQp5RaUitt9qtRIREVFmVtVQWLqI1dvM7R3rlnY1RERKXFBQEEFBQdhsNo8LkZdFNpuN1atX06NHjzJxyqakVbT2WyyWMtcOhaWLZNjsxCSmUT8soLSrIiJSKsrjcjEWi4WsrCx8fX3LXd2LQmVvf0ko3yc3i8Gu2JTSroKIiIiUIQpLl1BYEhERkYspLF2kU/2qRFTV4G4RERG5QGOWLjJrTOcyM/JeREREygb1LImIiIh4oLB0iTPpNs6ka9p/ERERcVBYusikBdtpM/knvtp0tLSrIiIiImWEwtJFqgdaAV0RJyIiIhcoLF2kWc0qAOyKPVPKNREREZGyQmHpIk3Ph6U98WfIyraXcm1ERESkLFBYukjdqv4E+FjIzLJz4GRqaVdHREREygCFpYuYzSaa13LMs6RxSyIiIgIKS25a1HKcitupsCQiIiJoBm831zapTla2QafI0NKuioiIiJQBCkuX6N+qJv1b1SztaoiIiEgZodNwIiIiIh4oLOUiIyub7ceSiUtOL+2qiIiISClTWMrF+Hl/cOM7v/LdH8dKuyoiIiJSyhSWctHi/OSUO4/rijgREZHKTmEpFy2ccy1p2RMREZHKTmEpFzlhaf+Js2RkZZdybURERKQ0KSzlolawL8F+3mTZDfbGny3t6oiIiEgpUljKhclk0kzeIiIiAigs5amF1ogTERERNIN3nvq3qkmNKr50a1SttKsiIiIipUhhKQ9dG1aja0MFJRERkcpOp+FEREREPFBY8uBIYhqL/oxlX4KuiBMREamsFJY8ePOnPTz82WYWb48t7aqIiIhIKVFY8kAzeYuIiIjCkgcta2v6ABERkcpOYcmDnJ6lg6dSScvMKuXaiIiISGlQWPIgLNBK9SpWDAN2x+lUnIiISGWksHQZmslbRESkclNYuoycNeIUlkRERConzeB9GUPaRdCuTght64aUdlVERESkFCgsXUaLWkHOU3EiIiJS+eg0nIiIiIgHCkv5sOlwIu+u2MeWmNOlXRUREREpYQpL+TB3wxFeX7KHFbsTSrsqIiIiUsIUlvIhZ8zSTi17IiIiUukoLOWD5loSERGpvBSW8qFFTUdYOpZ0juRztlKujYiIiJSkMhmW3n33XerXr4+vry9dunRh/fr1HstPnz6dZs2a4efnR926dfnHP/5Benp6kdUn2N+biBA/QL1LIiIilU2ZC0tz585l/PjxTJo0ic2bNxMVFUX//v1JSMh9cPVnn33GM888w6RJk9i1axczZsxg7ty5PPvss0VaL83kLSIiUjmVubA0bdo0xo4dy5gxY2jZsiUffPAB/v7+zJw5M9fya9as4eqrr2b48OHUr1+ffv36ceedd162N6qgcsYt7dYgbxERkUqlTM3gnZmZyaZNm5gwYYJzm9lsJjo6mrVr1+a6T/fu3ZkzZw7r16+nc+fOHDhwgB9++IERI0bk+TwZGRlkZGQ476ekOHqLbDYbNlvuY5JubV+Lfi2q0zAsIM8yZUFO3cpyHYtTZW5/ZW47qP2Vuf2Vue1QudtfUm02GYZhlMgz5cPx48eJiIhgzZo1dOvWzbn9qaeeYtWqVaxbty7X/d5++22eeOIJDMMgKyuLBx54gPfffz/P55k8eTJTpkxx2/7ZZ5/h7+9/5Q0RERGRYpeWlsbw4cNJTk4mKKj4liYrUz1LhbFy5Upefvll3nvvPbp06cK+fft49NFHefHFF3n++edz3WfChAmMHz/eeT8lJYW6devSr1+/Yn2xS4LNZmPp0qX07dsXb2/v0q5OiavM7a/MbQe1vzK3vzK3HSp3+0+dOlUiz1OmwlJYWBgWi4X4+HiX7fHx8dSsWTPXfZ5//nlGjBjBvffeC0CbNm1ITU3lvvvu45///Cdms/uwLKvVitVqddvu7e3t8YP247ZYVuxJ4Ma2tenRtHpBmlbiLteWiq4yt78ytx3U/src/srcdqic7S+p9papAd4+Pj507NiR5cuXO7fZ7XaWL1/uclruYmlpaW6ByGKxAFDUZxh/23+SeRuPsmZ/ySRZERERKX1lqmcJYPz48YwaNYqrrrqKzp07M336dFJTUxkzZgwAI0eOJCIigqlTpwIwaNAgpk2bRvv27Z2n4Z5//nkGDRrkDE1FRTN5i4iIVD5lLiwNGzaMEydOMHHiROLi4mjXrh2LFy8mPDwcgJiYGJeepOeeew6TycRzzz3HsWPHqF69OoMGDeKll14q8ropLImIiFQ+ZS4sAYwbN45x48bl+tjKlStd7nt5eTFp0iQmTZpU7PVqXrMKJhMknMng5NkMwgLdxz2JiIhIxVKmxiyVdf4+XtSvFgCod0lERKSyUFgqIC17IiIiUrkoLBVQi5qOcUvxKRmXKSkiIiIVQZkcs1SWjexenzHXNCDQqpdORESkMtA3fgEF+1WuCb9EREQqO52GExEREfFAYakQPl5ziKEfrGXhH8dLuyoiIiJSzBSWCuHgyVTWH0pkS0xSaVdFREREipnCUiG0rK2ZvEVERCoLhaVCaJmz7ElcSpEv1isiIiJli8JSITSuEYjFbCIpzUZcSnppV0dERESKkcJSIfh6W2hUXcueiIiIVAYKS4XkPBUXe6aUayIiIiLFSWGpkFrUCqJGFWtpV0NERESKmWbwLqR7r23I/T0blXY1REREpJipZ6mQLGZTaVdBRERESoDCUhGw2zV9gIiISEWlsHQF3vxpD51fWsbnG2JKuyoiIiJSTBSWrkBmlp2EMxmaPkBERKQCU1i6Ai00fYCIiEiFp7B0BXLWiNsdm6JxSyIiIhWUwtIVaBgWgI+XmdTMbI6cTivt6oiIiEgxUFi6Al4WM03DAwEteyIiIlJRKSxdoRY1HafidmrckoiISIWkGbyvUMfIqhw+lUatYN/SroqIiIgUA4WlK3RH53rc0bleaVdDREREiolOw4mIiIh4oLBURFIzsjibkVXa1RAREZEiprBUBCbM/5PWk5fw1cYjpV0VERERKWIKS0UgLNCKYWgmbxERkYpIYakIOJc9idNcSyIiIhWNwlIRyAlLe+LOkJVtL+XaiIiISFEqcFh64YUXWL16tcu2hIQE/vzzz1zLz507l1tuuaVwtSsnIkP98fexkJFl59Cp1NKujoiIiBShAoelyZMns3LlSpdt77//Pu3bt8+1/O7du1mwYEGhKldemM0mmtesAsCO4zoVJyIiUpHoNFwRcY5b0iBvERGRCkUzeBeRa5uEkZllp0O9kNKuioiIiBQhhaUicn3rWlzfulZpV0NERESKmE7DiYiIiHigsFSEMrPs7IpNIT4lvbSrIiIiIkWkUKfhtm/fzrx581zuA3z55ZcYhuFWtrL4x9ytLNoWy7MDmnNfj0alXR0REREpAoUKS19//TVff/21835OQLrjjjvcyhqGgclkKmT1ypdmNauwaFusrogTERGpQAocliZNmlQc9agQWjqnD9BcSyIiIhWFwlIRalHbEZb2JZwlIysbq5ellGskIiIiV0oDvItQ7WBfgny9yLIb7Es4W9rVERERkSJQ5PMsbd26lRUrVgBwzTXX0KlTp6J+ijLLZDLRolYQ6w4msiv2DK1qB5d2lUREROQKFbhnafXq1YwcOZLff//d7bHnnnuOjh078sQTT/DEE0/QtWtXHnnkkSKpaHnRQuOWREREKpQCh6W5c+fy5Zdf0rJlS5ftK1as4OWXX8ZisTBixAgefPBBwsLCeO+99/j222+Lqr5lXr9W4TzZvxkD22o2bxERkYqgwGFp7dq1dO/enaCgIJftH374ISaTiQ8++IDZs2fzn//8h99++w1vb29mz55dVPUt87o3CuPh3o3pUK9qaVdFREREikCBw9Lx48eJiopy275ixQqCgoIYPXq0c1vjxo0ZMGAAGzduvKJKioiIiJSWAoel06dP4+fn57ItJiaGEydOcM0112A2ux6ycePGnDx58spqWc4cSzrH4u2x7D+hK+JERETKuwKHpSpVqnDs2DGXbRs2bACgY8eObuVNJhO+vr6FrF759Nri3TwwZzOLt8eVdlVERETkChU4LLVt25bvv/+e1NRU57ZvvvkGk8lEjx493Mrv37+f2rVrF7hi7777LvXr18fX15cuXbqwfv36PMv26tULk8nkdhs4cGCBn7co5FwRt1NXxImIiJR7BQ5Ld999N4mJifTs2ZO3336bcePG8fnnn1OvXj169erlUjY7O5vVq1fTpk2bAj3H3LlzGT9+PJMmTWLz5s1ERUXRv39/EhISci0/f/58YmNjnbft27djsVi4/fbbC9q8IuGcPuC4wpKIiEh5V+BJKe+66y6WL1/Oxx9/zJYtWzAMg6CgIGbMmOE2XmnRokWcPHmS/v37F+g5pk2bxtixYxkzZgwAH3zwAYsWLWLmzJk888wzbuVDQ0Nd7n/xxRf4+/uXWljKWSPu4KlU0jKz8Pcp8rk/RUREpIQU6lt81qxZ3HPPPaxdu5Zq1arRv39/IiIi3MpZrVbeeustBg8enO9jZ2ZmsmnTJiZMmODcZjabiY6OZu3atfk6xowZM7jjjjsICAjI9fGMjAwyMjKc91NSHD1ANpsNm82W77rmJcTXTFigDyfPZrLj6Gna1Q254mPmV079i6Id5VFlbn9lbjuo/ZW5/ZW57VC5219SbTYZhmGUyDPl0/Hjx4mIiGDNmjV069bNuf2pp55i1apVrFu3zuP+69evp0uXLqxbt47OnTvnWmby5MlMmTLFbftnn32Gv7//lTXgvPd3mtmdbGZYw2y6h5epl1hERKRCSEtLY/jw4SQnJ7vN/1iUKtz5oRkzZtCmTZs8gxLAhAkTGD9+vPN+SkoKdevWpV+/fkX2Ym+z/MXuXw/hFVafAQNaFMkx88Nms7F06VL69u2Lt7d3iT1vWVGZ21+Z2w5qf2Vuf2VuO1Tu9p86dapEnqfAYemTTz4p1BONHDkyX+XCwsKwWCzEx8e7bI+Pj6dmzZoe901NTeWLL77ghRde8FjOarVitVrdtnt7exfZB+3mDnVoV68qUXVCSuXDW5RtKY8qc/src9tB7a/M7a/MbYfK2f6Sam+Bw9Lo0aMxmUwAGIbh/DkvOWXyG5Z8fHzo2LEjy5cvZ8iQIQDY7XaWL1/OuHHjPO775ZdfkpGRwV133ZWv5ypOrWoH06p2cGlXQ0RERK5QoU7DeXl5MWDAALp27VrU9QFg/PjxjBo1iquuuorOnTszffp0UlNTnVfHjRw5koiICKZOneqy34wZMxgyZAjVqlUrlnqJiIhI5VPgsHT77bfz3Xff8d1337F3717GjBnDyJEjqV69epFVatiwYZw4cYKJEycSFxdHu3btWLx4MeHh4YBjeZVLpynYs2cPv/76Kz/99FOR1eNKbY45zfqDiXRrWI2oErwiTkRERIpOgSelnDt3LsePH+ett97Cx8eHJ598kjp16nDrrbeyaNEi7HZ7kVRs3LhxHD58mIyMDNatW0eXLl2cj61cuZLZs2e7lG/WrBmGYdC3b98ief6i8Nm6GF75cTfLd+c+maaIiIiUfQUOSwBVq1bl73//O5s3b2bjxo3ce++9rFy5kptuuom6devy7LPPsnfv3qKua7mTMznlLi17IiIiUm4VKixdrEOHDrz77rscP36cOXPm0KpVK1577TVatGhRpk6JlYYWCksiIiLl3hWHpRxWq5VevXrRq1cvwsPDsdvtpKenF9Xhy6WcnqWjp8+Rkl75ZlYVERGpCK44LGVlZfH1118zcOBA6tWrx3PPPUedOnV4//33iY6OLoo6llvB/t7UDvYFYHfsmVKujYiIiBRGoWfw3rZtGzNmzOCzzz7j5MmThIWF8cgjj3D33XfTunXroqxjudaydhDHk9PZFZtC5wahl99BREREypQCh6X33nuPmTNnsmXLFsxmM/369eOee+7hpptuwsurwq2ecsVa1Api2a4Edh7XuCUREZHyqMDpZty4cXh7ezNo0CBGjRpFREQEAJs3b/a4n6e12iqyoVfVpX+rmjSuEVjaVREREZFCKFRXkM1mY+HChSxcuDDf+2RnZxfmqcq9uqH+1C3tSoiIiEihFTgsjRo1qjjqISIiIlImFTgszZo1qzjqUf4kH4PE/RDaCIIjPBZdvD2OVX8lMKBNLa5tUnTLwoiIiEjxK7J5lvJy8OBBRo8eXdxPU7I2fwLTW8PHgxz/bv7EY/HVe0/w+foj/LbvVAlVUERERIpKsYWlmJgYxo4dS/Pmzfn000+L62lKXvIxWPgoGOfXwDPssPAxx/Y8aCZvERGR8qtQYenXX3+ld+/eBAUFERoayuDBg9mzZw8AaWlpjB8/nqZNmzJjxgyqV6/O22+/XaSVLlWJ+y8EpRxGNiQeyHOXlrWqAApLIiIi5VGBxyxt2rSJ6OhoMjMzndsWLlzIxo0b+eWXX7jpppvYuXMntWvX5umnn+a+++7DarUWaaVLVWgjMJldA5PJDKEN89ylWU1Hz1LCmQxOnc2gWmAFej1EREQquAL3LL322mtkZmYydepUEhISSEhI4KWXXiI2NpZrr72W3bt389xzz7Fv3z4eeeSRihWUwDGYe9C/wWS5sM3bD8x5585AqxeR1fwB+HrTUWKTzxV3LUVERKSIFDgs/fbbb1x33XU8/fTThIWFERYWxoQJE+jduzdxcXG89tprvPDCC/j6+hZHfcuGDiPhsW1w1zcQ1hwyU+G7R8Aw8tylitURpl7+cTdXv/IzczfElFRtRURE5AoUOCwlJCTQsWNHt+052yrNPEzBEdD4Orh9FlissHcJbMp9WoXY5HPsuGi5E7sBz87frh4mERGRcqDAYSkrK4uAgAC37TnbqlWrduW1Kk/CW0L0JMfPS/4JJ/e5FTl4MpVL+5yyDYNDJ9OKv34iIiJyRYp9nqVKocuD0KAn2NLgm/sg2+bycIOwAMwm113MJgjwsSAiIiJlW6HWhpszZw6///67y7Z9+xw9KgMGDHArbzKZWLRoUWGeqnwwm2HI+/B+Nzi2CVa/Ab0nOB+uFezH1Fva8Oz87WQbBmYTeJlN3PPJRj64qyMdI6uWYuVFRETEk0KFpX379jnD0aUWL17sts1kMuVSsoIJjoCB0+Dre2D169CkL9S5yvnwsE716NG0OodOpuFtMfHPb7azJ/4Md/7f7/zr5tYMvUrL7YqIiJRFBQ5LBw8eLI56VAxtboM9P8L2r2D+ffDAL+BzYXxXrWA/agX7ATD/oe6Mn7eVJTvieeqrP9kVm8I/B7TAy6IzoyIiImVJgcNSZGRkcdSj4hj4BsSsdcz0veSfMGh6rsUCrF68/7eOvP3zXqYv28us3w7xV/wZ/nNnB6oG+JRsnUVERCRP6sYoan5VHeOXwDGVwB7305I5zGYTj0U35YO7OuLvY+G3faf4ZO3hEqqoiIiI5IfCUnFo2BO6jXP8/N04OHvCY/HrW9dk/kPdGXpVHR7u3agEKigiIiL5pbBUXK57Hmq0hNQTsPBRj7N7AzSvGcRrt0U5xyzZsu3M23gEu93zfiIiIlK8FJaKi7cv3PJ/YPGBPYtgy6cF2n3Kwh089dWfPPzZZlIzsoqpkiIiInI5CkvFqWYbuO45x88/PgOJB/K9a9uIEHwsZn7cHset76/hSKJm+xYRESkNCkvFrds4iLwGbKkw/37Izl8v0dBOdfn8vq6EBVrZHXeGm/7zK2v2nyzmyoqIiMilFJaKm9kCN78P1iA4uh5+fSvfu3aMrMrCR66mbZ1gTqfZGDFjPR+vOYRxmfFPIiIiUnQUlkpCSD0Y8Ibj51WvwLHN+d61VrAf8+7vxs3tI8i2G7y+ZA8JZzKKqaIiIiJyqUItdyKF0HYo/PUj7PjGMbv3/avBxz9fu/p6W5g2NIqWtYJoEBZAeJBvMVdWREREcqhnqaSYTI6146rUglN7YenEAu5uYmyPhkS3DHduW38wkT+PJhVxRUVERORiCkslyT8Uhrzn+HnDR7B3WaEPdSQxjfs/3cjtH6zlmy1Hi6iCIiIicimFpZLW6Dro8oDj5wUPQeqpQh0mxN+bDvWqkpFl5x9z/+DlH3aRrQksRUREipzCUmmIngzVm8PZePj+8rN756aKrzf/N/Iq5/Io/7f6AHfP3sBf8WfYm2wiNjm9iCstIiJSOSkslQZvP8fs3mZv2LUQ/vi8UIexmE082b8579zZHl9vM6v+OsHA/6zlPzst9HpzNXM3xBRxxUVERCofhaXSUisKek9w/PzDU3D6UKEPNSiqNh/c1dFlm92AZ+dvJzb53BVUUkRERBSWStPVj0G9bpB5Br55AOzZhT6Uj5f7W5ltGMz45SD3fryB+ZuPkpJuu4LKioiIVE6aZ6k0mS1w8wfw/jUQsxZ++zdcO75Qh2oQFoDZ5OhRymExmdh46DRbjyaxbFcCPhYz1zYJY0CbWkS3DCfYz7uIGiIiIlJxqWeptFWtDze86vh5xcsQ+0ehDlMr2I+pt7TBbHLcN5vg5Vta8+ptbfl7nyY0rhFIZrad5bsTePzLP7jqX0t54NNNWjpFRETkMtSzVBa0G+6Y3XvXQsfs3vetdAwCL6BhnerRrUFV5v2wgqEDelMvrAoAzWpWYXzfpvwVf4ZFf8byw7ZY9iacJTPbjslkcu6/dGc8neuHEuyvHicREZEcCktlgckEN/4bjqyHE7th2RS44ZVCHapWsC9Ngg1qBbsvidI0vApN+1bhH32bsjf+DJnZdudjR0+nMfaTjXhbTFzd2HGqrl/LcEL8fQrdLBERkYpAp+HKioBqMPhdx8/r3of9Pxfr0zUJr0Kr2sGOO8nHSN2zgqurZ2DLNli55wRPffUnV/1rGSNnrmfuhhiS0jJd9o9NPsea/Sd1tZ2IiFR46lkqS5r0hU73wob/wrcPwYNrHEukFDW7HdJOQsox2PI/2PBfmmHwP5OZ+OtfY252L37YFsvuuDOs/usEq/86gZ+PFzdF1QZg7oYYJszfht1wjI2aeksbhnWqV/T1FBERKQMUlsqavi/CgVWOxXa/fRC6PgTVGkNwRP72Nwx8bCmOgeJp8ZB8zBGKUo5BynFIPgpnYiE7M5d97YSvepK/j9vE3/v0YP+Js/zwZyzLdsXTp3kNwNGj9MzX28gZFm43YML8bfRoWp1awQUfZyUiIlLWKSyVNT7+jtm9/9sH/lrsuJnMMOjf0H4EpJ1yBJ+LQ1Dy+SCUchSvlOPckJ0J2y/3RCbwDYH0066bDQM+7Ald7qdR57E80qcJj/Rp4nz44MlULr1+zm7AnR/9To8m1elQryo3tq2Fl0VneEVEpGJQWCqLAsNd14sz7PDdI/D942DPpUfoIibAwASBNTAFRTh6pIJybrUhuI7j3yq14GwCTG/tOP7FMs/AL2845n1qfSt0e8gx4zi5z+cEcOhkGodOHmbRn7EMblfbuX3x9lhC/H1oWycYfx993EREpPzRt1dZlLgf3PpvuBCUAsMdgScnBF0UiGz+Nfjx163ccONNeHtfZgqA4AhHj9XCx8DIBpMFBk4D/6qw9j048jv8+YXjFnk1dH2IWs1uYOotbXh2/nayDQOLCZ68vjkRIX5siUnC28vknI7AMAwmLthBwpkMLGYTzWtWoX29EDrUq0qHelWJrObvMnWBXCL5mOOzENoo/6dhRUSkyCkslUWhjRyn3i7u8TGZYcxiqN0evDxczm+zYZgvew7ugg4joVEfSDwAoQ0vfCm3HAzHNjlC085v4fBvjlvVBgzr8gA9x9/KwRQz9cP8nWOVBkXVdjl0us1Op/qhbI45TWxyOjuOp7DjeApzfncs8NujaXU+ubvzReWz8fW2OO/HJp/j4MlUGoQFVL7xUGvfgyXPAobjve/xFETdAT4Bjpu3v2PKiStVkQJZynHCzuyElHZQLbK0ayMiFUiZDEvvvvsur7/+OnFxcURFRfHOO+/QuXPnPMsnJSXxz3/+k/nz55OYmEhkZCTTp09nwIABJVjrIpRbj8+g6VCvS/E9X25flBEd4bYZkPwCbPgINs6C0wdh8dPUtL5EzQ4jIfQ+IPcvJj8fC+/+rQPgCD5bYpLYfPg0m2NOs/1YCo2rBzrLpmZk0f6FpTSqEUiHeiFkZtv5etPRynHFnWE4wmrM745lbw796nidnY/bYdUrjpuTyRGYfAIc49x8ArF4+9MtOQ3LV3PBGnhRsApwKecMW4d+cZxqNewXxsV1GFnizS8Smz/Ba+GjXG3YMf7zWvlui4iUOWUuLM2dO5fx48fzwQcf0KVLF6ZPn07//v3Zs2cPNWrUcCufmZlJ3759qVGjBl999RUREREcPnyYkJCQkq98Ucqrx6c0BEdA9GTo8ST88Tn8/j6c2gdr/wO/vwctBkHXh6Fu5zx7O2oF+1GrjR8D2tQCICMrm/TMCz1nO2NTyMy2sys2hV2xKS772g145qIr7pLP2Vi2M57wIF9qBFkJr+JLkJ9X+Tmll22DuD8vhKOYdZCacPn9LL6QnX7+jgG2VMct1bHFDNQA2FOAnsUcht0Rzhv1KX89TMnH4Lu/Yzp/6tpk2GHho9DoOscYPRGRK1TmwtK0adMYO3YsY8aMAeCDDz5g0aJFzJw5k2eeecat/MyZM0lMTGTNmjXOMTr169cvySoXn7x6fEqLT4BjHqiOd8O+ZfD7u3BgJexc4LjV7gDdHnacwrN4Hi9l9bJg9bpwyq1T/VDWPduHLTGn+f7PWL7/M9alvGE4BpHXCvZj/4mzPP7lH5ccz0yNICs1Aq209DGR06d4NiOLrTFJeYaqEjnVl54CRzc4wtGR3+HoRrCluZax+Dh68up1hWpN4Ltxl5yGtcDfNzsG5medg8zUCzdbGmSeJSsthT82rqFdi8ZYstOd28lMO1/27PltqY7B/Rf3XoGjF/Pk3rL1mbucrAz44QncxvgZdvhvX+hyv2M5oUD3/2iJiORXmQpLmZmZbNq0iQkTJji3mc1moqOjWbt2ba77fPfdd3Tr1o2HH36YBQsWUL16dYYPH87TTz+NxWLJdR+5QmYzNO3nuMXvcPQu/fklHN8MX98DSydC57HQYVSBJtUMD/Ll+ta1iKobwg/bYl2uuDOboH6YPwBeZhPXNA4jPiWdhDMZJJ+zkZFl50jiOY4kniOy/oX99sSd4a4Z65z3fbzMhAdZqVHFl8ysbLYfT8E4f6rvX0Nac1O7CAKtV/hrkXL8fI/R745b/Hb3Kw59Q6BeN8ep1XrdoFY78L5oiRoj2/00bE6IyTm9dgnDZuPoARNtOw7AcrnB/cnHcr8ScsVLEN6yfISL5KMwbxQc25j742eOw7JJ8POL0PR6x+excR8w6++CiBRMmQpLJ0+eJDs7m/DwcJft4eHh7N69O9d9Dhw4wM8//8zf/vY3fvjhB/bt28dDDz2EzWZj0qRJue6TkZFBRkaG835KiuO0j81mw2azFVFrSkdO/UusHaFNYcB06PlPzJtnY940E1PKMVg2GWPVa9jbDMPe+T7wDsCUuB8jtJHjSj4Pwvy9+Nfgljy3YKdzzNK/BrckzN8Lm81Gi/AAZo3q4CyfbsvmxNkMElIyiE1K4+S+P5ztz7TZaFIj4HyoyiLzolB1MbsBz327nWe/2U5YoA+Rof7UC/WjXqg/kdX8iQz1p0FYAFV8vSDl+IW2VKkJJ/ZgPvI7pqPrMR1Zhyk5xq1NRkgkRt0u2Ot0wajbFcKaOMYJXezi96zNnRDZE9PpAxhVGzpes8u8pwV67/1rYBowDcsPj2MysjFMZjB7YTq6HuODa8i+ZSZG3WIaI1cETAdXYfn2PkxppzB8Q7C3GYp544zzbbGQ3e9l8PLFvHUO5mMbYPf3sPt7jCq1sUfdiT3qbxBSscbAlfjvfhlSmdsOlbv9JdVmk2EYuVyjXjqOHz9OREQEa9asoVu3bs7tTz31FKtWrWLdunVu+zRt2pT09HQOHjzo7EmaNm0ar7/+OrGxsW7lASZPnsyUKVPctn/22Wf4+/sXUWsqJ7PdRsTp32mUsJjg9CPO7QYX5oDaWnc0MWG9L3uspAw4kW6iuq9BiPXK65aZDWdskGKD3UkmFh8tWA/D7ZHnGGP+gRax8zFhYAA2fPDBde4rAxPJfpGcCmxKYkBTEgObEGevWqRtKSq+mYkEZMSTag3Hy36OzgffoUr6cexY2BExjAPV+xfNVXdFxbDTNP57msd+jQmDJL/6bGjwCGnW6i5tSfe50KNZ5dxRIk+tom7ir/hkOwZ4GZg4UaUVh6v1Ii64PXbzZXriRKRMSktLY/jw4SQnJxMUFFRsz1OmwlJmZib+/v589dVXDBkyxLl91KhRJCUlsWDBArd9evbsibe3N8uWLXNu+/HHHxkwYAAZGRn4+LhfZp9bz1LdunU5efJksb7YJcFms7F06VL69u17+XmWipNhYDr8C+bf/o3p0Cou/ro1AILrYoQ2hOB6GCH1MILrQkik49/A8EJ/Qee3/bHJ6fR6c7XLqT6Lyc7iMY3g9GHOxO7HduoglpQYAtKOUc0WSw0Scz3WOcOHTfYm/GluwbGgtqRVb8/Q7s25KrIqAF9sOMKkhbtceslu71j0A4+L5L3PPItl0T8w7/wGAHuLwWQPnA7WKkVX0cI6l4Tlu4cw7/sJAHu7u8ju/wp4OU5fXrb9WRmY/vrB0dt0cJVzs+FfDXubodjbjYCwpiXSlOJQZn73S0FlbjtU7vafOnWKWrVqFXtYKlOn4Xx8fOjYsSPLly93hiW73c7y5csZN25crvtcffXVfPbZZ9jtdsxmx2mNv/76i1q1auUalACsVitWq/t/7729vSvMB61MtKVJH/DyhkOrXDabAJKPYEo+kutuePlCcF3HaZKqkY5/QyLP3+pBQFjeYer8XDve59rh7Z/LlAbpyXD6EPVOH2Z+1Fa27fiTuiRQ13SC+l4nsXzmeYb03DzlPYGFZ5s57pwATpxhwFUG3t7exCafY+J3u1zW0nv2252s3ptIrRBfQvx8uDGqFo3OT6OQkm4jOc1GiL83gdaCXeEXm5zO3mQT7dOyqRdWyB5S76pw+yxY3w2WPIt51wLMJ3bB0E+hRvPCHbMoxP4Bc0dA0mGwWGHgm5g7jCC3RXXy/Ox7e0PUUMct8SBsmQNb/4fpTCyWde9jWfc+1O3quBK11ZBcx4WVB2Xid7+UVOa2Q+Vsf0m1t0yFJYDx48czatQorrrqKjp37sz06dNJTU11Xh03cuRIIiIimDp1KgAPPvgg//nPf3j00Ud55JFH2Lt3Ly+//DJ///vfS7MZkiOvCTZvm+W4MispBk4fdvybdNix1l1WumMh4VN7cz+mt/9FAarehVAVtw2vX950zLXzzqvQdqhjTNHpw3D6kOOWnuQ8TDug3cVn4uw4BlOHOHq5qFrfcdyq9R03ixU+vNbtKrV3HhnG6/41OZKYxqFTaRw+lUqbiGAg97X0ABbviHP+3KZOkDMs/bQjnifOX+nnZTYR4u9NiL8PIX6Ofx/s1YiO53usjp5O48+jyYT4e7PuQCLv/LwXu2HhvV2rr2xeKpPJcRVZrXbw5Wg4+Rd8dB0Mfsex/E1J2zIHFj3u+FyERMKwT53L7xRaaAPo8zz0muC4snPzJ451GI+cv2Lxx6ehzW2O4FS7fdk6FSkiJa7MhaVhw4Zx4sQJJk6cSFxcHO3atWPx4sXOQd8xMTHOHiSAunXrsmTJEv7xj3/Qtm1bIiIiePTRR3n66adLqwlysbwm2Gw1JPfy2TZHYLo4QCXFXAhVZ2IdIevEbsftEibnvwb8OTf35wio7h6Gcu4HRYDFw69Fbm0JjsAXaBJehSbhrqercltLz2SCh3o2wg4kpWUSWe1CD0ZGVjZWLzMZWXay7AYnz2Zy8uyF3q6/dbkQgH4/kOgMVhezG/D019uwmE3c1rEuAPsSzvDTzniqBfgQGmAlNMDH8XOgD1Xy6sGq1wXuXw1f3w0HV8NXd8ORDcR2mcDB07bin1ndlg4/PukIMgBN+sMtH4Jf1aJ7DosXNLvecTsTB1s/czzf6YOwaZbjFt4GOo5yhKfMtIoz43lJzd5ekWaJl0qrzIUlgHHjxuV52m3lypVu27p168bvv/9ezLWSQivIBJsW7ws9ObnJynBcMp4TonJCVdx2OJnLFZMtBkG97heCUUikY3brkmgLjsk4XdfSM/HyLa3z7PX5W5dI/tYlknRbNqfTMjmdaiPpXCZJaTaS0my0qHXhnHyQrxed6lflWNI5jielux3rxJkL4/K2xCTx2uI9uT6nt8XE9GHtGdjWMWHo9mPJfLXpKKEBPo5Q1f592gb8h4jt78O69zm2djn/yPw7J0yhxTez+ulDMG+k4/QbJrjun3DN445pK4pLlZpw7Xi4+jE4/KsjNO38DuK3OeZyWvwM2LMcZSvAjOcsfLRgs7dnZ0F2BmRnQlam4+ecf/Patu9n2PIpzmV7yvNrJpVamQxLUgEV1QSbXlao1shxu1hu8waZLHD9q0X/v9kCtmVYp3r0aFqdQyfTXNbS88TX2+KY9dxD2X6tatKvVU1ik89x9Ss/u81L1afFhSk46lT155YOESSmZrrc0jKzsWUbBFgvnI/cFZvC7DWHLnm2a4k2+zPN+32uMv/FIuuzPGJ7hAnz4fs/Y6kd7EdIgDeh/j5UDfA5/683jaoHEuLvYS3D3Pz1E/avx2LOSCLbLxTLbTMcs3GXFLMZGvRw3G5IhG1fwvr/wqm/LpQx7PDd3yGwJjTpW75O0yUfvRCU4HxbHnHMl2aQdwi6dE6ugirPs8SXJPXElUkKS1IxnD/dZyx8zDnXjuniiRxL2eWCz5Uee+otbZgwf5vLWnpNLzol2K1RNbo1qua2b7otm1OpmYReFGia1azCQ70akZiayamLgtWa5E7cmFmHD7yn09J8mDneL/NG1jA+2HsjRq5DrWH6sHYMae94D1b/dYIpC3cQGuBDVf/ztwAfQgMc47G6RoZQb9vbsPo1zMBWeyMeTnqMvyc2ZlijXA9/xS47g7t/qGP8VvXm8MlNlzxowGe3Q7XG0Po2x2m6sCbFU9ErZbc7Ju/cuQD+nJd78EnYVYADmhz/cbFYHQt7W87fvKwX/rWlOSatvZiR7ZjNvoz8XpY5henxkxKhsCQVR4eRZEX2ZN2Pn9PlhjvxrkQrzw/rVI9uDaoy74cVDB3Qm3ph+bvU39fbQkSIa0hoWyeEtnVC3Mrm9GDdnDmFf3nN5Hav1Tzt/QVDa8aytNlk4jJ8HacO0zI5nZpJYlom1atcuOo0LiWd/SdS2X8i1e3YVUlhSb1PIeE3AD7J6su/su4iE2+e/nobry/ZQ4DVC18vC77eZv7ep4mz52zn8RRmrzmIj8XE8Rgzfy3fh7/VG19vC37eFjo3qErjGo7XI/mcjX0JZ/H1NvPzrgTeWvZX/hZrrtbY/UIFTI5gcGrfhYWOa7Z1hKZWtzguFChN9mw4su78ckTfOWY0z4vJDEPedyynkxN4Lg0/F28ze12+Ny2vWeK/G+cIUlF3lq8eueIW+6ejtzLnkhD1xJUpCktSsQTV5lSVFpedJbwiqhXsS5Ngg1rBvpcvXKjjXxh/9WTW/WwxmvKi9WManFrFfbvudlylVrNdnvtf17wGn4/tyuk0R09VUlomiak2Ak/9wcgjEwlLSCDb4svj5+7mW/s1LvteOtD9bEaW8+eYxDTmbTx6/p6Zn2MPuOz70s2tnWHpz6NJjJix3q1uOYPiT6faeKCXoxvreNI5vlgfQ4i/Y+xWi87/oun65509l9z4FqbWt8DuH2D7V7D/Z8cCyXF/Opb8qdcNWt9KfN3+7E/zL/4B8YDJyMZ0aDXsWQS7Frou0OxTxTGQveVgOBMPPz7leqFC1B1FWxm3izvMEFQHkmPg2wcdIe7G6RBUq2iftzzItjmWQTq6EY6sh6PrHeP0LmVkw77l0FG9S6VNYUlE8s11/FUfLGf/5lif7fRB+G803PiWY+HaXIQFWgkLvGh+M8OAjTNh6zOOsTGhjUgc+F+++6/rzPtmE8wc3Ykqvl6k2+ycy8ymVcSFge6NawTyZP9mpKbb2PXXPmrXjSQz2yA9y066LZvI0AtXG1rMJuqF+pNyzkbSOfdlEk6evTAo/uDJVN7+ed9Fj9anJtOpb47nkD2ckWe685C1CkQN41DEjbz343quzviVDik/UydlC6aYtRCzlmrGU+yxt2KavTvdBo5icNeW2LLt+FjMmM1F0LOSbYODq8jY/BXRu7/Ha+uZC4/5BkOzgY6A1LCX6/qDzW7I94UKhXbpBRGB4bDm37BiqmOqhve6wA2vQdthFbuX6WzChVB0dCMc2+xYEDs/Fj4C2+Y5Tgc3G6C1DUuJwpKIFIjL+KvgDnD/Kpg/1jFf0bcPOk79XP+q6xfzpTLTYNF4+ONzx/3mN8KQ96juG8zUW2Lcrh7s1SzvhX0b1wikcY3G2Gw2fsj8iwEDWuQ5UV33RmGsfqp3noPic8ZXgSPcjegaSWLahV6w06m+bE6rTqbdTojfhXFeR0+fY96ONObRAehAOIncaFnLTZa1RJkP0MOyjR6WbWQsmcnJHb2YcrAFy+0dyDJb8bGY8fE6f7OYua9HQ0Z1rw/A4VOpPPP1Nny8zHhbzFjPl/MzZdHi3Cb6GL9TO+5nSE8i5xrPRCOQIzWuo0aXofg3v46gAP/cp4YoqosuLufS57n2cWh6g+OzErsVvrn/fC/TW44rEsu7bBvEbXOMzTqy3vFv0mH3cr7BUKfThVtER9j1nWtPXK0ox+m5Q784bsH1zi9SPqJop9CQy1JYEpEr4x8Kw7+E1a/DyqmwaTYc3wpDP3FM13CpU/sd0wLEb3d8IURPhu5/d/YsFObqwYLKa0qH1ucnEwXHQPcXh7R229cwDM7ZsjFfFEDqh/kzaVBLTqdmcjrNRmJaLX4/WZ8ZxwdS3xTLILMjODUxHyP82FLe81nKWcOXn+xX8V12N361tSH5/J/j1MwLpxhTzmWx9sApAKxk0tP8B9GW9fQxbybIdKFn4oQRzJLsq/jB3oV19hZkH7HAEYCVeFtMVPX3YUTXSB7p4xiAnpqRxazfDhIaYKVa4Pk5twJ8qBZgJcgv75njLzsgPr/CW8K9y+C36bDyVdjzAxxeAwNehza3l91eptyuVDsT5xqMjm9xTKDqwgQ1WlwIRnU7Q7Um7lNh5DY1SfJR2DDD8XuVHANLn3f8nkXdAZ3vL92Z9SsRhSURuXJmM/R6Gup0hK/vdfQYfNgDbv2v49L6HLsXwTcPQEYKBNSA22ZCg2vdDlecVw/mKGwoM5lM+Pu4/umsU9WfMVc3cNmW03t1yKjFO9m38E72zbQyH+HzbkcJ3LeAwOQj3GL5lVssv5LtW5XkBgM41eAmqjSt7fxSrucVxpc94ql5dAk141fhnX0hIJ31qU5KgxtIjLyBm77Lxn7JFYm+3mbSbXZs2QYJZzKwXdSNFpeSzhs//UVuvMwm7r22Ic/c4PgSPpNu482f/iI26Rw/7Yx3LIptgrHXNGRA21rUDPKl5vlxcjlLjeZrmR6LN/R40nFq6dsHHXNqzR9L+h/z2dZ+EnXq1i/2z0CBXHylGibHzO6pJx0B5lK+IRdCUZ2rHL1GvsHu5XJzaU9ccB2IngQ9n3JMY7HuQ8d/NDbOdNwa9sZ01b1XPrWDeKSwJCJFp3G0Y9bveaPg+Gb43+3Q9UFo3Bd2fw8bZzjK1e0Kt88u9cG9JTGlw4XeKzMjbx5IUKd6YPzL0ROx/SvY8Q2W1BOE7vofobv+B8uDHWESg2Cg08UHDa7rGH/U4iYC63Qi0GzGlHwOFv7MxevqWEwmVjzRi6r+Ps6pH6oGXDhtaPUyM/SqOs7pIU6ddZQ5m5FFlt3Ax+tC8IpPyXCbd8sw4P9+OcD//XKAMVfXZ9KgVs6yXacux8/bgr+PBT8fi8vP/VrW5O5rHKEy3ZbNW8v+wt/bh4BmH3FV4Ce03vcBvvt/pPG+X5icNZrug+9jWOdIDMPgxNkM/M5f4ehlufLJSfPdS5aZ6pjZ/YcnLn4FHJ9vwNFr1BLq5pxS6+y4etJsvvAcGT7UutLrLrz9HD1P7UfAoV9h3QeOHrkDK/A6sII+PjUwVz8GHUfkP5hJviksiUjRCqkHdy+GxRMc4ej39xy3HF0fgr4vOHoWKrg8e69MJsdyMvW6QP+pcGg1bPvaMXYnI9n9QFfdDe3vgtod3E5R5TbP1su3tHY+V+0QP2pfMj1Enar+vHab+/p66bZsElMz8fW+MIg40OrFTVG1+e4P96kHwgJ8XAbtp50/hXjOls05WzZcMktEs4vm/kpJt/HhqouvXOxOc1Md3vR+n1bmw/zb+z8sWbiO+DozCaxWm84vLXeW9LaYHNNInA9jfZpXp935xwzD4KH/bcbX23L+ZnaGLD8fCw3CAjh5NsP5eplMMObqBvRpXgMvswkviwkvewZVj60k7NAi/A8ty3Mwtq3Pi9BxJF5+wW69aXM3xLjNfVYks92bTI7e2AbXOlYw2PARxuZPCExPgKX/hFVTHRdZdL4fwhpf+fMJoLAkIsXBy+oYyLtxJi5dHiYzdBtXKYJSjsv2Xlm8HDOUN7oOWt8Cc25xL9PqFsepnDwUdp6tS/l6W9yCVc1gXyYMaM73fx53GRBvMZlY+PdrXNoWWS2ADf+M5lxmNmm2LM5lZjt+zswmzZZNZKi/s6zVYuGeaxqQlplNui2bI6fT2HgIBme+yEOW73jE6xv6WzZg+7gHGf1exWQKwDAcgcSWbWDLzuLM+SkkTqdmwvlDZ2TZ+XH7hYWqL9WjSRi/7jvpbIthwMxfD/K/X/fQ0/wHN1p+p495MwGmC1dGElzHcWr0os9ylmHm2kUhxC1yzA3WuX4o8x7oBjh6rZ7+epuzbM7UFN9sOUZYoJWG1QMZ37ep8/HF2+OwGwaBVi8Cfb2ocv7fAKsXAT5eWPK6arJqJPT7F0fbPMLur1+mV/ZveJ/eC+v/z3Fr3Be6PgANryvepYIqAYUlESkeiftxCUrgGFeReECT7OWlenP3yS9NFsdg38soznm28hoQf2kItJhNLhORehLs783zN7Z03s8Z45VlePF29i0stXfkDe8PaJVxGO+F93Gg3U1k9H+ddJ9QztmyndNInLNlE+BtYs+GIwCYTSZeHNKa9PMhLKeXK93mmEoi0OrF6r0nAfDBxrXmPxloWUd/yyYCuNCDdJwa7ArtQ5/b7oda7WDLp2QveBSLyU6WYebZrHuI48Ks+Bd3LB086T7xKjgWvwaIqhviEpZe/H4nx5Jy771qWD2Anx/v5bz/6BdbOHk2wxGsrN7EJp9j7f5TGPTDRF9m9Uyl1+n58NcS2LcU9i3FqNYEU5f7HROBWgMLtaRKkQ3uL6cUlkSkeIQ2KvQXf6XlNpHj+Qkjy0C4LO6rFC8NZH9Rn50Dv6FV2jz45Q1Mu77D9/Bv+A58k5BWN7vsa7PZyFkm2sfLzIiuec/eH5uYzLEN3zLAvI5+5o0EmdIuPBgUAa1uhla3UDuiA7UvTkAdRmJp1AcjcT+ENOCFwNpMshtkZRtk2e0uV0c2CAvAbMJtaooJNzTHy2ImxN+1Z7VDZFUiQvw4m5HlvJ1Jt2HLNqhidf2a3njodJ7BysDEPaur8Oszs6nV/zjf/N8U+qT/RNCpvfDDE5z9YSL7vJvS1vYH5ksWN1791wls2XaC/bwJ8fcmyM+bYD9vrF6W4julmIuyGsoUlkSkeJThL/4yLbfLx8uI4r5KMfdANgGaD4BvH3JcBfblaNjxLQx8EwLC8nfgbBscXA075lNr1/fM9E5yPhRnVCWlwUCa9hkFEVd5Pl0VHIEpOAIvPH955tUTl1fAeOfO9rluz8jKJiPL9Sq3l29pw+nUTM5kZLHjWDJfnO9RczbVMDh0Mo1ajRrxlmUMz2XcxK2W1Yy2LKGhOY52tq0XCht2xxV+ja5j6o8H2RWb4lYHXy8z6RfVwW7AM19vY8mOeKr6++DrbXaODfP1shDs783IbvWd5TcdPk1qRtaFMt4W57JFVm8LwX4XgmNJhrKCUlgSkeJThr/4y7SSmjCyDMo1kNWKgrErHHN5/fIm7PzWcUXYwDeh1ZDcD5SdBYd/hR3fONbGO5d44bGAGqQ2uZGDNfpRrWUPmoYE5H6MK1AUPXFWLwtWL9cZu3s2re78OTb5HPM2HnEbS1Y/zDGAa9WTvUjLzCb53ECSUl/g8Mb/ELnlddcnMezwYU9e9GrPb2GtWJPdgt3poaSk2zAMXIKScxfg590JbtvBMZnrxWHp1R93s/5QYq5l/bwt7HrxemdbLh3n9ez87fRoWt3za3cmNu/HipDCkogUr0r8xS9FyMsHrvsnNB/o6GVK2AFfjoKdt0C3Rwk7sxOS2sDZY46AtOs7SD1xYX//MGh5k2OwfGR3AswW3KccLVrF3RN3uSshTSaTY5C41csxcD9wDGx9031OprSTXMVSrmIpjwKE1MOIupZzEVez178dN8855HZK8dE+TfDxspBuyyY9K5uM82PCLp2DLLKaPynpNjLOLz+Ubst2/uzrfaEXL7dxXs5esrxew82f4PXl3wvz0hWYwpKIiJQftdvBfSth9WvwyzTYMR+vHfO5GjD2veJa1i8UWgxyXGUYeY3jysMKpkBXQuZ2avyG16BaI8dyKgd/ccwflRSDaev/8N/6P6KAP6rWY9GZxqzJbsk6oxXjb7km36fHXr/dfYoKcEzxkHVRAsttnNfFvWQApCU6VgBI3O+YKX3dB5guvYikmFS8T46IiFRsXj5w3XMQ0Qk+H0rO0GrnEOtWNzvmpWrQs1JMU1GgKyHzOjXeqLfj34yzEPO7Y+6vg79A7FaqpMVwhyWGOyw/O8qsawrx5+d6qn9t/seOXcRkMuFtuTAoPqeX7F/zN1KPWBqZ4xjbyk6t5Qsc4ejUPjh3usDPU1QUlkREpHzyyeP0zFX35LqMjpzn6dS4NRCaRDtuAOnJcHjt+Z6n1Y5Fgk/+5bjlzMhfo6UjNDW4FiKvdqwXCXlPUWBLh9MHHb1Ep/adD0P7GXZqP8OsF82RlduKPFVqO3rCqtSEbV/hNj1JMVFYEhGR8knTUxQ/32Bodr3jBo5TYYfXXDhtl7ADEnY6bus/BExQs7VjjNiBlTjCjAnqXwNmL0cwSjqCx5DjH+YIRNUaO97Lao0d90Mbgs9Fg/Eb9MD48tFia/rFFJZERKR8Oj8Gx1j4GCYjG8NkwaTpKYqXfyi0uNFxA8diwod+vRCeTu5x9D65MByPX8wa5BqEqjV2hN9qDcGvav7q0mEkWaEd4JU2V9ysy1FYEhGR8qvDSLIie7Lux8/pcsOdeFfLe0JKKQYBYY7pG3KmcDgTD+s/gl9edy/b/e/QbIAjHAVUd1vnsFCqlMxi3FosRkREyreg2pyq0gKCapd2TaRKOFw1xnF69GImC3R5ACK7QWCNoglKJUhhSURERIpOzhQFpvMTalaA2ft1Gk5ERESKVgWbvV9hSURERIpeBZq9X6fhRERERDxQWBIRERHxQGFJRERExAOFJREREREPFJZEREREPFBYEhEREfFAYUlERETEA4UlEREREQ8UlkREREQ8UFgSERER8UBhSURERMQDhSURERERDxSWRERERDxQWBIRERHxQGFJRERExAOFJREREREPFJZEREREPFBYEhEREfFAYUlERETEA4UlEREREQ8UlkREREQ8UFgSERER8UBhSURERMQDhSURERERDxSWRERERDwos2Hp3XffpX79+vj6+tKlSxfWr1+fZ9nZs2djMplcbr6+viVYWxEREamoymRYmjt3LuPHj2fSpEls3ryZqKgo+vfvT0JCQp77BAUFERsb67wdPny4BGssIiIiFVWZDEvTpk1j7NixjBkzhpYtW/LBBx/g7+/PzJkz89zHZDJRs2ZN5y08PLwEaywiIiIVlVdpV+BSmZmZbNq0iQkTJji3mc1moqOjWbt2bZ77nT17lsjISOx2Ox06dODll1+mVatWuZbNyMggIyPDeT8lJQUAm82GzWYropaUjpz6l/d2FFZlbn9lbjuo/ZW5/ZW57VC5219SbTYZhmGUyDPl0/Hjx4mIiGDNmjV069bNuf2pp55i1apVrFu3zm2ftWvXsnfvXtq2bUtycjJvvPEGq1evZseOHdSpU8et/OTJk5kyZYrb9s8++wx/f/+ibZCIiIgUi7S0NIYPH05ycjJBQUHF9jxlrmepMLp16+YSrLp3706LFi348MMPefHFF93KT5gwgfHjxzvvp6SkULduXfr161esL3ZJsNlsLF26lL59++Lt7V3a1Slxlbn9lbntoPZX5vZX5rZD5W7/qVOnSuR5ylxYCgsLw2KxEB8f77I9Pj6emjVr5usY3t7etG/fnn379uX6uNVqxWq15rpfRfmgVaS2FEZlbn9lbjuo/ZW5/ZW57VA5219S7S1zA7x9fHzo2LEjy5cvd26z2+0sX77cpffIk+zsbLZt20atWrWKq5oiIiJSSZS5niWA8ePHM2rUKK666io6d+7M9OnTSU1NZcyYMQCMHDmSiIgIpk6dCsALL7xA165dady4MUlJSbz++uscPnyYe++9tzSbISIiIhVAmQxLw4YN48SJE0ycOJG4uDjatWvH4sWLndMBxMTEYDZf6BQ7ffo0Y8eOJS4ujqpVq9KxY0fWrFlDy5YtS6sJIiIiUkGUybAEMG7cOMaNG5frYytXrnS5/9Zbb/HWW2+VQK1ERESksilzY5ZEREREyhKFJREREREPFJZEREREPFBYEhEREfFAYUlERETEA4UlEREREQ8UlkREREQ8UFgSERER8UBhSURERMQDhSURERERDxSWRERERDxQWBIRERHxQGFJRERExAOFJREREREPFJZEREREPFBYEhEREfFAYUlERETEA4UlEREREQ8UlkREREQ8UFgSERER8UBhSURERMQDhSURERERDxSWRERERDxQWBIRERHxQGFJRERExAOFJREREREPFJZEREREPFBYEhEREfFAYUlERETEA4UlEREREQ8UlkREREQ8UFgSERER8UBhSURERMQDhSURERERDxSWRERERDxQWBIRERHxQGFJRERExAOFJREREREPFJZEREREPFBYEhEREfFAYUlERETEA4UlEREREQ8UlkREREQ8UFgSERER8UBhSURERMQDhSURERERDxSWRERERDxQWBIRERHxQGFJRERExAOFJREREREPymxYevfdd6lfvz6+vr506dKF9evX52u/L774ApPJxJAhQ4q3giIiIlIplMmwNHfuXMaPH8+kSZPYvHkzUVFR9O/fn4SEBI/7HTp0iCeeeIJrr722hGoqIiIiFV2ZDEvTpk1j7NixjBkzhpYtW/LBBx/g7+/PzJkz89wnOzubv/3tb0yZMoWGDRuWYG1FRESkIitzYSkzM5NNmzYRHR3t3GY2m4mOjmbt2rV57vfCCy9Qo0YN7rnnnpKopoiIiFQSXqVdgUudPHmS7OxswsPDXbaHh4eze/fuXPf59ddfmTFjBlu3bs3Xc2RkZJCRkeG8n5ycDEBiYiI2m61wFS8jbDYbaWlpnDp1Cm9v79KuTomrzO2vzG0Htb8yt78ytx0qd/sTExMBMAyjWJ+nzIWlgjpz5gwjRozgo48+IiwsLF/7TJ06lSlTprhtb9CgQVFXT0RERIrZqVOnCA4OLrbjl7mwFBYWhsViIT4+3mV7fHw8NWvWdCu/f/9+Dh06xKBBg5zb7HY7AF5eXuzZs4dGjRq57DNhwgTGjx/vUj4xMZFq1aphMpmKsjklLiUlhbp163LkyBGCgoJKuzolrjK3vzK3HdT+ytz+ytx2qNztT05Opl69eoSGhhbr85S5sOTj40PHjh1Zvny58/J/u93O8uXLGTdunFv55s2bs23bNpdtzz33HGfOnOHf//43devWddvHarVitVpdtoWEhBRZG8qCoKCgSvdLc7HK3P7K3HZQ+ytz+ytz26Fyt99sLt4h2GUuLAGMHz+eUaNGcdVVV9G5c2emT59OamoqY8aMAWDkyJFEREQwdepUfH19ad26tcv+OcHn0u0iIiIiBVUmw9KwYcM4ceIEEydOJC4ujnbt2rF48WLnoO+YmJhiT5EiIiIiUEbDEsC4ceNyPe0GsHLlSo/7zp49u+grVE5YrVYmTZrkdpqxsqjM7a/MbQe1vzK3vzK3HSp3+0uq7SajuK+3ExERESnHdC5LRERExAOFJREREREPFJZEREREPFBYEhEREfFAYakcmTp1Kp06daJKlSrUqFGDIUOGsGfPHo/7zJ49G5PJ5HLz9fUtoRoXrcmTJ7u1pXnz5h73+fLLL2nevDm+vr60adOGH374oYRqW/Tq16/v1n6TycTDDz+ca/ny/N6vXr2aQYMGUbt2bUwmE99++63L44ZhMHHiRGrVqoWfnx/R0dHs3bv3ssd99913qV+/Pr6+vnTp0oX169cXUwuujKf222w2nn76adq0aUNAQAC1a9dm5MiRHD9+3OMxC/P7Uxou996PHj3arR3XX3/9ZY9bEd57INe/ASaTiddffz3PY5aX9z4/33Hp6ek8/PDDVKtWjcDAQG699Va3FT8uVdi/FxdTWCpHVq1axcMPP8zvv//O0qVLsdls9OvXj9TUVI/7BQUFERsb67wdPny4hGpc9Fq1auXSll9//TXPsmvWrOHOO+/knnvuYcuWLQwZMoQhQ4awffv2Eqxx0dmwYYNL25cuXQrA7bffnuc+5fW9T01NJSoqinfffTfXx1977TXefvttPvjgA9atW0dAQAD9+/cnPT09z2POnTuX8ePHM2nSJDZv3kxUVBT9+/cnISGhuJpRaJ7an5aWxubNm3n++efZvHkz8+fPZ8+ePdx0002XPW5Bfn9Ky+Xee4Drr7/epR2ff/65x2NWlPcecGl3bGwsM2fOxGQyceutt3o8bnl47/PzHfePf/yDhQsX8uWXX7Jq1SqOHz/OLbfc4vG4hfl74caQcishIcEAjFWrVuVZZtasWUZwcHDJVaoYTZo0yYiKisp3+aFDhxoDBw502dalSxfj/vvvL+KalY5HH33UaNSokWG323N9vKK894DxzTffOO/b7XajZs2axuuvv+7clpSUZFitVuPzzz/P8zidO3c2Hn74Yef97Oxso3bt2sbUqVOLpd5F5dL252b9+vUGYBw+fDjPMgX9/SkLcmv7qFGjjMGDBxfoOBX5vR88eLBx3XXXeSxTHt97w3D/jktKSjK8vb2NL7/80llm165dBmCsXbs212MU9u/FpdSzVI4lJycDXHYBwbNnzxIZGUndunUZPHgwO3bsKInqFYu9e/dSu3ZtGjZsyN/+9jdiYmLyLLt27Vqio6NdtvXv35+1a9cWdzWLXWZmJnPmzOHuu+/2uPhzRXrvcxw8eJC4uDiX9zY4OJguXbrk+d5mZmayadMml33MZjPR0dEV4vOQnJyMyWS67BqXBfn9KctWrlxJjRo1aNasGQ8++CCnTp3Ks2xFfu/j4+NZtGgR99xzz2XLlsf3/tLvuE2bNmGz2Vzey+bNm1OvXr0838vC/L3IjcJSOWW323nssce4+uqrPa6B16xZM2bOnMmCBQuYM2cOdrud7t27c/To0RKsbdHo0qULs2fPZvHixbz//vscPHiQa6+9ljNnzuRaPi4uzrlETo7w8HDi4uJKorrF6ttvvyUpKYnRo0fnWaYivfcXy3n/CvLenjx5kuzs7Ar5eUhPT+fpp5/mzjvv9LiIakF/f8qq66+/nk8++YTly5fz6quvsmrVKm644Qays7NzLV+R3/uPP/6YKlWqXPY0VHl873P7jouLi8PHx8ftPwWe3svC/L3ITZld7kQ8e/jhh9m+fftlzzt369aNbt26Oe93796dFi1a8OGHH/Liiy8WdzWL1A033OD8uW3btnTp0oXIyEjmzZuXr/9ZVSQzZszghhtuoHbt2nmWqUjvveTOZrMxdOhQDMPg/fff91i2ovz+3HHHHc6f27RpQ9u2bWnUqBErV66kT58+pVizkjdz5kz+9re/XfbCjfL43uf3O66kqGepHBo3bhzff/89K1asoE6dOgXa19vbm/bt27Nv375iql3JCQkJoWnTpnm2pWbNmm5XScTHx1OzZs2SqF6xOXz4MMuWLePee+8t0H4V5b3Pef8K8t6GhYVhsVgq1OchJygdPnyYpUuXeuxVys3lfn/Ki4YNGxIWFpZnOyriew/wyy+/sGfPngL/HYCy/97n9R1Xs2ZNMjMzSUpKcinv6b0szN+L3CgslSOGYTBu3Di++eYbfv75Zxo0aFDgY2RnZ7Nt2zZq1apVDDUsWWfPnmX//v15tqVbt24sX77cZdvSpUtdelvKo1mzZlGjRg0GDhxYoP0qynvfoEEDatas6fLepqSksG7dujzfWx8fHzp27Oiyj91uZ/ny5eXy85ATlPbu3cuyZcuoVq1agY9xud+f8uLo0aOcOnUqz3ZUtPc+x4wZM+jYsSNRUVEF3resvveX+47r2LEj3t7eLu/lnj17iImJyfO9LMzfi7wqJ+XEgw8+aAQHBxsrV640YmNjnbe0tDRnmREjRhjPPPOM8/6UKVOMJUuWGPv37zc2bdpk3HHHHYavr6+xY8eO0mjCFXn88ceNlStXGgcPHjR+++03Izo62ggLCzMSEhIMw3Bv+2+//WZ4eXkZb7zxhrFr1y5j0qRJhre3t7Ft27bSasIVy87ONurVq2c8/fTTbo9VpPf+zJkzxpYtW4wtW7YYgDFt2jRjy5Ytzqu9XnnlFSMkJMRYsGCB8eeffxqDBw82GjRoYJw7d855jOuuu8545513nPe/+OILw2q1GrNnzzZ27txp3HfffUZISIgRFxdX4u27HE/tz8zMNG666SajTp06xtatW13+FmRkZDiPcWn7L/f7U1Z4avuZM2eMJ554wli7dq1x8OBBY9myZUaHDh2MJk2aGOnp6c5jVNT3PkdycrLh7+9vvP/++7keo7y+9/n5jnvggQeMevXqGT///LOxceNGo1u3bka3bt1cjtOsWTNj/vz5zvv5+XtxOQpL5QiQ623WrFnOMj179jRGjRrlvP/YY48Z9erVM3x8fIzw8HBjwIABxubNm0u+8kVg2LBhRq1atQwfHx8jIiLCGDZsmLFv3z7n45e23TAMY968eUbTpk0NHx8fo1WrVsaiRYtKuNZFa8mSJQZg7Nmzx+2xivTer1ixItfPek777Ha78fzzzxvh4eGG1Wo1+vTp4/aaREZGGpMmTXLZ9s477zhfk86dOxu///57CbWoYDy1/+DBg3n+LVixYoXzGJe2/3K/P2WFp7anpaUZ/fr1M6pXr254e3sbkZGRxtixY91CT0V973N8+OGHhp+fn5GUlJTrMcrre5+f77hz584ZDz30kFG1alXD39/fuPnmm43Y2Fi341y8T37+XlyO6fyBRURERCQXGrMkIiIi4oHCkoiIiIgHCksiIiIiHigsiYiIiHigsCQiIiLigcKSiIiIiAcKSyIiIiIeKCyJiBRA/fr1qV+/fmlXQ0RKkMKSiJS4Q4cOYTKZPN4USESkrPAq7QqISOXVqFEj7rrrrlwfCwkJKdnKiIjkQWFJREpN48aNmTx5cmlXQ0TEI52GE5Eyz2Qy0atXL44ePcqdd95JWFgY/v7+XH311SxbtizXfU6ePMljjz1GgwYNsFqt1KhRg6FDh7J9+/Zcy2dmZvLWW2/RqVMnqlSpQmBgIC1btmT8+PGcPn3arfzZs2d59NFHqV27NlarlbZt2/LVV18VabtFpGzQQroiUuIOHTpEgwYN6N+/P4sXL75seZPJRNu2bUlKSqJ69epER0dz4sQJ5s6dS3p6Ol999RVDhgxxlj9x4gTdunVj//799OrVi65du3Lw4EG++uorrFYrS5Ys4ZprrnGWP3fuHH379uW3336jSZMmXH/99VitVvbu3cvSpUv57bffaNeuHeAY4G2z2YiMjOT06dNER0eTlpbGF198wblz51i8eDH9+vUr6pdMREqRwpKIlLicsORpzFLXrl25/vrrAUdYAhg+fDhz5sxx3v/zzz/p1KkTwcHBHD58GD8/PwDuvvtuZs2axYQJE3j55Zedx/zhhx8YOHAgjRs3Zs+ePZjNjs71J554gjfffJMRI0Ywa9YsLBaLc5/k5GQsFguBgYGAIywdPnyYwYMHM2/ePHx8fABYvnw50dHR+Q6AIlJ+KCyJSInLCUuePProo0yfPh1whCWLxcL+/fuJjIx0KXfvvfcyY8YMvvrqK2699VYyMzMJDg4mICCAmJgY/P39Xcr369ePpUuXsnr1aq699lqysrIIDQ3FbDZz8OBBqlat6rFeOWHpwIEDbm2oX78+Z86c4dSpU/l8JUSkPNCYJREpNf3798cwjFxvOUEpR7169dyCEsC1114LwJYtWwDYvXs36enpdO7c2S0oAfTu3RuArVu3OsufOXOGTp06XTYo5QgJCck17NWpU4ekpKR8HUNEyg+FJREpF8LDwz1uT05OBiAlJcVj+Vq1armUy9kvIiIi33UJDg7OdbuXlxd2uz3fxxGR8kFhSUTKhfj4eI/bcwJMUFCQx/JxcXEu5XLmczp27FiR1VVEKhaFJREpF2JiYjh8+LDb9l9++QWA9u3bA9C8eXN8fX3ZsGEDaWlpbuVXrlwJ4Ly6rVmzZgQFBbFhw4ZcpwgQEVFYEpFyITs7m2effZaLr0n5888/+fTTT6levToDBgwAwMfHhzvvvJOTJ08ydepUl2MsXryYJUuW0LhxY66++mrAcers/vvvJzk5mUcffZTs7GyXfZKTkzl79mwxt05EyjJdDSciJS4/UwcAPPPMM/j6+nqcZ+ncuXN8/fXXbvMsde3alQMHDnDdddfRpUsXDh06xJdffomPj4/bPEvp6en069ePX375hSZNmnDDDTdgtVo5cOAAixcv5tdff3WZZymnDZfq1asXq1atQn9WRSoWhSURKXH5mToA4PTp04SEhGAymejZsydz5szhiSeeYOnSpaSlpdG+fXumTJlC37593fY9efIkL774IgsWLOD48eMEBwfTq1cvJk2aROvWrd3KZ2Rk8J///Ic5c+awZ88eLBYL9erV44YbbuC5555zjm1SWBKpfBSWRKTMywlLOeONRERKksYsiYiIiHigsCQiIiLigcKSiIiIiAdepV0BEZHL0dBKESlN6lkSERER8UBhSURERMQDhSURERERDxSWRERERDxQWBIRERHxQGFJRERExAOFJREREREPFJZEREREPFBYEhEREfHg/wHgAlu9jXmThAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def train2(model, optimizer, criterion, metric, train_loader, valid_loader,\n",
        "               n_epochs):\n",
        "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        metric.reset()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            model.train()\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            metric.update(y_pred, y_batch)\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        history[\"train_losses\"].append(mean_loss)\n",
        "        history[\"train_metrics\"].append(metric.compute().item())\n",
        "        history[\"valid_metrics\"].append(\n",
        "            evaluate_tm(model, valid_loader, metric).item())\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
        "    return history\n",
        "\n",
        "torch.manual_seed(42)\n",
        "learning_rate = 0.01\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 50), nn.ReLU(),\n",
        "    nn.Linear(50, 40), nn.ReLU(),\n",
        "    nn.Linear(40, 30), nn.ReLU(),\n",
        "    nn.Linear(30, 1)\n",
        ")\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
        "                 n_epochs)\n",
        "\n",
        "# Since we compute the training metric\n",
        "plt.plot(np.arange(n_epochs) + 0.5, history[\"train_metrics\"], \".--\",\n",
        "         label=\"Training\")\n",
        "plt.plot(np.arange(n_epochs) + 1.0, history[\"valid_metrics\"], \".-\",\n",
        "         label=\"Validation\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.grid()\n",
        "plt.title(\"Learning curves\")\n",
        "plt.axis([0.5, 20, 0.4, 1.0])\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzqjW3WzL5De"
      },
      "source": [
        "# Building Nonsequential Models Using Custom Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60d0b5e4"
      },
      "source": [
        "This `WideAndDeep` class defines a custom PyTorch model that implements the Wide & Deep learning architecture. This architecture is designed to combine the strengths of both linear (wide) and deep neural networks:\n",
        "\n",
        "*   **`__init__(self, n_features)`**: The constructor sets up the layers:\n",
        "    *   `super().__init__()`: Ensures that your `WideAndDeep` module is properly set up as a valid PyTorch module, inheriting all the necessary infrastructure from `nn.Module` before you add your specific layers and logic.\n",
        "    *   `self.deep_stack`: This is a sequential deep neural network composed of three linear layers with ReLU activation functions. It processes the input features through several hidden layers.\n",
        "    *   `self.output_layer`: This is the final linear layer that produces the model's output (e.g., a regression prediction). It takes as input the concatenated output from the deep stack and the original input features.\n",
        "\n",
        "*   **`forward(self, X)`**: This method defines how data flows through the model:\n",
        "    *   `deep_output = self.deep_stack(X)`: The input `X` is first passed through the deep network to extract complex, non-linear feature interactions.\n",
        "    *   `wide_and_deep = torch.concat([X, deep_output], dim=1)`: The original input features `X` (the \"wide\" part) are directly concatenated with the `deep_output` (the \"deep\" part). This allows the model to learn simple, direct relationships (from the wide path) alongside more intricate, non-linear patterns (from the deep path).\n",
        "    *   `return self.output_layer(wide_and_deep)`: The combined features are then fed into the output layer to produce the final prediction.\n",
        "\n",
        "This architecture is particularly useful for tasks where both memorization of feature interactions (handled by the wide path, implicitly through the direct connection of `X` to the output layer) and generalization from new feature combinations (handled by the deep path) are important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "2KhKsQdpL5De"
      },
      "outputs": [],
      "source": [
        "class WideAndDeep(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 40), nn.ReLU(),\n",
        "            nn.Linear(40, 30), nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(30 + n_features, 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        deep_output = self.deep_stack(X)\n",
        "        wide_and_deep = torch.concat([X, deep_output], dim=1)\n",
        "        return self.output_layer(wide_and_deep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "toXaDJ3qL5De"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model = WideAndDeep(n_features).to(device)\n",
        "learning_rate = 0.002  # the model changed, so did the optimal learning rate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the stuff in notes\n",
        "for child in model.named_children():\n",
        "  print(child)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekMEJ3f3HDBl",
        "outputId": "3c486663-5f8e-4577-fa80-fcf5fddda08a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('deep_stack', Sequential(\n",
            "  (0): Linear(in_features=8, out_features=50, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=50, out_features=40, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=40, out_features=30, bias=True)\n",
            "  (5): ReLU()\n",
            "))\n",
            "('output_layer', Linear(in_features=38, out_features=1, bias=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "kVUfgXTPL5De",
        "outputId": "8e27e335-9870-472b-ce20-b2f810eb3ad9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, train loss: 1.7802, train metric: 1.3344, valid metric: 0.8690\n",
            "Epoch 2/20, train loss: 0.6201, train metric: 0.7875, valid metric: 0.9492\n",
            "Epoch 3/20, train loss: 0.5900, train metric: 0.7682, valid metric: 0.7331\n",
            "Epoch 4/20, train loss: 0.5607, train metric: 0.7488, valid metric: 0.7771\n",
            "Epoch 5/20, train loss: 0.5408, train metric: 0.7353, valid metric: 0.7967\n",
            "Epoch 6/20, train loss: 0.5244, train metric: 0.7241, valid metric: 0.7098\n",
            "Epoch 7/20, train loss: 0.5070, train metric: 0.7119, valid metric: 0.7419\n",
            "Epoch 8/20, train loss: 0.4941, train metric: 0.7030, valid metric: 0.6750\n",
            "Epoch 9/20, train loss: 0.4798, train metric: 0.6928, valid metric: 0.6762\n",
            "Epoch 10/20, train loss: 0.4657, train metric: 0.6825, valid metric: 0.6678\n",
            "Epoch 11/20, train loss: 0.4538, train metric: 0.6736, valid metric: 0.6617\n",
            "Epoch 12/20, train loss: 0.4441, train metric: 0.6665, valid metric: 0.6651\n",
            "Epoch 13/20, train loss: 0.4328, train metric: 0.6580, valid metric: 0.6803\n",
            "Epoch 14/20, train loss: 0.4232, train metric: 0.6506, valid metric: 0.6288\n",
            "Epoch 15/20, train loss: 0.4139, train metric: 0.6434, valid metric: 0.6202\n",
            "Epoch 16/20, train loss: 0.4063, train metric: 0.6374, valid metric: 0.6216\n",
            "Epoch 17/20, train loss: 0.3991, train metric: 0.6317, valid metric: 0.6129\n",
            "Epoch 18/20, train loss: 0.3937, train metric: 0.6274, valid metric: 0.6031\n",
            "Epoch 19/20, train loss: 0.3879, train metric: 0.6228, valid metric: 0.6092\n",
            "Epoch 20/20, train loss: 0.3834, train metric: 0.6193, valid metric: 0.5957\n"
          ]
        }
      ],
      "source": [
        "# extra code: train the model, exactly our previous models\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
        "                 n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if you want to send a subset of the features through the wide path and a different subset (possibly overlapping) through the deep path?"
      ],
      "metadata": {
        "id": "LE0PyE3CHtkk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff75ea4e"
      },
      "source": [
        "This `WideAndDeepV2` class is an advanced version of the Wide & Deep architecture, specifically designed to handle cases where different subsets of input features are fed into the \"wide\" and \"deep\" paths of the network. It differs from `WideAndDeep` in how it prepares inputs for these paths.\n",
        "\n",
        "*   **`__init__(self, n_features)`**: The constructor sets up the layers:\n",
        "    *   `self.deep_stack`: This is a sequential deep neural network. Notably, its first linear layer expects `n_features - 2` inputs, indicating that only a subset of the original features will be processed by the deep path.\n",
        "    *   `self.output_layer`: This is the final linear layer. It expects `30 + 5` inputs, meaning the output from the deep stack (30 neurons) is concatenated with 5 features from the original input for the wide path.\n",
        "\n",
        "*   **`forward(self, X)`**: This method defines how data flows through the model:\n",
        "    *   `X_wide = X[:, :5]`: This line extracts the first 5 features from the input tensor `X` to be used for the wide path. This is a specific subset of features.\n",
        "    *   `X_deep = X[:, 2:]`: This line extracts features starting from the third one (`index 2`) to the end, to be used for the deep path. This subset overlaps with the wide features (features at index 2, 3, 4 are common) and also includes features not in the wide path.\n",
        "    *   `deep_output = self.deep_stack(X_deep)`: The selected `X_deep` features are passed through the deep network.\n",
        "    *   `wide_and_deep = torch.concat([X_wide, deep_output], dim=1)`: The selected `X_wide` features are concatenated with the `deep_output`. This creates the combined input for the final output layer.\n",
        "    *   `return self.output_layer(wide_and_deep)`: The combined features are then fed into the output layer to produce the final prediction.\n",
        "\n",
        "This version allows for more fine-grained control over which features contribute to the simple linear part (wide) and which are processed through the complex non-linear part (deep), potentially improving model performance by better leveraging feature characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ot3NPj2XL5De"
      },
      "outputs": [],
      "source": [
        "class WideAndDeepV2(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 40), nn.ReLU(),\n",
        "            nn.Linear(40, 30), nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(30 + 5, 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X_wide = X[:, :5]\n",
        "        X_deep = X[:, 2:]\n",
        "        deep_output = self.deep_stack(X_deep)\n",
        "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
        "        return self.output_layer(wide_and_deep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "g3kLAwo_L5De"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model = WideAndDeepV2(n_features).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "yFSpvSJcL5De",
        "outputId": "6f0fb103-1e5d-4006-9a6c-e793f873c78f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, train loss: 1.8482, train metric: 1.3598, valid metric: 0.9100\n",
            "Epoch 2/20, train loss: 0.6282, train metric: 0.7927, valid metric: 0.8028\n",
            "Epoch 3/20, train loss: 0.5763, train metric: 0.7591, valid metric: 0.7567\n",
            "Epoch 4/20, train loss: 0.5413, train metric: 0.7356, valid metric: 0.7290\n",
            "Epoch 5/20, train loss: 0.5099, train metric: 0.7142, valid metric: 0.7011\n",
            "Epoch 6/20, train loss: 0.4841, train metric: 0.6958, valid metric: 0.6816\n",
            "Epoch 7/20, train loss: 0.4656, train metric: 0.6824, valid metric: 0.6670\n",
            "Epoch 8/20, train loss: 0.4526, train metric: 0.6728, valid metric: 0.6576\n",
            "Epoch 9/20, train loss: 0.4438, train metric: 0.6662, valid metric: 0.6539\n",
            "Epoch 10/20, train loss: 0.4380, train metric: 0.6618, valid metric: 0.6498\n",
            "Epoch 11/20, train loss: 0.4326, train metric: 0.6577, valid metric: 0.6470\n",
            "Epoch 12/20, train loss: 0.4284, train metric: 0.6546, valid metric: 0.6447\n",
            "Epoch 13/20, train loss: 0.4253, train metric: 0.6521, valid metric: 0.6452\n",
            "Epoch 14/20, train loss: 0.4216, train metric: 0.6494, valid metric: 0.6468\n",
            "Epoch 15/20, train loss: 0.4190, train metric: 0.6473, valid metric: 0.6484\n",
            "Epoch 16/20, train loss: 0.4169, train metric: 0.6458, valid metric: 0.6452\n",
            "Epoch 17/20, train loss: 0.4144, train metric: 0.6438, valid metric: 0.6459\n",
            "Epoch 18/20, train loss: 0.4118, train metric: 0.6417, valid metric: 0.6470\n",
            "Epoch 19/20, train loss: 0.4101, train metric: 0.6404, valid metric: 0.6475\n",
            "Epoch 20/20, train loss: 0.4082, train metric: 0.6389, valid metric: 0.6493\n"
          ]
        }
      ],
      "source": [
        "# extra code: train the model, exactly our previous models\n",
        "learning_rate = 0.002\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
        "                 n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXGaggMtL5De"
      },
      "source": [
        "## Building Models with Multiple Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49b75916"
      },
      "source": [
        "This `WideAndDeepV3` class builds upon the previous Wide & Deep architectures by explicitly separating the inputs for the wide and deep paths. This design is particularly useful when you have distinct sets of features that you want to feed into each part of the model directly, rather than extracting them within the `forward` method.\n",
        "\n",
        "*   **`__init__(self, n_features)`**: The constructor is identical to `WideAndDeepV2`:\n",
        "    *   `self.deep_stack`: A sequential deep neural network. Its first linear layer expects `n_features - 2` inputs, meaning a specific subset of features is intended for the deep path.\n",
        "    *   `self.output_layer`: The final linear layer. It expects `30 + 5` inputs, indicating that the output from the deep stack (30 neurons) is concatenated with 5 features from the wide path.\n",
        "\n",
        "*   **`forward(self, X_wide, X_deep)`**: This method defines how data flows through the model and is the key difference:\n",
        "    *   Instead of taking a single `X` and slicing it internally (as in `WideAndDeepV2`), this `forward` method **directly accepts two separate input tensors**: `X_wide` and `X_deep`.\n",
        "    *   `deep_output = self.deep_stack(X_deep)`: The `X_deep` features are passed through the deep network.\n",
        "    *   `wide_and_deep = torch.concat([X_wide, deep_output], dim=1)`: The `X_wide` features are concatenated with the `deep_output`.\n",
        "    *   `return self.output_layer(wide_and_deep)`: The combined features are then fed into the output layer to produce the final prediction.\n",
        "\n",
        "This explicit input separation makes the model more flexible, as it allows you to preprocess or obtain `X_wide` and `X_deep` independently before passing them to the model, and it makes the model's intended feature usage clearer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "5KRhvwIdL5De"
      },
      "outputs": [],
      "source": [
        "class WideAndDeepV3(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 40), nn.ReLU(),\n",
        "            nn.Linear(40, 30), nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(30 + 5, 1)\n",
        "\n",
        "    def forward(self, X_wide, X_deep):\n",
        "        deep_output = self.deep_stack(X_deep)\n",
        "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
        "        return self.output_layer(wide_and_deep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4863533"
      },
      "source": [
        "The primary difference in this data preparation cell, compared to earlier steps, is the way `TensorDataset` is initialized. Instead of passing a single set of input features (e.g., `X_train`), it now accepts **multiple distinct input feature tensors** (`X_train[:, :5]` for the 'wide' path and `X_train[:, 2:]` for the 'deep' path), along with the target labels. This prepares the data to directly match the multiple input arguments expected by the `forward()` method of models like `WideAndDeepV3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "bWnN8MBTL5De"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "train_data_wd = TensorDataset(X_train[:, :5], X_train[:, 2:], y_train)\n",
        "train_loader_wd = DataLoader(train_data_wd, batch_size=32, shuffle=True)\n",
        "valid_data_wd = TensorDataset(X_valid[:, :5], X_valid[:, 2:], y_valid)\n",
        "valid_loader_wd = DataLoader(valid_data_wd, batch_size=32)\n",
        "test_data_wd = TensorDataset(X_test[:, :5], X_test[:, 2:], y_test)\n",
        "test_loader_wd = DataLoader(test_data_wd, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17e75d6a"
      },
      "source": [
        "This code cell introduces and defines two key functions, `evaluate_multi_in` and `train_multi_in`, specifically tailored for PyTorch models that accept **multiple input tensors** (like the `WideAndDeepV3` model). It also demonstrates how to set up and train such a model.\n",
        "\n",
        "### `evaluate_multi_in` Function:\n",
        "This function is for evaluating models with multiple inputs. Its main differences from the standard `evaluate_tm` are:\n",
        "*   **Input Unpacking**: When iterating through the `data_loader`, it unpacks `(X_batch_wide, X_batch_deep, y_batch)` because the `TensorDataset` was configured to yield these three components.\n",
        "*   **Device Transfer**: Both `X_batch_wide` and `X_batch_deep` are explicitly moved to the specified `device`.\n",
        "*   **Model Call**: The model is called with separate arguments: `y_pred = model(X_batch_wide, X_batch_deep)` to match the `forward` method of `WideAndDeepV3`.\n",
        "\n",
        "### `train_multi_in` Function:\n",
        "This function handles the training loop for models with multiple inputs. Key distinctions from the standard `train2` function include:\n",
        "*   **Input Unpacking**: It uses `for *X_batch_inputs, y_batch in train_loader:` to flexibly unpack all input tensors (in this case, `X_wide` and `X_deep`) into a list called `X_batch_inputs`.\n",
        "*   **Device Transfer**: It iterates through `X_batch_inputs` to move each input tensor to the `device`.\n",
        "*   **Model Call**: The model is called using argument unpacking: `y_pred = model(*X_batch_inputs)`. This passes the elements of `X_batch_inputs` (i.e., `X_batch_wide` and `X_batch_deep`) as separate arguments to the `model`'s `forward` method.\n",
        "*   **Validation Call**: It uses the `evaluate_multi_in` function to calculate and record the validation metric.\n",
        "\n",
        "### Model Initialization and Training Execution:\n",
        "*   A `WideAndDeepV3` model is initialized with `n_features` and moved to the `device`.\n",
        "*   An `SGD` optimizer, `MSELoss` criterion, and `torchmetrics.MeanSquaredError` metric are set up.\n",
        "*   The `train_multi_in` function is then called with the model, optimizer, loss, metric, and the `_wd` suffixed data loaders (which provide the multiple inputs), to train the model for `n_epochs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "i8CYKBwgL5De",
        "outputId": "bc52a89c-10cc-4050-ac0e-e8d613cecc62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892\n",
            "Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455\n",
            "Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374\n",
            "Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512\n",
            "Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305\n",
            "Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287\n",
            "Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252\n",
            "Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158\n",
            "Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407\n",
            "Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063\n",
            "Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974\n",
            "Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888\n",
            "Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981\n",
            "Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842\n",
            "Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410\n",
            "Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747\n",
            "Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686\n",
            "Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679\n",
            "Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621\n",
            "Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690\n"
          ]
        }
      ],
      "source": [
        "def evaluate_multi_in(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()  # reset the metric at the beginning\n",
        "    with torch.no_grad():\n",
        "        for X_batch_wide, X_batch_deep, y_batch in data_loader:\n",
        "            X_batch_wide = X_batch_wide.to(device)\n",
        "            X_batch_deep = X_batch_deep.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(X_batch_wide, X_batch_deep)\n",
        "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
        "    return metric.compute()  # compute the final result at the end\n",
        "\n",
        "def train_multi_in(model, optimizer, criterion, metric, train_loader,\n",
        "                   valid_loader, n_epochs):\n",
        "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        metric.reset()\n",
        "        for *X_batch_inputs, y_batch in train_loader:\n",
        "            model.train()\n",
        "            X_batch_inputs = [X.to(device) for X in X_batch_inputs]\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(*X_batch_inputs)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            metric.update(y_pred, y_batch)\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        history[\"train_losses\"].append(mean_loss)\n",
        "        history[\"train_metrics\"].append(metric.compute().item())\n",
        "        history[\"valid_metrics\"].append(\n",
        "            evaluate_multi_in(model, valid_loader, metric).item())\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
        "    return history\n",
        "\n",
        "torch.manual_seed(42)\n",
        "learning_rate = 0.01\n",
        "model = WideAndDeepV3(n_features).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train_multi_in(model, optimizer, mse, rmse, train_loader_wd,\n",
        "                         valid_loader_wd, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dd59251"
      },
      "source": [
        "This code cell defines a custom PyTorch `Dataset` called `WideAndDeepDataset`. This class is essential for preparing data in a structured way that can be easily used by PyTorch's `DataLoader`, especially when your model expects multiple, named inputs (like `X_wide` and `X_deep` for the `WideAndDeepV3` architecture when called with keyword arguments).\n",
        "\n",
        "*   **`__init__(self, X_wide, X_deep, y)`**: The constructor takes three arguments:\n",
        "    *   `X_wide`: The features intended for the 'wide' path of the model.\n",
        "    *   `X_deep`: The features intended for the 'deep' path of the model.\n",
        "    *   `y`: The target labels for the data.\n",
        "    It simply stores these tensors as attributes of the dataset object.\n",
        "\n",
        "*   **`__len__(self)`**: This method is required by PyTorch's `Dataset` interface. It returns the total number of samples in the dataset, which is determined by the length of the target `y` tensor.\n",
        "\n",
        "*   **`__getitem__(self, idx)`**: This crucial method defines how a single sample (indexed by `idx`) is retrieved from the dataset. It returns:\n",
        "    *   A dictionary `input_dict` containing the `X_wide` and `X_deep` tensors for the given index, under the keys \"X_wide\" and \"X_deep\" respectively. This format is particularly useful when you want to pass these inputs to a model using keyword arguments (e.g., `model(**inputs)`).\n",
        "    *   The corresponding target label `self.y[idx]`.\n",
        "\n",
        "This custom `Dataset` makes it convenient to manage and load data for models that have multiple distinct input branches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "jaX9QRVWL5De"
      },
      "outputs": [],
      "source": [
        "class WideAndDeepDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X_wide, X_deep, y):\n",
        "        self.X_wide = X_wide\n",
        "        self.X_deep = X_deep\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_dict = {\"X_wide\": self.X_wide[idx], \"X_deep\": self.X_deep[idx]}\n",
        "        return input_dict, self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f40b428"
      },
      "source": [
        "This code cell, building on the custom `WideAndDeepDataset`, prepares your data for training, validation, and testing by creating `DataLoader` instances. The key aspects are:\n",
        "\n",
        "*   **Custom `Dataset` Usage**: It instantiates `WideAndDeepDataset` objects for the training, validation, and test sets. Crucially, it passes the sliced `X_train` (and `X_valid`, `X_test`) into their respective `X_wide` and `X_deep` components, explicitly defining which features go to which path.\n",
        "\n",
        "*   **`DataLoader` for Batches**: It then wraps these `WideAndDeepDataset` objects with `DataLoader`s. These data loaders will yield batches, where each batch consists of a dictionary containing the `X_wide` and `X_deep` tensors (under their respective keys) and the corresponding `y` target tensor. This format perfectly matches the `forward` method signature of models that accept keyword arguments for their inputs (e.g., `model(**inputs)`).\n",
        "\n",
        "*   **Shuffling**: `shuffle=True` is used for the `train_loader_named` to ensure that training samples are presented in a random order in each epoch, which is beneficial for model generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "ibUFv4azL5De"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "train_data_named = WideAndDeepDataset(\n",
        "    X_wide=X_train[:, :5], X_deep=X_train[:, 2:], y=y_train)\n",
        "train_loader_named = DataLoader(train_data_named, batch_size=32, shuffle=True)\n",
        "valid_data_named = WideAndDeepDataset(\n",
        "    X_wide=X_valid[:, :5], X_deep=X_valid[:, 2:], y=y_valid)\n",
        "valid_loader_named = DataLoader(valid_data_named, batch_size=32)\n",
        "test_data_named = WideAndDeepDataset(\n",
        "    X_wide=X_test[:, :5], X_deep=X_test[:, 2:], y=y_test)\n",
        "test_loader_named = DataLoader(test_data_named, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e48e77f0"
      },
      "source": [
        "This code cell defines `evaluate_named` and `train_named` functions, which are specialized for handling models that receive multiple inputs via a dictionary (i.e., named arguments), typically when using a custom `Dataset` like `WideAndDeepDataset`.\n",
        "\n",
        "### `evaluate_named` Function:\n",
        "This function evaluates the model on a given `data_loader`. Its key features include:\n",
        "*   **Input Handling**: It iterates through the `data_loader`, which yields `(inputs_dict, y_batch)`. The `inputs_dict` contains named tensors (e.g., `{'X_wide': tensor_wide, 'X_deep': tensor_deep}`).\n",
        "*   **Device Transfer**: It moves each tensor within the `inputs_dict` and the `y_batch` to the specified `device`.\n",
        "*   **Model Call**: It calls the model's `forward` method using explicit keyword arguments: `y_pred = model(X_wide=inputs[\"X_wide\"], X_deep=inputs[\"X_deep\"])`.\n",
        "*   **Metric Calculation**: It updates and computes the overall metric using the provided `metric` object (e.g., `torchmetrics.Accuracy`).\n",
        "\n",
        "### `train_named` Function:\n",
        "This function handles the training loop, adapting to models with named inputs:\n",
        "*   **Input Handling**: Similar to `evaluate_named`, it iterates through `train_loader`, receiving `(inputs_dict, y_batch)`.\n",
        "*   **Device Transfer**: All input tensors from `inputs_dict` are moved to the `device`.\n",
        "*   **Model Call**: It uses the Python `**inputs` syntax (`y_pred = model(**inputs)`) to unpack the dictionary into keyword arguments for the model's `forward` method. This is a clean way to pass named inputs.\n",
        "*   **Loss Calculation, Backpropagation, and Optimization**: These steps are standard for training, calculating loss, computing gradients, and updating parameters.\n",
        "*   **Metric Tracking**: It tracks training loss, training metric, and crucially, calls `evaluate_named` to get the validation metric at the end of each epoch, printing the results.\n",
        "\n",
        "The cell then initializes a `WideAndDeepV3` model, an `SGD` optimizer, `MSELoss`, and `RMSE` metric, and uses `train_named` to train the model with the `_named` suffixed data loaders, demonstrating how to train a multi-input model when data is provided as named inputs from a custom `Dataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Jz5PKCdzL5De",
        "outputId": "0b933027-2ec4-4cd4-f1fc-c24225ae3ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892\n",
            "Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455\n",
            "Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374\n",
            "Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512\n",
            "Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305\n",
            "Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287\n",
            "Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252\n",
            "Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158\n",
            "Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407\n",
            "Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063\n",
            "Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974\n",
            "Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888\n",
            "Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981\n",
            "Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842\n",
            "Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410\n",
            "Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747\n",
            "Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686\n",
            "Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679\n",
            "Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621\n",
            "Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690\n"
          ]
        }
      ],
      "source": [
        "def evaluate_named(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()  # reset the metric at the beginning\n",
        "    with torch.no_grad():\n",
        "        for inputs, y_batch in data_loader:\n",
        "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(X_wide=inputs[\"X_wide\"], X_deep=inputs[\"X_deep\"])\n",
        "            metric.update(y_pred, y_batch)\n",
        "    return metric.compute()  # compute the final result at the end\n",
        "\n",
        "def train_named(model, optimizer, criterion, metric, train_loader,\n",
        "                   valid_loader, n_epochs):\n",
        "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        metric.reset()\n",
        "        for inputs, y_batch in train_loader:\n",
        "            model.train()\n",
        "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(**inputs)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            metric.update(y_pred, y_batch)\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        history[\"train_losses\"].append(mean_loss)\n",
        "        history[\"train_metrics\"].append(metric.compute().item())\n",
        "        history[\"valid_metrics\"].append(\n",
        "            evaluate_named(model, valid_loader, metric).item())\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
        "    return history\n",
        "\n",
        "torch.manual_seed(42)\n",
        "learning_rate = 0.01\n",
        "model = WideAndDeepV3(n_features).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train_named(model, optimizer, mse, rmse, train_loader_named,\n",
        "                      valid_loader_named, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2otWUhiL5De"
      },
      "source": [
        "## Building Models with Multiple Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cd9ee93"
      },
      "source": [
        "This `WideAndDeepV4` class extends the Wide & Deep architecture to support **multiple outputs**, specifically adding an auxiliary output. This is useful for multi-task learning or for regularizing the deep path by forcing it to learn a useful intermediate representation.\n",
        "\n",
        "*   **`__init__(self, n_features)`**: The constructor is similar to `WideAndDeepV3`, but with an important addition:\n",
        "    *   `self.deep_stack`: The sequential deep neural network, taking `n_features - 2` inputs.\n",
        "    *   `self.output_layer`: This is now explicitly referred to as the **main output layer**, combining `30` neurons from the deep stack with `5` wide features to produce one output.\n",
        "    *   `self.aux_output_layer`: A new **auxiliary output layer**. It takes the output of the `deep_stack` (30 neurons) and produces a single auxiliary output. This auxiliary output is typically used for an auxiliary loss, encouraging the deep path to learn features that are useful for the main task.\n",
        "\n",
        "*   **`forward(self, X_wide, X_deep)`**: This method now returns two outputs:\n",
        "    *   `deep_output = self.deep_stack(X_deep)`: The `X_deep` features are passed through the deep network.\n",
        "    *   `wide_and_deep = torch.concat([X_wide, deep_output], dim=1)`: The `X_wide` features are concatenated with the `deep_output`.\n",
        "    *   `main_output = self.output_layer(wide_and_deep)`: The primary prediction is generated from the combined wide and deep features.\n",
        "    *   `aux_output = self.aux_output_layer(deep_output)`: The auxiliary prediction is generated directly from the `deep_output`.\n",
        "    *   `return main_output, aux_output`: The model now returns both the main prediction and the auxiliary prediction.\n",
        "\n",
        "This architecture allows for more complex training schemes where different parts of the model contribute to different (or related) prediction tasks, often leading to better overall performance and generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "x2TrJCUcL5De"
      },
      "outputs": [],
      "source": [
        "class WideAndDeepV4(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 40), nn.ReLU(),\n",
        "            nn.Linear(40, 30), nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(30 + 5, 1)\n",
        "        self.aux_output_layer = nn.Linear(30, 1)\n",
        "\n",
        "    def forward(self, X_wide, X_deep):\n",
        "        deep_output = self.deep_stack(X_deep)\n",
        "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
        "        main_output = self.output_layer(wide_and_deep)\n",
        "        aux_output = self.aux_output_layer(deep_output)\n",
        "        return main_output, aux_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47b111ed"
      },
      "source": [
        "This code cell defines two functions, `evaluate_multi_out` and `train_multi_out`, specifically designed for PyTorch models that produce **multiple outputs** (like the `WideAndDeepV4` model). It also demonstrates how to set up and train such a model.\n",
        "\n",
        "### `evaluate_multi_out` Function:\n",
        "This function evaluates the model, similar to previous evaluation functions, but with a key difference:\n",
        "*   **Multiple Output Handling**: When calling `y_pred, _ = model(**inputs)`, it expects the model to return multiple outputs. It uses only the *first* output (`y_pred`) for metric calculation, effectively ignoring the auxiliary output (`_`).\n",
        "\n",
        "### `train_multi_out` Function:\n",
        "This function handles the training loop for models with multiple outputs. Its key features include:\n",
        "*   **Multiple Output Handling**: After the forward pass (`y_pred, y_pred_aux = model(**inputs)`), it captures both the main prediction (`y_pred`) and the auxiliary prediction (`y_pred_aux`).\n",
        "*   **Combined Loss Calculation**: It calculates separate loss values for the main output (`main_loss`) and the auxiliary output (`aux_loss`). These losses are then combined into a single `loss` using a weighted sum (`0.8 * main_loss + 0.2 * aux_loss`). This is a common practice in multi-task learning, where the auxiliary loss helps regularize the model and guide the learning of intermediate representations.\n",
        "\n",
        "### Model Initialization and Training Execution:\n",
        "*   A `WideAndDeepV4` model (which has main and auxiliary output layers) is initialized and moved to the `device`.\n",
        "*   An `SGD` optimizer, `MSELoss` criterion, and `torchmetrics.MeanSquaredError` metric are set up.\n",
        "*   The `train_multi_out` function is then called with the model and the `_named` suffixed data loaders to train the model, leveraging the combined loss for optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "eKkYws1qL5De",
        "outputId": "182b9c60-b266-4b42-fdc1-570034fb4460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, train loss: 1.0693, train metric: 0.9506, valid metric: 0.7085\n",
            "Epoch 2/20, train loss: 0.5817, train metric: 0.6946, valid metric: 0.6607\n",
            "Epoch 3/20, train loss: 0.5010, train metric: 0.6581, valid metric: 0.6425\n",
            "Epoch 4/20, train loss: 0.4690, train metric: 0.6497, valid metric: 0.6654\n",
            "Epoch 5/20, train loss: 0.4503, train metric: 0.6420, valid metric: 0.6338\n",
            "Epoch 6/20, train loss: 0.4387, train metric: 0.6373, valid metric: 0.6563\n",
            "Epoch 7/20, train loss: 0.4315, train metric: 0.6330, valid metric: 0.6193\n",
            "Epoch 8/20, train loss: 0.4249, train metric: 0.6302, valid metric: 0.6167\n",
            "Epoch 9/20, train loss: 0.4116, train metric: 0.6202, valid metric: 0.6450\n",
            "Epoch 10/20, train loss: 0.4085, train metric: 0.6198, valid metric: 0.5938\n",
            "Epoch 11/20, train loss: 0.4073, train metric: 0.6197, valid metric: 0.5959\n",
            "Epoch 12/20, train loss: 0.3914, train metric: 0.6078, valid metric: 0.6073\n",
            "Epoch 13/20, train loss: 0.3847, train metric: 0.6033, valid metric: 0.5815\n",
            "Epoch 14/20, train loss: 0.3849, train metric: 0.6048, valid metric: 0.6042\n",
            "Epoch 15/20, train loss: 0.3744, train metric: 0.5965, valid metric: 0.5740\n",
            "Epoch 16/20, train loss: 0.3690, train metric: 0.5928, valid metric: 0.6111\n",
            "Epoch 17/20, train loss: 0.3675, train metric: 0.5923, valid metric: 0.5766\n",
            "Epoch 18/20, train loss: 0.3606, train metric: 0.5869, valid metric: 0.5782\n",
            "Epoch 19/20, train loss: 0.3604, train metric: 0.5867, valid metric: 0.5664\n",
            "Epoch 20/20, train loss: 0.3566, train metric: 0.5837, valid metric: 0.5654\n"
          ]
        }
      ],
      "source": [
        "import torchmetrics\n",
        "\n",
        "def evaluate_multi_out(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()\n",
        "    with torch.no_grad():\n",
        "        for inputs, y_batch in data_loader:\n",
        "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred, _ = model(**inputs)\n",
        "            metric.update(y_pred, y_batch)\n",
        "    return metric.compute()\n",
        "\n",
        "def train_multi_out(model, optimizer, criterion, metric, train_loader,\n",
        "                   valid_loader, n_epochs):\n",
        "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        metric.reset()\n",
        "        for inputs, y_batch in train_loader:\n",
        "            model.train()\n",
        "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred, y_pred_aux = model(**inputs)\n",
        "            main_loss = criterion(y_pred, y_batch)\n",
        "            aux_loss = criterion(y_pred_aux, y_batch)\n",
        "            loss = 0.8 * main_loss + 0.2 * aux_loss\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            metric.update(y_pred, y_batch)\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        history[\"train_losses\"].append(mean_loss)\n",
        "        history[\"train_metrics\"].append(metric.compute().item())\n",
        "        history[\"valid_metrics\"].append(\n",
        "            evaluate_multi_out(model, valid_loader, metric).item())\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
        "    return history\n",
        "\n",
        "torch.manual_seed(42)\n",
        "learning_rate = 0.01\n",
        "model = WideAndDeepV4(n_features).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train_multi_out(model, optimizer, mse, rmse, train_loader_named,\n",
        "                          valid_loader_named, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlGZMWS3L5De"
      },
      "source": [
        "# Building an Image Classifier with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-F4sW86L5De"
      },
      "source": [
        "## Using TorchVision to Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba5bb1eb"
      },
      "source": [
        "This cell is responsible for loading and preparing the FashionMNIST dataset, a common benchmark for image classification tasks, using PyTorch's `torchvision` library. Here's a breakdown:\n",
        "\n",
        "*   **`import torchvision`** and **`import torchvision.transforms.v2 as T`**:\n",
        "    *   These lines import the necessary libraries. `torchvision` provides access to popular datasets, model architectures, and image transformations. `torchvision.transforms.v2` (aliased as `T`) offers advanced image processing utilities.\n",
        "\n",
        "*   **`toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)])`**:\n",
        "    *   This creates a `Compose` object, which chains together multiple image transformations. When applied to an image, it will first:\n",
        "        *   **`T.ToImage()`**: Convert the input (which might be a PIL Image or NumPy array) into a PyTorch `Image` tensor.\n",
        "        *   **`T.ToDtype(torch.float32, scale=True)`**: Convert the image tensor's data type to `torch.float32` and scale its pixel values to the range `[0.0, 1.0]`. This is a standard practice for neural network inputs.\n",
        "\n",
        "*   **`train_and_valid_data = torchvision.datasets.FashionMNIST(...)`**:\n",
        "    *   This line loads the training portion of the FashionMNIST dataset. `root=\"datasets\"` specifies where the data should be stored. `train=True` indicates the training set. `download=True` ensures the dataset is downloaded if it's not already present. `transform=toTensor` applies the defined transformations to each image as it's loaded.\n",
        "\n",
        "*   **`test_data = torchvision.datasets.FashionMNIST(...)`**:\n",
        "    *   Similar to the above, this loads the test portion of the FashionMNIST dataset (`train=False`).\n",
        "\n",
        "*   **`torch.manual_seed(42)`**:\n",
        "    *   Sets the random seed for PyTorch operations. This is crucial for reproducibility, ensuring that random splits or initializations yield the same results every time the code is run.\n",
        "\n",
        "*   **`train_data, valid_data = torch.utils.data.random_split(train_and_valid_data, [55_000, 5_000])`**:\n",
        "    *   This splits the `train_and_valid_data` (which initially contains 60,000 training samples) into two new datasets: `train_data` (55,000 samples) and `valid_data` (5,000 samples). This creates a dedicated validation set from the original training data, which is essential for monitoring model performance during training and tuning hyperparameters without touching the final test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "oLhYLbWKL5De",
        "outputId": "7610de03-16b1-4552-fa96-d31dd9a6f8bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.8MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 202kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.77MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 21.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms.v2 as T\n",
        "\n",
        "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)])\n",
        "\n",
        "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"datasets\", train=True, download=True, transform=toTensor)\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"datasets\", train=False, download=True, transform=toTensor)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_data, valid_data = torch.utils.data.random_split(\n",
        "    train_and_valid_data, [55_000, 5_000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "P87Id66PL5De"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=32)\n",
        "test_loader = DataLoader(test_data, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtP6m6gHL5De"
      },
      "source": [
        "Each entry is a tuple (image, target):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "WVUY08utL5De"
      },
      "outputs": [],
      "source": [
        "X_sample, y_sample = train_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtcS0U3_L5Df"
      },
      "source": [
        "Each image has a shape \\[channels, rows, columns\\]. Grayscale images like in Fashion MNIST have a single channel (while RGB images have 3, and other types of images, such as satellite images, may have many more). Fashion images are grayscale and 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "abVKhMr0L5Df",
        "outputId": "565d420a-ac24-4356-e3fb-62e0527c91ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "X_sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "6z0Om7W6L5Df",
        "outputId": "f2e4a8a1-5179-4611-a698-93ad302a3883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "X_sample.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "lvapAVgML5Df",
        "outputId": "a99156bd-a9d1-4b14-b0ad-f752c4b5a53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ankle boot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "train_and_valid_data.classes[y_sample]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMmv0-hKL5Df"
      },
      "source": [
        "## Building the Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9905bcad"
      },
      "source": [
        "This code cell defines a custom PyTorch neural network model named `ImageClassifier` and then initializes an instance of this model, along with the loss function to be used for training.\n",
        "\n",
        "### `ImageClassifier` Class Definition:\n",
        "\n",
        "*   **`class ImageClassifier(nn.Module):`**:\n",
        "    *   Defines a new class `ImageClassifier` that inherits from `nn.Module`. All custom PyTorch models must inherit from `nn.Module`.\n",
        "\n",
        "*   **`def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):`**:\n",
        "    *   This is the constructor for the model. It takes parameters defining the size of the input, hidden layers, and output layer.\n",
        "    *   **`super().__init__()`**: Calls the constructor of the parent `nn.Module` class, which is necessary for PyTorch to properly track layers and parameters.\n",
        "    *   **`self.mlp = nn.Sequential(...)`**: This creates a sequential container for the layers of the MLP (Multi-Layer Perceptron).\n",
        "        *   **`nn.Flatten()`**: This layer flattens the input image tensor (e.g., from `[batch_size, 1, 28, 28]` to `[batch_size, 784]`). It converts the 2D image data into a 1D vector per sample, which is required for fully connected (`nn.Linear`) layers.\n",
        "        *   **`nn.Linear(n_inputs, n_hidden1)`**: The first fully connected (dense) layer, mapping the flattened input features to `n_hidden1` neurons.\n",
        "        *   **`nn.ReLU()`**: The Rectified Linear Unit activation function, which introduces non-linearity to the model.\n",
        "        *   **`nn.Linear(n_hidden1, n_hidden2)`**: The second fully connected hidden layer, mapping `n_hidden1` neurons to `n_hidden2` neurons.\n",
        "        *   **`nn.ReLU()`**: Another ReLU activation function.\n",
        "        *   **`nn.Linear(n_hidden2, n_classes)`**: The output layer, mapping `n_hidden2` neurons to `n_classes` (the number of output categories). For classification tasks with `nn.CrossEntropyLoss`, this layer typically does *not* have an activation function like `softmax` because `CrossEntropyLoss` expects raw logits.\n",
        "\n",
        "*   **`def forward(self, X):`**:\n",
        "    *   This method defines the forward pass of the model. It describes how input data `X` flows through the network to produce an output.\n",
        "    *   **`return self.mlp(X)`**: Simply passes the input `X` through the `mlp` (sequential stack of layers) defined in the constructor.\n",
        "\n",
        "### Model Initialization and Loss Function Setup:\n",
        "\n",
        "*   **`model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=300, n_hidden2=100, n_classes=10).to(device)`**:\n",
        "    *   Creates an instance of the `ImageClassifier` model.\n",
        "        *   `n_inputs=1 * 28 * 28`: For FashionMNIST, images are 28x28 pixels with 1 channel (grayscale), so the total number of input features after flattening is 784.\n",
        "        *   `n_hidden1=300`, `n_hidden2=100`: Defines the number of neurons in the two hidden layers.\n",
        "        *   `n_classes=10`: FashionMNIST has 10 classes (types of clothing).\n",
        "    *   **`.to(device)`**: Moves the entire model (including its weights and biases) to the specified computation `device` (e.g., 'cuda' for GPU or 'cpu'). This is essential for leveraging hardware acceleration.\n",
        "\n",
        "*   **`xentropy = nn.CrossEntropyLoss()`**:\n",
        "    *   Initializes the `CrossEntropyLoss` function, which is commonly used for multi-class classification problems in PyTorch. As mentioned, this loss function internally applies `softmax` to the model's raw logits before calculating the cross-entropy, so your model's output layer should not have an explicit `softmax` activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "yZjteh3sL5Df"
      },
      "outputs": [],
      "source": [
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(n_inputs, n_hidden1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden1, n_hidden2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden2, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.mlp(X)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=300, n_hidden2=100,\n",
        "                        n_classes=10).to(device)\n",
        "xentropy = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "829931ba"
      },
      "source": [
        "This code cell configures the optimizer and the metric for evaluating the model, and then starts the training process.\n",
        "\n",
        "*   **`optimizer = torch.optim.SGD(model.parameters(), lr=0.1)`**:\n",
        "    *   This line initializes the **optimizer** for your model, using the Stochastic Gradient Descent (SGD) algorithm.\n",
        "        *   **`model.parameters()`**: This argument tells the optimizer *which* parameters (weights and biases) of your neural network `model` it should update. PyTorch automatically tracks all tensors within `model` that have `requires_grad=True`.\n",
        "        *   **`lr=0.1`**: This sets the **learning rate** to 0.1. The learning rate is a crucial hyperparameter that determines the step size taken during each gradient descent update.\n",
        "\n",
        "*   **`accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)`**:\n",
        "    *   This initializes an **accuracy metric** using the `torchmetrics` library.\n",
        "        *   **`torchmetrics.Accuracy`**: This is a dedicated accuracy metric provided by `torchmetrics`, designed to be efficient and correctly handle batch-wise calculations.\n",
        "        *   **`task=\"multiclass\"`**: Specifies that this is a multiclass classification problem.\n",
        "        *   **`num_classes=10`**: Indicates there are 10 distinct classes in the FashionMNIST dataset.\n",
        "        *   **`.to(device)`**: Moves the accuracy metric's internal state (if any) to the same computing `device` (e.g., GPU) as the model, ensuring consistent calculations.\n",
        "\n",
        "*   **`_ = train2(model, optimizer, xentropy, accuracy, train_loader, valid_loader, n_epochs)`**:\n",
        "    *   This is the function call that initiates the **training loop**.\n",
        "        *   **`train2`**: This is a custom training function (defined in a previous cell) that handles the epoch-based training process, including forward passes, loss calculation, backward passes, parameter updates, and tracking of training and validation metrics.\n",
        "        *   The arguments passed are the `model` to be trained, the `optimizer` to update parameters, the `xentropy` (CrossEntropyLoss) as the criterion (loss function), the `accuracy` metric, the `train_loader` for training data, the `valid_loader` for validation data, and `n_epochs` (the total number of training epochs, which was previously defined as 20)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "EksmBymYL5Df",
        "outputId": "0210406d-7e2e-4393-d649-c553fb47d24d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, train loss: 0.6058, train metric: 0.7816, valid metric: 0.8416\n",
            "Epoch 2/20, train loss: 0.4059, train metric: 0.8497, valid metric: 0.8372\n",
            "Epoch 3/20, train loss: 0.3633, train metric: 0.8663, valid metric: 0.8530\n",
            "Epoch 4/20, train loss: 0.3359, train metric: 0.8762, valid metric: 0.8660\n",
            "Epoch 5/20, train loss: 0.3147, train metric: 0.8835, valid metric: 0.8754\n",
            "Epoch 6/20, train loss: 0.2991, train metric: 0.8881, valid metric: 0.8666\n",
            "Epoch 7/20, train loss: 0.2859, train metric: 0.8916, valid metric: 0.8622\n",
            "Epoch 8/20, train loss: 0.2745, train metric: 0.8971, valid metric: 0.8722\n",
            "Epoch 9/20, train loss: 0.2639, train metric: 0.9007, valid metric: 0.8834\n",
            "Epoch 10/20, train loss: 0.2531, train metric: 0.9041, valid metric: 0.8810\n",
            "Epoch 11/20, train loss: 0.2463, train metric: 0.9068, valid metric: 0.8850\n",
            "Epoch 12/20, train loss: 0.2353, train metric: 0.9109, valid metric: 0.8910\n",
            "Epoch 13/20, train loss: 0.2303, train metric: 0.9125, valid metric: 0.8870\n",
            "Epoch 14/20, train loss: 0.2235, train metric: 0.9144, valid metric: 0.8734\n",
            "Epoch 15/20, train loss: 0.2154, train metric: 0.9184, valid metric: 0.8788\n",
            "Epoch 16/20, train loss: 0.2089, train metric: 0.9207, valid metric: 0.8826\n",
            "Epoch 17/20, train loss: 0.2030, train metric: 0.9234, valid metric: 0.8906\n",
            "Epoch 18/20, train loss: 0.1989, train metric: 0.9242, valid metric: 0.8884\n",
            "Epoch 19/20, train loss: 0.1924, train metric: 0.9271, valid metric: 0.8818\n",
            "Epoch 20/20, train loss: 0.1888, train metric: 0.9282, valid metric: 0.8716\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "_ = train2(model, optimizer, xentropy, accuracy, train_loader, valid_loader,\n",
        "           n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "Z3TjrE7UL5Df",
        "outputId": "df6e5ae2-d88e-4483-97cb-588bae0b22d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 4, 2], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "model.eval()\n",
        "X_new, y_new = next(iter(valid_loader))\n",
        "X_new = X_new[:3].to(device)\n",
        "with torch.no_grad():\n",
        "    y_pred_logits = model(X_new)\n",
        "y_pred = y_pred_logits.argmax(dim=1)  # index of the largest logit\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85d262b0"
      },
      "source": [
        "This code cell demonstrates how to use a trained PyTorch model to make predictions on new, unseen data, a process often referred to as **inference**.\n",
        "\n",
        "*   **`model.eval()`**:\n",
        "    *   This sets the model to evaluation mode. This is crucial during inference because certain layers (like `Dropout` and `BatchNorm`) behave differently during training and evaluation. In evaluation mode, `Dropout` layers are inactive (they don't drop units), and `BatchNorm` layers use their learned running statistics instead of batch statistics. This ensures consistent and deterministic predictions.\n",
        "\n",
        "*   **`X_new, y_new = next(iter(valid_loader))`**:\n",
        "    *   This line retrieves the *first batch* of data from the `valid_loader`. `iter(valid_loader)` creates an iterator, and `next()` gets the next item (which is a batch). `X_new` will contain the input images, and `y_new` will contain their corresponding true labels.\n",
        "\n",
        "*   **`X_new = X_new[:3].to(device)`**:\n",
        "    *   This takes only the first 3 samples from the retrieved batch (`X_new[:3]`) and moves them to the specified `device` (e.g., GPU). This is done to demonstrate prediction on a small subset of data.\n",
        "\n",
        "*   **`with torch.no_grad():`**:\n",
        "    *   This is a context manager that disables PyTorch's autograd engine. During inference, you don't need to compute gradients because you're not updating the model's weights. Disabling gradient computation offers several benefits:\n",
        "        *   **Reduced Memory Usage**: No intermediate activations or gradient information needs to be stored.\n",
        "        *   **Faster Computation**: Operations are faster because PyTorch doesn't perform the overhead of building the computation graph.\n",
        "        *   **Prevents Accidental Updates**: Ensures that no model parameters are accidentally modified.\n",
        "\n",
        "*   **`y_pred_logits = model(X_new)`**:\n",
        "    *   Inside the `torch.no_grad()` block, the `X_new` (input images) are passed through the `model`'s forward pass. The output, `y_pred_logits`, represents the raw scores (logits) generated by the model for each class for each input image. For classification, these are typically pre-softmax values.\n",
        "\n",
        "*   **`y_pred = y_pred_logits.argmax(dim=1)`**:\n",
        "    *   **`argmax(dim=1)`**: This function finds the index of the maximum value along `dimension 1` (which corresponds to the class dimension for a batch of predictions). The `argmax` operation effectively selects the class with the highest predicted logit score as the model's prediction for each sample.\n",
        "    *   `y_pred` will be a tensor containing the predicted class labels (as integers) for the `X_new` samples.\n",
        "\n",
        "*   **`y_pred`**:\n",
        "    *   This line simply displays the `y_pred` tensor, showing the predicted class indices for the first three samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "lg66d_DqL5Df",
        "outputId": "65000805-ed96-4fa4-ac98-ed8f41b3a338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sneaker', 'Coat', 'Pullover']"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "[train_and_valid_data.classes[index] for index in y_pred]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhdrCC3sL5Df"
      },
      "source": [
        "Let's check whether the model made the correct predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "H18CLprlL5Df",
        "outputId": "c001b4de-f895-409b-89cc-f797ff64f2cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "y_new[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU15LLSLL5Df"
      },
      "source": [
        "\n",
        "All correct! 😃\n",
        "\n",
        "What if we want the model's estimated probabilities?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e6ca8b9"
      },
      "source": [
        "This code cell calculates the estimated class probabilities from the model's raw output (logits) using the `softmax` activation function.\n",
        "\n",
        "*   **`import torch.nn.functional as F`**:\n",
        "    *   Imports the `torch.nn.functional` module, commonly aliased as `F`. This module provides various functions for neural network operations, including activation functions like `softmax`.\n",
        "\n",
        "*   **`y_proba = F.softmax(y_pred_logits, dim=1)`**:\n",
        "    *   This is the core step. The `F.softmax()` function is applied to `y_pred_logits` (the raw output from your model).\n",
        "        *   **`y_pred_logits`**: These are the unnormalized scores (logits) that the neural network outputs for each class. They can be positive, negative, or zero.\n",
        "        *   **`dim=1`**: This argument specifies that the `softmax` operation should be applied along `dimension 1` of the `y_pred_logits` tensor. In a typical classification output where `y_pred_logits` has a shape `[batch_size, num_classes]`, `dim=1` means that for each sample in the batch, the `softmax` is computed across its `num_classes` values. The result is a set of probabilities for each sample that sum to 1.\n",
        "    *   The `softmax` function converts the logits into a probability distribution, where each value is between 0 and 1, and the sum of probabilities for all classes for a given sample is 1.\n",
        "\n",
        "*   **`if device == \"mps\":\n",
        "    y_proba = y_proba.cpu()`**:\n",
        "    *   This is a conditional statement to handle a specific behavior for Apple Silicon (MPS) devices. On some PyTorch versions or configurations, `round()` might not be directly available or behave as expected on MPS tensors. Moving the tensor to the CPU (`.cpu()`) before rounding ensures consistent behavior across different devices, although it might incur a minor performance overhead if `round()` was directly supported on MPS.\n",
        "\n",
        "*   **`y_proba.round(decimals=3)`**:\n",
        "    *   This rounds the calculated probabilities to 3 decimal places for easier readability. The `round()` method (or function) is a utility to format the output, not to change the underlying precision of the `y_proba` tensor itself, which remains `float32` or `float64`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "1YWpNpYNL5Df",
        "outputId": "6f9ebc09-0640-45a7-a7b7-909353d901b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000, 0.9110, 0.0000,\n",
              "         0.0880],\n",
              "        [0.0000, 0.0000, 0.0040, 0.0000, 0.9960, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.6250, 0.0000, 0.3350, 0.0000, 0.0390, 0.0000, 0.0000,\n",
              "         0.0000]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "y_proba = F.softmax(y_pred_logits, dim=1)\n",
        "if device == \"mps\":\n",
        "    y_proba = y_proba.cpu()\n",
        "y_proba.round(decimals=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddc2cc44"
      },
      "source": [
        "This code cell extracts the top 4 predicted class probabilities and their corresponding indices (class labels) from the model's output logits. It's useful for understanding the model's confidence across its highest predictions.\n",
        "\n",
        "*   **`y_top4_values, y_top4_indices = torch.topk(y_pred_logits, k=4, dim=1)`**:\n",
        "    *   **`torch.topk()`**: This function is used to find the `k` largest elements along a given dimension of a tensor. It returns both the values and their original indices.\n",
        "        *   **`y_pred_logits`**: The raw output (logits) from the model for each class.\n",
        "        *   **`k=4`**: Specifies that we want to retrieve the 4 highest logit values.\n",
        "        *   **`dim=1`**: Indicates that the operation should be performed across the class dimension (for each sample in the batch).\n",
        "    *   `y_top4_values` will contain the 4 highest logit values for each sample.\n",
        "    *   `y_top4_indices` will contain the original class indices corresponding to those 4 highest logit values.\n",
        "\n",
        "*   **`y_top4_probas = F.softmax(y_top4_values, dim=1)`**:\n",
        "    *   The `F.softmax()` function is then applied specifically to these `y_top4_values`. This converts these top 4 logit values into a probability distribution. It's important to note that these probabilities will sum to 1 only *among themselves* (the top 4 classes), not across all 10 possible classes, because they are calculated only from the subset of selected logits.\n",
        "\n",
        "*   **`if device == \"mps\":\n",
        "    y_top4_probas = y_top4_probas.cpu()`**:\n",
        "    *   Similar to the previous cell, this ensures compatibility and correct behavior for `round()` operations if the `device` is Apple Silicon (MPS).\n",
        "\n",
        "*   **`y_top4_probas.round(decimals=3)`**:\n",
        "    *   Rounds the calculated top 4 probabilities to 3 decimal places for clearer display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "2iOV1jVAL5Df",
        "outputId": "8bc174e6-9604-49c5-8d43-add4a3503215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9110, 0.0880, 0.0010, 0.0000],\n",
              "        [0.9960, 0.0040, 0.0000, 0.0000],\n",
              "        [0.6250, 0.3350, 0.0390, 0.0000]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "y_top4_values, y_top4_indices = torch.topk(y_pred_logits, k=4, dim=1)\n",
        "y_top4_probas = F.softmax(y_top4_values, dim=1)\n",
        "if device == \"mps\":\n",
        "    y_top4_probas = y_top4_probas.cpu()\n",
        "y_top4_probas.round(decimals=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "qJNcalAFL5Df",
        "outputId": "da0c9d43-4348-45be-f962-1486c8b9b8a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7, 9, 5, 8],\n",
              "        [4, 2, 6, 0],\n",
              "        [2, 4, 6, 0]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "y_top4_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "951aaedc"
      },
      "source": [
        "This code cell calculates the total number of **trainable parameters** in your `model`.\n",
        "\n",
        "*   **`model.parameters()`**:\n",
        "    *   This is a method available for all `nn.Module` objects in PyTorch. It returns an iterator over all the parameters (weights and biases) that are part of the model and have `requires_grad=True`. These are the parameters that will be updated during the training process by the optimizer.\n",
        "\n",
        "*   **`param.numel()`**:\n",
        "    *   For each `param` (which is a tensor representing a weight matrix or a bias vector) obtained from `model.parameters()`, `param.numel()` returns the total number of elements (i.e., scalar values) within that tensor. For example, if a weight matrix has a shape of `(300, 784)`, `numel()` would return `300 * 784 = 235200`.\n",
        "\n",
        "*   **`[param.numel() for param in model.parameters()]`**:\n",
        "    *   This is a list comprehension that iterates through all the parameters in the model and calculates the number of elements for each parameter, creating a list of these counts.\n",
        "\n",
        "*   **`sum(...)`**:\n",
        "    *   Finally, the `sum()` function adds up all the numbers in the list generated by the list comprehension. The result is the grand total of all trainable scalar parameters (weights and biases) in the entire neural network model.\n",
        "\n",
        "This number gives you an idea of the model's complexity and size. A model with more parameters generally has a higher capacity to learn complex patterns but also requires more data to train effectively and is more prone to overfitting if not regularized properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "PmBrxyp_L5Df",
        "outputId": "4510fe3b-9f6b-4495-e09e-19f540b87264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "266610"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "sum([param.numel() for param in model.parameters()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM8Knnl1L5Df"
      },
      "source": [
        "# Hyperparameter Tuning using Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fe112d6"
      },
      "source": [
        "This code cell defines the `objective` function, which is the heart of hyperparameter tuning with the Optuna library.\n",
        "\n",
        "*   **`import optuna`**:\n",
        "    *   Imports the Optuna library, a popular open-source hyperparameter optimization framework.\n",
        "\n",
        "*   **`def objective(trial):`**:\n",
        "    *   This defines the `objective` function. Optuna will repeatedly call this function, passing in a `trial` object. The `trial` object is used to suggest hyperparameter values and report results.\n",
        "\n",
        "*   **`learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)`**:\n",
        "    *   This line asks Optuna's `trial` object to suggest a value for the `learning_rate` hyperparameter. It will sample a floating-point number between `1e-5` (0.00001) and `1e-1` (0.1). The `log=True` argument means that the sampling will be done on a logarithmic scale, which is often suitable for learning rates.\n",
        "\n",
        "*   **`n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)`**:\n",
        "    *   This suggests an integer value for `n_hidden`, representing the number of neurons in the hidden layers (in this case, both `n_hidden1` and `n_hidden2` are set to this value). The range for this integer is between 20 and 300, inclusive.\n",
        "\n",
        "*   **`model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=n_hidden, n_hidden2=n_hidden, n_classes=10).to(device)`**:\n",
        "    *   A new `ImageClassifier` model is instantiated using the suggested `n_hidden` value for both hidden layers. This ensures that each trial evaluates a model with a different architecture (or at least different hidden layer sizes).\n",
        "    *   The model is immediately moved to the appropriate `device` (CPU or GPU).\n",
        "\n",
        "*   **`optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)`**:\n",
        "    *   An `SGD` optimizer is set up for this trial's model, using the `learning_rate` suggested by Optuna.\n",
        "\n",
        "*   **`xentropy = nn.CrossEntropyLoss()`**:\n",
        "    *   The `CrossEntropyLoss` function is initialized as the criterion for this trial.\n",
        "\n",
        "*   **`accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)`** and **`accuracy = accuracy.to(device)`**:\n",
        "    *   A `torchmetrics.Accuracy` object is created and moved to the device to evaluate the model's performance during training.\n",
        "\n",
        "*   **`history = train2(model, optimizer, xentropy, accuracy, train_loader, valid_loader, n_epochs=10)`**:\n",
        "    *   The `train2` function (defined earlier) is called to train the model using the current set of hyperparameters for 10 epochs. The `history` object contains the training and validation metrics over these epochs.\n",
        "\n",
        "*   **`validation_accuracy = max(history[\"valid_metrics\"])`**:\n",
        "    *   From the `history` of the training, the best (maximum) validation accuracy achieved across the 10 epochs is extracted. This is the metric that Optuna will try to maximize.\n",
        "\n",
        "*   **`return validation_accuracy`**:\n",
        "    *   The best validation accuracy is returned by the `objective` function. Optuna uses this return value to guide its search for optimal hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "mXSLsEJSL5Df"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
        "    model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=n_hidden,\n",
        "                            n_hidden2=n_hidden, n_classes=10).to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    xentropy = nn.CrossEntropyLoss()\n",
        "    accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "    accuracy = accuracy.to(device)\n",
        "    history = train2(model, optimizer, xentropy, accuracy, train_loader,\n",
        "                     valid_loader, n_epochs=10)\n",
        "    validation_accuracy = max(history[\"valid_metrics\"])\n",
        "    return validation_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1be0c4e5"
      },
      "source": [
        "This code cell sets up and initiates the hyperparameter optimization study using Optuna.\n",
        "\n",
        "*   **`sampler = optuna.samplers.TPESampler(seed=42)`**:\n",
        "    *   Initializes a `TPESampler` (Tree-structured Parzen Estimator) from Optuna. This is a popular and effective sampling algorithm that adaptively proposes new hyperparameter combinations based on the performance of previously evaluated trials. Setting `seed=42` ensures that the sampling process itself is reproducible.\n",
        "\n",
        "*   **`study = optuna.create_study(direction=\"maximize\", sampler=sampler)`**:\n",
        "    *   Creates an Optuna `Study` object. A study is the central object in Optuna, managing the optimization process.\n",
        "        *   **`direction=\"maximize\"`**: Specifies that Optuna should try to maximize the objective function's return value (in our case, validation accuracy).\n",
        "        *   **`sampler=sampler`**: Assigns the previously defined `TPESampler` to this study.\n",
        "\n",
        "*   **`study.optimize(objective, n_trials=5)`**:\n",
        "    *   This is the core call that starts the hyperparameter optimization.\n",
        "        *   **`objective`**: The function that Optuna will call repeatedly. Each call to `objective` constitutes a `trial`, where a model is trained and evaluated with a specific set of suggested hyperparameters.\n",
        "        *   **`n_trials=5`**: Specifies that Optuna should run 5 independent trials. In each trial, it will suggest a set of hyperparameters, execute the `objective` function, and record the result. The `TPESampler` will use the results of earlier trials to inform its suggestions for later trials, aiming to converge on better hyperparameters. In other words, a trial represents one complete execution of the objective function\n",
        "        *   `Epochs` deal with how much a single model instance trains on its data while `trials` deal with how many different hyperparameter configurations are tested to find the best-performing model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "zPCGmNp2L5Df",
        "outputId": "d99d858b-d1cc-4921-c148-0ec82432da8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 17:32:49,629] A new study created in memory with name: no-name-34cd8563-98c2-4f11-a447-d4568504b7be\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 2.2769, train metric: 0.1471, valid metric: 0.1860\n",
            "Epoch 2/10, train loss: 2.2093, train metric: 0.2794, valid metric: 0.3500\n",
            "Epoch 3/10, train loss: 2.1164, train metric: 0.4110, valid metric: 0.4554\n",
            "Epoch 4/10, train loss: 1.9776, train metric: 0.5137, valid metric: 0.5562\n",
            "Epoch 5/10, train loss: 1.7867, train metric: 0.5826, valid metric: 0.6026\n",
            "Epoch 6/10, train loss: 1.5775, train metric: 0.6184, valid metric: 0.6228\n",
            "Epoch 7/10, train loss: 1.3978, train metric: 0.6288, valid metric: 0.6326\n",
            "Epoch 8/10, train loss: 1.2605, train metric: 0.6360, valid metric: 0.6372\n",
            "Epoch 9/10, train loss: 1.1572, train metric: 0.6468, valid metric: 0.6424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 17:35:19,747] Trial 0 finished with value: 0.6435999870300293 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.6435999870300293.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 1.0782, train metric: 0.6537, valid metric: 0.6436\n",
            "Epoch 1/10, train loss: 1.1459, train metric: 0.6229, valid metric: 0.7338\n",
            "Epoch 2/10, train loss: 0.6108, train metric: 0.7841, valid metric: 0.7992\n",
            "Epoch 3/10, train loss: 0.5203, train metric: 0.8169, valid metric: 0.8094\n",
            "Epoch 4/10, train loss: 0.4810, train metric: 0.8302, valid metric: 0.8310\n",
            "Epoch 5/10, train loss: 0.4557, train metric: 0.8404, valid metric: 0.8352\n",
            "Epoch 6/10, train loss: 0.4387, train metric: 0.8460, valid metric: 0.8442\n",
            "Epoch 7/10, train loss: 0.4240, train metric: 0.8512, valid metric: 0.8408\n",
            "Epoch 8/10, train loss: 0.4123, train metric: 0.8566, valid metric: 0.8514\n",
            "Epoch 9/10, train loss: 0.3998, train metric: 0.8601, valid metric: 0.8532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 17:37:48,374] Trial 1 finished with value: 0.8547999858856201 and parameters: {'learning_rate': 0.008471801418819975, 'n_hidden': 188}. Best is trial 1 with value: 0.8547999858856201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 0.3897, train metric: 0.8638, valid metric: 0.8548\n",
            "Epoch 1/10, train loss: 2.3069, train metric: 0.1144, valid metric: 0.1082\n",
            "Epoch 2/10, train loss: 2.2993, train metric: 0.1231, valid metric: 0.1294\n",
            "Epoch 3/10, train loss: 2.2914, train metric: 0.1606, valid metric: 0.1710\n",
            "Epoch 4/10, train loss: 2.2836, train metric: 0.1839, valid metric: 0.1840\n",
            "Epoch 5/10, train loss: 2.2762, train metric: 0.1891, valid metric: 0.1856\n",
            "Epoch 6/10, train loss: 2.2692, train metric: 0.1910, valid metric: 0.1898\n",
            "Epoch 7/10, train loss: 2.2623, train metric: 0.1933, valid metric: 0.1932\n",
            "Epoch 8/10, train loss: 2.2554, train metric: 0.2000, valid metric: 0.2022\n",
            "Epoch 9/10, train loss: 2.2485, train metric: 0.2122, valid metric: 0.2160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 17:40:16,510] Trial 2 finished with value: 0.23340000212192535 and parameters: {'learning_rate': 4.207988669606632e-05, 'n_hidden': 63}. Best is trial 1 with value: 0.8547999858856201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 2.2414, train metric: 0.2299, valid metric: 0.2334\n",
            "Epoch 1/10, train loss: 2.3035, train metric: 0.1373, valid metric: 0.1526\n",
            "Epoch 2/10, train loss: 2.3005, train metric: 0.1569, valid metric: 0.1724\n",
            "Epoch 3/10, train loss: 2.2975, train metric: 0.1755, valid metric: 0.1896\n",
            "Epoch 4/10, train loss: 2.2945, train metric: 0.1941, valid metric: 0.2132\n",
            "Epoch 5/10, train loss: 2.2914, train metric: 0.2105, valid metric: 0.2288\n",
            "Epoch 6/10, train loss: 2.2884, train metric: 0.2261, valid metric: 0.2418\n",
            "Epoch 7/10, train loss: 2.2853, train metric: 0.2419, valid metric: 0.2580\n",
            "Epoch 8/10, train loss: 2.2823, train metric: 0.2581, valid metric: 0.2742\n",
            "Epoch 9/10, train loss: 2.2792, train metric: 0.2736, valid metric: 0.2918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 17:42:44,033] Trial 3 finished with value: 0.30959999561309814 and parameters: {'learning_rate': 1.7073967431528103e-05, 'n_hidden': 263}. Best is trial 1 with value: 0.8547999858856201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 2.2761, train metric: 0.2897, valid metric: 0.3096\n",
            "Epoch 1/10, train loss: 1.8379, train metric: 0.4869, valid metric: 0.6208\n",
            "Epoch 2/10, train loss: 0.9751, train metric: 0.6666, valid metric: 0.6978\n",
            "Epoch 3/10, train loss: 0.7608, train metric: 0.7253, valid metric: 0.7416\n",
            "Epoch 4/10, train loss: 0.6704, train metric: 0.7639, valid metric: 0.7720\n",
            "Epoch 5/10, train loss: 0.6108, train metric: 0.7913, valid metric: 0.7906\n",
            "Epoch 6/10, train loss: 0.5687, train metric: 0.8053, valid metric: 0.8050\n",
            "Epoch 7/10, train loss: 0.5386, train metric: 0.8164, valid metric: 0.8082\n",
            "Epoch 8/10, train loss: 0.5158, train metric: 0.8243, valid metric: 0.8214\n",
            "Epoch 9/10, train loss: 0.4988, train metric: 0.8279, valid metric: 0.8220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 17:45:14,400] Trial 4 finished with value: 0.8220000267028809 and parameters: {'learning_rate': 0.002537815508265664, 'n_hidden': 218}. Best is trial 1 with value: 0.8547999858856201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 0.4842, train metric: 0.8330, valid metric: 0.8092\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
        "study.optimize(objective, n_trials=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "fbBWrbHuL5Df",
        "outputId": "ba73e3eb-1494-4132-dd0d-06b6a16b6ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.008471801418819975, 'n_hidden': 188}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "iPXVi2bPL5Df",
        "outputId": "c7241ed0-a298-4870-f81f-59e1fb9552a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8547999858856201"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "study.best_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ba684d"
      },
      "source": [
        "This code cell defines an updated `objective` function for Optuna hyperparameter tuning, which is more robust as it incorporates **early stopping (pruning)**.\n",
        "\n",
        "### Differences from the Previous `objective` Function:\n",
        "\n",
        "1.  **Data Loaders as Arguments**: The function now explicitly accepts `train_loader` and `valid_loader` as arguments: `def objective(trial, train_loader, valid_loader):`. In the previous version, these were implicitly available in the global scope where `objective` was defined.\n",
        "\n",
        "2.  **Iterative Training within the Objective**: Instead of calling `train2` once for all `n_epochs`, this version includes a loop `for epoch in range(n_epochs):`.\n",
        "    *   Inside this loop, `train2` is called for *one epoch at a time* (`n_epochs=1`). This allows Optuna to monitor the trial's performance epoch by epoch.\n",
        "    *   the actual number of epochs for a not-pruned trial is determined by the n_epochs in the objective function's for loop (e.g., 20 epochs in your case)\n",
        "\n",
        "3.  **Tracking `best_validation_accuracy`**: The function now keeps track of the `best_validation_accuracy` achieved over the epochs within a single trial. This ensures that the function returns the *peak* performance of that hyperparameter configuration, not just the performance from the last epoch.\n",
        "\n",
        "4.  **`trial.report(validation_accuracy, epoch)`**: This is a key addition for Optuna's pruning functionality.\n",
        "    *   At the end of each epoch, the current `validation_accuracy` and the `epoch` number are reported to Optuna. This allows Optuna's pruner to track the performance of the trial over time.\n",
        "\n",
        "5.  **`if trial.should_prune(): raise optuna.TrialPruned()`**: This is the core of **early stopping (pruning)**.\n",
        "    *   After reporting the current performance, `trial.should_prune()` is called. Optuna's `pruner` (which we will define shortly, e.g., `MedianPruner`) analyzes the reported intermediate results of the current trial against other trials.\n",
        "    *   If the pruner determines that the current trial is unlikely to yield better results than already-found good trials, it returns `True`.\n",
        "    *   When `True`, a `optuna.TrialPruned()` exception is raised, which immediately stops the current trial. This saves computational resources by avoiding the completion of unpromising trials, allowing Optuna to focus on more promising hyperparameter combinations faster.\n",
        "\n",
        "### How it Works:\n",
        "\n",
        "This enhanced `objective` function allows Optuna to not only search for good hyperparameters but also to intelligently stop training models that are underperforming early on. This can significantly speed up the hyperparameter tuning process, especially when training each trial takes a considerable amount of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "I6QaCBf-L5Df"
      },
      "outputs": [],
      "source": [
        "def objective(trial, train_loader, valid_loader):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
        "    model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=n_hidden,\n",
        "                            n_hidden2=n_hidden, n_classes=10).to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    xentropy = nn.CrossEntropyLoss()\n",
        "    accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "    accuracy = accuracy.to(device)\n",
        "    best_validation_accuracy = 0.0\n",
        "    for epoch in range(n_epochs):\n",
        "        history = train2(model, optimizer, xentropy, accuracy, train_loader,\n",
        "                         valid_loader, n_epochs=1)\n",
        "        validation_accuracy = max(history[\"valid_metrics\"])\n",
        "        if validation_accuracy > best_validation_accuracy:\n",
        "            best_validation_accuracy = validation_accuracy\n",
        "        trial.report(validation_accuracy, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "    return best_validation_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed14f9a"
      },
      "source": [
        "These two consecutive cells both aim to create a callable object (`objective_with_data`) that, when called with a `trial` argument, will internally call our `objective` function with the `trial` *and* the `train_loader` and `valid_loader` already provided.\n",
        "\n",
        "They achieve the same functional outcome, but use slightly different Python constructs:\n",
        "\n",
        "1.  **`objective_with_data = lambda trial: objective(trial, train_loader=train_loader, valid_loader=valid_loader)`**:\n",
        "    *   This uses a `lambda` function, which is a small, anonymous function defined in-line.\n",
        "    *   It defines a new function that takes `trial` as its only explicit argument.\n",
        "    *   When `objective_with_data(some_trial)` is called, it executes `objective(some_trial, train_loader=train_loader, valid_loader=valid_loader)`, effectively passing the pre-set data loaders.\n",
        "    *   **Pros**: Simple and concise for straightforward one-liner functions.\n",
        "    *   **Cons**: Can become less readable for more complex argument bindings or multi-line logic.\n",
        "\n",
        "2.  **`from functools import partial\n",
        "objective_with_data = partial(objective, train_loader=train_loader, valid_loader=valid_loader)`**:\n",
        "    *   This uses `functools.partial`, which is a standard library function designed specifically for partial application of functions.\n",
        "    *   `partial()` returns a new callable object that behaves like `objective`, but with some of its arguments pre-filled.\n",
        "    *   When `objective_with_data(some_trial)` is called, `partial` correctly passes `some_trial` as the first positional argument to `objective`, while `train_loader` and `valid_loader` are passed as keyword arguments as specified during its creation.\n",
        "    *   **Pros**: Explicitly designed for this use case, often considered more idiomatic and robust for partial function application, especially when dealing with many arguments or more complex function signatures. Can be slightly more efficient as it doesn't create a new function scope every time like a lambda might in some contexts.\n",
        "    *   **Cons**: Requires an import from `functools`, and for very simple cases, `lambda` might appear slightly shorter.\n",
        "\n",
        "Both cells achieve the exact same effect in this specific context: they create a version of the `objective` function that is ready to be called by `study.optimize()` (which only provides the `trial` argument) while still having access to the necessary `train_loader` and `valid_loader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "KuY2g6azL5Df"
      },
      "outputs": [],
      "source": [
        "objective_with_data = lambda trial: objective(\n",
        "    trial, train_loader=train_loader, valid_loader=valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "qiqXYsE7L5Df"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "objective_with_data = partial(objective, train_loader=train_loader,\n",
        "                              valid_loader=valid_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5574bedd"
      },
      "source": [
        "This code cell sets up and initiates the hyperparameter optimization study using Optuna, incorporating a pruning strategy to accelerate the search.\n",
        "\n",
        "*   **`torch.manual_seed(42)`**:\n",
        "    *   Sets the random seed for PyTorch, ensuring reproducibility of model training within each trial.\n",
        "\n",
        "*   **`sampler = optuna.samplers.TPESampler(seed=42)`**:\n",
        "    *   Initializes a `TPESampler` (Tree-structured Parzen Estimator). This sampling algorithm intelligently proposes new hyperparameter combinations based on the performance of previously evaluated trials. The `seed=42` ensures reproducible sampling.\n",
        "\n",
        "*   **`pruner = optuna.pruners.MedianPruner()`**:\n",
        "    *   This is a significant addition compared to the previous study setup. A `MedianPruner` is initialized. Pruners are strategies that Optuna uses to **stop unpromising trials early** during the optimization process.\n",
        "        *   The `MedianPruner` works by comparing the intermediate performance of a trial (reported epoch by epoch by the `objective` function) to the median performance of other trials that have completed the same number of steps (epochs).\n",
        "        *   If a trial's performance falls below this median threshold, it is deemed unpromising and is *pruned* (stopped prematurely). This saves computational resources by not completing full training for hyperparameter sets that are unlikely to yield good results.\n",
        "\n",
        "*   **`study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)`**:\n",
        "    *   Creates an Optuna `Study` object. Here, the `pruner` is passed to the study, enabling the early stopping mechanism.\n",
        "        *   **`direction=\"maximize\"`**: Specifies that Optuna should try to maximize the objective function's return value (validation accuracy).\n",
        "        *   **`sampler=sampler`**: Assigns the `TPESampler` to guide hyperparameter suggestions.\n",
        "        *   **`pruner=pruner`**: Integrates the `MedianPruner` into the study.\n",
        "\n",
        "*   **`study.optimize(objective_with_data, n_trials=20)`**:\n",
        "    *   Starts the hyperparameter optimization process.\n",
        "        *   **`objective_with_data`**: The `objective` function (which was previously wrapped with `partial` or `lambda`) is called repeatedly.\n",
        "        *   **`n_trials=20`**: Optuna will attempt to run 20 trials. However, due to the `pruner`, some of these trials might be stopped early if they are not performing well, meaning not all 20 trials will necessarily complete all epochs specified within the `objective` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "WjZ4W5k9L5Df",
        "outputId": "c975886e-edc1-43d5-fc64-69785a6fd24c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 17:45:14,455] A new study created in memory with name: no-name-dd0dabd5-c23e-485a-bbbb-52c2c7391a4b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 2.2769, train metric: 0.1471, valid metric: 0.1860\n",
            "Epoch 1/1, train loss: 2.2093, train metric: 0.2794, valid metric: 0.3500\n",
            "Epoch 1/1, train loss: 2.1164, train metric: 0.4110, valid metric: 0.4554\n",
            "Epoch 1/1, train loss: 1.9776, train metric: 0.5137, valid metric: 0.5562\n",
            "Epoch 1/1, train loss: 1.7867, train metric: 0.5826, valid metric: 0.6026\n",
            "Epoch 1/1, train loss: 1.5775, train metric: 0.6184, valid metric: 0.6228\n",
            "Epoch 1/1, train loss: 1.3978, train metric: 0.6288, valid metric: 0.6326\n",
            "Epoch 1/1, train loss: 1.2605, train metric: 0.6360, valid metric: 0.6372\n",
            "Epoch 1/1, train loss: 1.1572, train metric: 0.6468, valid metric: 0.6424\n",
            "Epoch 1/1, train loss: 1.0782, train metric: 0.6537, valid metric: 0.6436\n",
            "Epoch 1/1, train loss: 1.0162, train metric: 0.6611, valid metric: 0.6530\n",
            "Epoch 1/1, train loss: 0.9665, train metric: 0.6689, valid metric: 0.6620\n",
            "Epoch 1/1, train loss: 0.9258, train metric: 0.6761, valid metric: 0.6700\n",
            "Epoch 1/1, train loss: 0.8919, train metric: 0.6835, valid metric: 0.6782\n",
            "Epoch 1/1, train loss: 0.8629, train metric: 0.6897, valid metric: 0.6848\n",
            "Epoch 1/1, train loss: 0.8381, train metric: 0.6954, valid metric: 0.6876\n",
            "Epoch 1/1, train loss: 0.8166, train metric: 0.7009, valid metric: 0.6932\n",
            "Epoch 1/1, train loss: 0.7974, train metric: 0.7073, valid metric: 0.6964\n",
            "Epoch 1/1, train loss: 0.7802, train metric: 0.7119, valid metric: 0.7090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 17:50:22,348] Trial 0 finished with value: 0.7089999914169312 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.7089999914169312.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.7647, train metric: 0.7196, valid metric: 0.7082\n",
            "Epoch 1/1, train loss: 1.1485, train metric: 0.6157, valid metric: 0.7332\n",
            "Epoch 1/1, train loss: 0.6133, train metric: 0.7864, valid metric: 0.8082\n",
            "Epoch 1/1, train loss: 0.5200, train metric: 0.8179, valid metric: 0.8136\n",
            "Epoch 1/1, train loss: 0.4783, train metric: 0.8311, valid metric: 0.8232\n",
            "Epoch 1/1, train loss: 0.4533, train metric: 0.8402, valid metric: 0.8020\n",
            "Epoch 1/1, train loss: 0.4357, train metric: 0.8465, valid metric: 0.8446\n",
            "Epoch 1/1, train loss: 0.4211, train metric: 0.8510, valid metric: 0.8276\n",
            "Epoch 1/1, train loss: 0.4083, train metric: 0.8562, valid metric: 0.8398\n",
            "Epoch 1/1, train loss: 0.3981, train metric: 0.8606, valid metric: 0.8532\n",
            "Epoch 1/1, train loss: 0.3881, train metric: 0.8640, valid metric: 0.8582\n",
            "Epoch 1/1, train loss: 0.3782, train metric: 0.8663, valid metric: 0.8532\n",
            "Epoch 1/1, train loss: 0.3699, train metric: 0.8693, valid metric: 0.8566\n",
            "Epoch 1/1, train loss: 0.3631, train metric: 0.8712, valid metric: 0.8574\n",
            "Epoch 1/1, train loss: 0.3554, train metric: 0.8745, valid metric: 0.8494\n",
            "Epoch 1/1, train loss: 0.3477, train metric: 0.8764, valid metric: 0.8672\n",
            "Epoch 1/1, train loss: 0.3420, train metric: 0.8786, valid metric: 0.8520\n",
            "Epoch 1/1, train loss: 0.3366, train metric: 0.8807, valid metric: 0.8680\n",
            "Epoch 1/1, train loss: 0.3299, train metric: 0.8820, valid metric: 0.8666\n",
            "Epoch 1/1, train loss: 0.3246, train metric: 0.8841, valid metric: 0.8672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 17:55:29,858] Trial 1 finished with value: 0.8679999709129333 and parameters: {'learning_rate': 0.008471801418819975, 'n_hidden': 188}. Best is trial 1 with value: 0.8679999709129333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.3191, train metric: 0.8862, valid metric: 0.8638\n",
            "Epoch 1/1, train loss: 2.2998, train metric: 0.1078, valid metric: 0.1152\n",
            "Epoch 1/1, train loss: 2.2923, train metric: 0.1305, valid metric: 0.1432\n",
            "Epoch 1/1, train loss: 2.2856, train metric: 0.1605, valid metric: 0.1704\n",
            "Epoch 1/1, train loss: 2.2797, train metric: 0.1872, valid metric: 0.1912\n",
            "Epoch 1/1, train loss: 2.2744, train metric: 0.2091, valid metric: 0.2114\n",
            "Epoch 1/1, train loss: 2.2693, train metric: 0.2230, valid metric: 0.2216\n",
            "Epoch 1/1, train loss: 2.2643, train metric: 0.2332, valid metric: 0.2320\n",
            "Epoch 1/1, train loss: 2.2591, train metric: 0.2408, valid metric: 0.2380\n",
            "Epoch 1/1, train loss: 2.2538, train metric: 0.2456, valid metric: 0.2424\n",
            "Epoch 1/1, train loss: 2.2481, train metric: 0.2493, valid metric: 0.2456\n",
            "Epoch 1/1, train loss: 2.2422, train metric: 0.2511, valid metric: 0.2464\n",
            "Epoch 1/1, train loss: 2.2360, train metric: 0.2534, valid metric: 0.2476\n",
            "Epoch 1/1, train loss: 2.2296, train metric: 0.2538, valid metric: 0.2478\n",
            "Epoch 1/1, train loss: 2.2229, train metric: 0.2535, valid metric: 0.2482\n",
            "Epoch 1/1, train loss: 2.2160, train metric: 0.2544, valid metric: 0.2492\n",
            "Epoch 1/1, train loss: 2.2086, train metric: 0.2549, valid metric: 0.2508\n",
            "Epoch 1/1, train loss: 2.2009, train metric: 0.2561, valid metric: 0.2522\n",
            "Epoch 1/1, train loss: 2.1928, train metric: 0.2572, valid metric: 0.2520\n",
            "Epoch 1/1, train loss: 2.1842, train metric: 0.2582, valid metric: 0.2526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:00:40,725] Trial 2 finished with value: 0.25380000472068787 and parameters: {'learning_rate': 4.207988669606632e-05, 'n_hidden': 63}. Best is trial 1 with value: 0.8679999709129333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 2.1751, train metric: 0.2610, valid metric: 0.2538\n",
            "Epoch 1/1, train loss: 2.3015, train metric: 0.0997, valid metric: 0.1028\n",
            "Epoch 1/1, train loss: 2.2984, train metric: 0.1009, valid metric: 0.1050\n",
            "Epoch 1/1, train loss: 2.2953, train metric: 0.1051, valid metric: 0.1124\n",
            "Epoch 1/1, train loss: 2.2923, train metric: 0.1160, valid metric: 0.1270\n",
            "Epoch 1/1, train loss: 2.2894, train metric: 0.1347, valid metric: 0.1496\n",
            "Epoch 1/1, train loss: 2.2865, train metric: 0.1548, valid metric: 0.1652\n",
            "Epoch 1/1, train loss: 2.2837, train metric: 0.1699, valid metric: 0.1800\n",
            "Epoch 1/1, train loss: 2.2808, train metric: 0.1800, valid metric: 0.1872\n",
            "Epoch 1/1, train loss: 2.2780, train metric: 0.1855, valid metric: 0.1916\n",
            "Epoch 1/1, train loss: 2.2752, train metric: 0.1893, valid metric: 0.1960\n",
            "Epoch 1/1, train loss: 2.2725, train metric: 0.1950, valid metric: 0.2008\n",
            "Epoch 1/1, train loss: 2.2697, train metric: 0.2000, valid metric: 0.2026\n",
            "Epoch 1/1, train loss: 2.2669, train metric: 0.2058, valid metric: 0.2046\n",
            "Epoch 1/1, train loss: 2.2641, train metric: 0.2124, valid metric: 0.2116\n",
            "Epoch 1/1, train loss: 2.2613, train metric: 0.2177, valid metric: 0.2166\n",
            "Epoch 1/1, train loss: 2.2585, train metric: 0.2238, valid metric: 0.2224\n",
            "Epoch 1/1, train loss: 2.2556, train metric: 0.2289, valid metric: 0.2264\n",
            "Epoch 1/1, train loss: 2.2528, train metric: 0.2339, valid metric: 0.2314\n",
            "Epoch 1/1, train loss: 2.2498, train metric: 0.2383, valid metric: 0.2342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:05:54,067] Trial 3 finished with value: 0.23960000276565552 and parameters: {'learning_rate': 1.7073967431528103e-05, 'n_hidden': 263}. Best is trial 1 with value: 0.8679999709129333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 2.2469, train metric: 0.2429, valid metric: 0.2396\n",
            "Epoch 1/1, train loss: 1.8945, train metric: 0.4923, valid metric: 0.6290\n",
            "Epoch 1/1, train loss: 1.0016, train metric: 0.6582, valid metric: 0.6772\n",
            "Epoch 1/1, train loss: 0.7747, train metric: 0.7115, valid metric: 0.7248\n",
            "Epoch 1/1, train loss: 0.6864, train metric: 0.7551, valid metric: 0.7596\n",
            "Epoch 1/1, train loss: 0.6268, train metric: 0.7833, valid metric: 0.7806\n",
            "Epoch 1/1, train loss: 0.5830, train metric: 0.8000, valid metric: 0.7864\n",
            "Epoch 1/1, train loss: 0.5500, train metric: 0.8113, valid metric: 0.8064\n",
            "Epoch 1/1, train loss: 0.5252, train metric: 0.8184, valid metric: 0.8130\n",
            "Epoch 1/1, train loss: 0.5061, train metric: 0.8238, valid metric: 0.8204\n",
            "Epoch 1/1, train loss: 0.4908, train metric: 0.8290, valid metric: 0.8206\n",
            "Epoch 1/1, train loss: 0.4777, train metric: 0.8338, valid metric: 0.8150\n",
            "Epoch 1/1, train loss: 0.4681, train metric: 0.8375, valid metric: 0.8304\n",
            "Epoch 1/1, train loss: 0.4591, train metric: 0.8403, valid metric: 0.8320\n",
            "Epoch 1/1, train loss: 0.4516, train metric: 0.8429, valid metric: 0.8314\n",
            "Epoch 1/1, train loss: 0.4447, train metric: 0.8460, valid metric: 0.8346\n",
            "Epoch 1/1, train loss: 0.4380, train metric: 0.8474, valid metric: 0.8360\n",
            "Epoch 1/1, train loss: 0.4321, train metric: 0.8496, valid metric: 0.8378\n",
            "Epoch 1/1, train loss: 0.4272, train metric: 0.8512, valid metric: 0.8364\n",
            "Epoch 1/1, train loss: 0.4223, train metric: 0.8528, valid metric: 0.8406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:11:04,706] Trial 4 finished with value: 0.8429999947547913 and parameters: {'learning_rate': 0.002537815508265664, 'n_hidden': 218}. Best is trial 1 with value: 0.8679999709129333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.4173, train metric: 0.8556, valid metric: 0.8430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:11:20,330] Trial 5 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 2.3017, train metric: 0.1007, valid metric: 0.1056\n",
            "Epoch 1/1, train loss: 0.8584, train metric: 0.7026, valid metric: 0.7982\n",
            "Epoch 1/1, train loss: 0.5069, train metric: 0.8211, valid metric: 0.8228\n",
            "Epoch 1/1, train loss: 0.4499, train metric: 0.8404, valid metric: 0.8340\n",
            "Epoch 1/1, train loss: 0.4183, train metric: 0.8517, valid metric: 0.8512\n",
            "Epoch 1/1, train loss: 0.3936, train metric: 0.8579, valid metric: 0.8478\n",
            "Epoch 1/1, train loss: 0.3755, train metric: 0.8661, valid metric: 0.8520\n",
            "Epoch 1/1, train loss: 0.3602, train metric: 0.8699, valid metric: 0.8640\n",
            "Epoch 1/1, train loss: 0.3477, train metric: 0.8746, valid metric: 0.8666\n",
            "Epoch 1/1, train loss: 0.3359, train metric: 0.8784, valid metric: 0.8712\n",
            "Epoch 1/1, train loss: 0.3264, train metric: 0.8823, valid metric: 0.8712\n",
            "Epoch 1/1, train loss: 0.3180, train metric: 0.8846, valid metric: 0.8698\n",
            "Epoch 1/1, train loss: 0.3097, train metric: 0.8864, valid metric: 0.8784\n",
            "Epoch 1/1, train loss: 0.3021, train metric: 0.8903, valid metric: 0.8666\n",
            "Epoch 1/1, train loss: 0.2951, train metric: 0.8917, valid metric: 0.8710\n",
            "Epoch 1/1, train loss: 0.2887, train metric: 0.8942, valid metric: 0.8698\n",
            "Epoch 1/1, train loss: 0.2824, train metric: 0.8964, valid metric: 0.8716\n",
            "Epoch 1/1, train loss: 0.2762, train metric: 0.8993, valid metric: 0.8806\n",
            "Epoch 1/1, train loss: 0.2699, train metric: 0.9011, valid metric: 0.8802\n",
            "Epoch 1/1, train loss: 0.2646, train metric: 0.9036, valid metric: 0.8776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:16:23,649] Trial 6 finished with value: 0.8853999972343445 and parameters: {'learning_rate': 0.021368329072358756, 'n_hidden': 79}. Best is trial 6 with value: 0.8853999972343445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.2600, train metric: 0.9043, valid metric: 0.8854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:16:38,689] Trial 7 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 2.2926, train metric: 0.1081, valid metric: 0.1064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:16:53,457] Trial 8 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 2.2836, train metric: 0.1225, valid metric: 0.1526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:17:08,025] Trial 9 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 2.2631, train metric: 0.2483, valid metric: 0.3554\n",
            "Epoch 1/1, train loss: 0.6987, train metric: 0.7437, valid metric: 0.8334\n",
            "Epoch 1/1, train loss: 0.4543, train metric: 0.8360, valid metric: 0.8288\n",
            "Epoch 1/1, train loss: 0.4144, train metric: 0.8490, valid metric: 0.8488\n",
            "Epoch 1/1, train loss: 0.3903, train metric: 0.8575, valid metric: 0.8354\n",
            "Epoch 1/1, train loss: 0.3719, train metric: 0.8637, valid metric: 0.8454\n",
            "Epoch 1/1, train loss: 0.3600, train metric: 0.8676, valid metric: 0.8538\n",
            "Epoch 1/1, train loss: 0.3476, train metric: 0.8716, valid metric: 0.8554\n",
            "Epoch 1/1, train loss: 0.3408, train metric: 0.8744, valid metric: 0.8570\n",
            "Epoch 1/1, train loss: 0.3327, train metric: 0.8781, valid metric: 0.8526\n",
            "Epoch 1/1, train loss: 0.3281, train metric: 0.8784, valid metric: 0.8620\n",
            "Epoch 1/1, train loss: 0.3220, train metric: 0.8824, valid metric: 0.8650\n",
            "Epoch 1/1, train loss: 0.3178, train metric: 0.8827, valid metric: 0.8680\n",
            "Epoch 1/1, train loss: 0.3126, train metric: 0.8851, valid metric: 0.8588\n",
            "Epoch 1/1, train loss: 0.3094, train metric: 0.8862, valid metric: 0.8560\n",
            "Epoch 1/1, train loss: 0.3053, train metric: 0.8866, valid metric: 0.8676\n",
            "Epoch 1/1, train loss: 0.3016, train metric: 0.8881, valid metric: 0.8596\n",
            "Epoch 1/1, train loss: 0.2989, train metric: 0.8902, valid metric: 0.8716\n",
            "Epoch 1/1, train loss: 0.2956, train metric: 0.8909, valid metric: 0.8586\n",
            "Epoch 1/1, train loss: 0.2915, train metric: 0.8909, valid metric: 0.8744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:22:04,659] Trial 10 finished with value: 0.8744000196456909 and parameters: {'learning_rate': 0.08165528450509137, 'n_hidden': 21}. Best is trial 6 with value: 0.8853999972343445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.2908, train metric: 0.8915, valid metric: 0.8604\n",
            "Epoch 1/1, train loss: 0.6527, train metric: 0.7611, valid metric: 0.8132\n",
            "Epoch 1/1, train loss: 0.4509, train metric: 0.8355, valid metric: 0.8452\n",
            "Epoch 1/1, train loss: 0.4139, train metric: 0.8495, valid metric: 0.8462\n",
            "Epoch 1/1, train loss: 0.3909, train metric: 0.8578, valid metric: 0.8522\n",
            "Epoch 1/1, train loss: 0.3755, train metric: 0.8626, valid metric: 0.8498\n",
            "Epoch 1/1, train loss: 0.3641, train metric: 0.8658, valid metric: 0.8566\n",
            "Epoch 1/1, train loss: 0.3536, train metric: 0.8695, valid metric: 0.8534\n",
            "Epoch 1/1, train loss: 0.3476, train metric: 0.8734, valid metric: 0.8600\n",
            "Epoch 1/1, train loss: 0.3391, train metric: 0.8772, valid metric: 0.8556\n",
            "Epoch 1/1, train loss: 0.3309, train metric: 0.8779, valid metric: 0.8600\n",
            "Epoch 1/1, train loss: 0.3271, train metric: 0.8809, valid metric: 0.8628\n",
            "Epoch 1/1, train loss: 0.3212, train metric: 0.8814, valid metric: 0.8650\n",
            "Epoch 1/1, train loss: 0.3187, train metric: 0.8829, valid metric: 0.8686\n",
            "Epoch 1/1, train loss: 0.3132, train metric: 0.8844, valid metric: 0.8612\n",
            "Epoch 1/1, train loss: 0.3095, train metric: 0.8848, valid metric: 0.8634\n",
            "Epoch 1/1, train loss: 0.3076, train metric: 0.8869, valid metric: 0.8628\n",
            "Epoch 1/1, train loss: 0.3024, train metric: 0.8875, valid metric: 0.8438\n",
            "Epoch 1/1, train loss: 0.2976, train metric: 0.8899, valid metric: 0.8542\n",
            "Epoch 1/1, train loss: 0.2958, train metric: 0.8909, valid metric: 0.8580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:27:00,242] Trial 11 finished with value: 0.8686000108718872 and parameters: {'learning_rate': 0.07553503645583189, 'n_hidden': 21}. Best is trial 6 with value: 0.8853999972343445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.2937, train metric: 0.8901, valid metric: 0.8550\n",
            "Epoch 1/1, train loss: 0.6195, train metric: 0.7764, valid metric: 0.8170\n",
            "Epoch 1/1, train loss: 0.4179, train metric: 0.8472, valid metric: 0.8488\n",
            "Epoch 1/1, train loss: 0.3729, train metric: 0.8637, valid metric: 0.8500\n",
            "Epoch 1/1, train loss: 0.3477, train metric: 0.8713, valid metric: 0.8666\n",
            "Epoch 1/1, train loss: 0.3280, train metric: 0.8791, valid metric: 0.8670\n",
            "Epoch 1/1, train loss: 0.3120, train metric: 0.8842, valid metric: 0.8716\n",
            "Epoch 1/1, train loss: 0.2989, train metric: 0.8886, valid metric: 0.8730\n",
            "Epoch 1/1, train loss: 0.2866, train metric: 0.8923, valid metric: 0.8780\n",
            "Epoch 1/1, train loss: 0.2771, train metric: 0.8978, valid metric: 0.8544\n",
            "Epoch 1/1, train loss: 0.2690, train metric: 0.8984, valid metric: 0.8774\n",
            "Epoch 1/1, train loss: 0.2588, train metric: 0.9028, valid metric: 0.8776\n",
            "Epoch 1/1, train loss: 0.2506, train metric: 0.9062, valid metric: 0.8808\n",
            "Epoch 1/1, train loss: 0.2432, train metric: 0.9081, valid metric: 0.8842\n",
            "Epoch 1/1, train loss: 0.2368, train metric: 0.9099, valid metric: 0.8822\n",
            "Epoch 1/1, train loss: 0.2318, train metric: 0.9125, valid metric: 0.8824\n",
            "Epoch 1/1, train loss: 0.2254, train metric: 0.9149, valid metric: 0.8840\n",
            "Epoch 1/1, train loss: 0.2192, train metric: 0.9173, valid metric: 0.8868\n",
            "Epoch 1/1, train loss: 0.2142, train metric: 0.9193, valid metric: 0.8862\n",
            "Epoch 1/1, train loss: 0.2098, train metric: 0.9213, valid metric: 0.8848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:31:54,286] Trial 12 finished with value: 0.8867999911308289 and parameters: {'learning_rate': 0.08525846269447772, 'n_hidden': 116}. Best is trial 12 with value: 0.8867999911308289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.2030, train metric: 0.9223, valid metric: 0.8744\n",
            "Epoch 1/1, train loss: 0.8659, train metric: 0.7036, valid metric: 0.7850\n",
            "Epoch 1/1, train loss: 0.5120, train metric: 0.8185, valid metric: 0.8188\n",
            "Epoch 1/1, train loss: 0.4574, train metric: 0.8378, valid metric: 0.8286\n",
            "Epoch 1/1, train loss: 0.4263, train metric: 0.8487, valid metric: 0.8460\n",
            "Epoch 1/1, train loss: 0.4035, train metric: 0.8569, valid metric: 0.8448\n",
            "Epoch 1/1, train loss: 0.3874, train metric: 0.8618, valid metric: 0.8476\n",
            "Epoch 1/1, train loss: 0.3711, train metric: 0.8666, valid metric: 0.8340\n",
            "Epoch 1/1, train loss: 0.3580, train metric: 0.8712, valid metric: 0.8580\n",
            "Epoch 1/1, train loss: 0.3456, train metric: 0.8760, valid metric: 0.8660\n",
            "Epoch 1/1, train loss: 0.3345, train metric: 0.8791, valid metric: 0.8686\n",
            "Epoch 1/1, train loss: 0.3258, train metric: 0.8815, valid metric: 0.8662\n",
            "Epoch 1/1, train loss: 0.3169, train metric: 0.8858, valid metric: 0.8750\n",
            "Epoch 1/1, train loss: 0.3089, train metric: 0.8879, valid metric: 0.8746\n",
            "Epoch 1/1, train loss: 0.3016, train metric: 0.8903, valid metric: 0.8766\n",
            "Epoch 1/1, train loss: 0.2944, train metric: 0.8931, valid metric: 0.8740\n",
            "Epoch 1/1, train loss: 0.2885, train metric: 0.8951, valid metric: 0.8748\n",
            "Epoch 1/1, train loss: 0.2822, train metric: 0.8977, valid metric: 0.8722\n",
            "Epoch 1/1, train loss: 0.2770, train metric: 0.8997, valid metric: 0.8698\n",
            "Epoch 1/1, train loss: 0.2729, train metric: 0.9007, valid metric: 0.8670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:36:48,779] Trial 13 finished with value: 0.8784000277519226 and parameters: {'learning_rate': 0.01891149541864801, 'n_hidden': 116}. Best is trial 12 with value: 0.8867999911308289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.2671, train metric: 0.9020, valid metric: 0.8784\n",
            "Epoch 1/1, train loss: 0.9440, train metric: 0.6748, valid metric: 0.7730\n",
            "Epoch 1/1, train loss: 0.5292, train metric: 0.8132, valid metric: 0.8262\n",
            "Epoch 1/1, train loss: 0.4689, train metric: 0.8346, valid metric: 0.8306\n",
            "Epoch 1/1, train loss: 0.4349, train metric: 0.8445, valid metric: 0.8290\n",
            "Epoch 1/1, train loss: 0.4107, train metric: 0.8556, valid metric: 0.8436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:38:18,540] Trial 14 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.3919, train metric: 0.8613, valid metric: 0.8300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:38:34,457] Trial 15 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 1.8496, train metric: 0.4092, valid metric: 0.6042\n",
            "Epoch 1/1, train loss: 0.7456, train metric: 0.7386, valid metric: 0.7672\n",
            "Epoch 1/1, train loss: 0.4683, train metric: 0.8341, valid metric: 0.8424\n",
            "Epoch 1/1, train loss: 0.4143, train metric: 0.8511, valid metric: 0.8464\n",
            "Epoch 1/1, train loss: 0.3811, train metric: 0.8621, valid metric: 0.8568\n",
            "Epoch 1/1, train loss: 0.3579, train metric: 0.8696, valid metric: 0.8682\n",
            "Epoch 1/1, train loss: 0.3400, train metric: 0.8758, valid metric: 0.8690\n",
            "Epoch 1/1, train loss: 0.3261, train metric: 0.8804, valid metric: 0.8708\n",
            "Epoch 1/1, train loss: 0.3149, train metric: 0.8837, valid metric: 0.8794\n",
            "Epoch 1/1, train loss: 0.3020, train metric: 0.8895, valid metric: 0.8714\n",
            "Epoch 1/1, train loss: 0.2935, train metric: 0.8930, valid metric: 0.8400\n",
            "Epoch 1/1, train loss: 0.2845, train metric: 0.8949, valid metric: 0.8720\n",
            "Epoch 1/1, train loss: 0.2761, train metric: 0.8982, valid metric: 0.8792\n",
            "Epoch 1/1, train loss: 0.2684, train metric: 0.9003, valid metric: 0.8848\n",
            "Epoch 1/1, train loss: 0.2615, train metric: 0.9045, valid metric: 0.8772\n",
            "Epoch 1/1, train loss: 0.2560, train metric: 0.9049, valid metric: 0.8820\n",
            "Epoch 1/1, train loss: 0.2497, train metric: 0.9071, valid metric: 0.8832\n",
            "Epoch 1/1, train loss: 0.2434, train metric: 0.9097, valid metric: 0.8848\n",
            "Epoch 1/1, train loss: 0.2380, train metric: 0.9126, valid metric: 0.8832\n",
            "Epoch 1/1, train loss: 0.2331, train metric: 0.9145, valid metric: 0.8806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:43:39,291] Trial 16 finished with value: 0.8848000168800354 and parameters: {'learning_rate': 0.032666299131732864, 'n_hidden': 142}. Best is trial 12 with value: 0.8867999911308289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.2271, train metric: 0.9154, valid metric: 0.8800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:43:54,397] Trial 17 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 1.5604, train metric: 0.5038, valid metric: 0.6536\n",
            "Epoch 1/1, train loss: 0.6189, train metric: 0.7751, valid metric: 0.8314\n",
            "Epoch 1/1, train loss: 0.4237, train metric: 0.8447, valid metric: 0.8492\n",
            "Epoch 1/1, train loss: 0.3814, train metric: 0.8605, valid metric: 0.8582\n",
            "Epoch 1/1, train loss: 0.3567, train metric: 0.8681, valid metric: 0.8622\n",
            "Epoch 1/1, train loss: 0.3375, train metric: 0.8744, valid metric: 0.8674\n",
            "Epoch 1/1, train loss: 0.3246, train metric: 0.8788, valid metric: 0.8480\n",
            "Epoch 1/1, train loss: 0.3123, train metric: 0.8849, valid metric: 0.8644\n",
            "Epoch 1/1, train loss: 0.3012, train metric: 0.8871, valid metric: 0.8734\n",
            "Epoch 1/1, train loss: 0.2915, train metric: 0.8916, valid metric: 0.8760\n",
            "Epoch 1/1, train loss: 0.2858, train metric: 0.8931, valid metric: 0.8758\n",
            "Epoch 1/1, train loss: 0.2778, train metric: 0.8955, valid metric: 0.8804\n",
            "Epoch 1/1, train loss: 0.2715, train metric: 0.8972, valid metric: 0.8616\n",
            "Epoch 1/1, train loss: 0.2642, train metric: 0.9011, valid metric: 0.8800\n",
            "Epoch 1/1, train loss: 0.2598, train metric: 0.9009, valid metric: 0.8782\n",
            "Epoch 1/1, train loss: 0.2561, train metric: 0.9033, valid metric: 0.8734\n",
            "Epoch 1/1, train loss: 0.2494, train metric: 0.9058, valid metric: 0.8788\n",
            "Epoch 1/1, train loss: 0.2474, train metric: 0.9069, valid metric: 0.8720\n",
            "Epoch 1/1, train loss: 0.2411, train metric: 0.9089, valid metric: 0.8750\n",
            "Epoch 1/1, train loss: 0.2375, train metric: 0.9103, valid metric: 0.8768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:48:59,309] Trial 18 finished with value: 0.8830000162124634 and parameters: {'learning_rate': 0.0954812841907134, 'n_hidden': 50}. Best is trial 12 with value: 0.8867999911308289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.2353, train metric: 0.9109, valid metric: 0.8830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 18:49:14,830] Trial 19 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.7417, train metric: 0.7395, valid metric: 0.7640\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "pruner = optuna.pruners.MedianPruner()\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=sampler,\n",
        "                            pruner=pruner)\n",
        "study.optimize(objective_with_data, n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "sL1KFaH6L5Df",
        "outputId": "eff0ddd1-fd57-4bd3-c7d7-89bd159ad3fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8867999911308289"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "pnNDoyK8L5Df",
        "outputId": "06f660ed-9326-4ac9-a65a-09638169e667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.08525846269447772, 'n_hidden': 116}"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkrfWGelL5Df"
      },
      "source": [
        "# Saving and Loading a PyTorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "Uyeng4LcL5Df"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"my_fashion_mnist.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "5HhTdWv5L5Dg"
      },
      "outputs": [],
      "source": [
        "loaded_model = torch.load(\"my_fashion_mnist.pt\", weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "X1nDs1msL5Dg"
      },
      "outputs": [],
      "source": [
        "loaded_model.eval()\n",
        "y_pred_logits = loaded_model(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "3-Ktc21AL5Dg"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"my_fashion_mnist_weights.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "C9WT4e8eL5Dg",
        "outputId": "75ce2090-4b2b-43b1-8f5e-cdf7c283c36e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.OrderedDict"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "type(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f87a4d6"
      },
      "source": [
        "This code cell demonstrates how to load a pre-trained model's parameters (weights and biases) into a newly created model instance. This is a common and recommended practice in PyTorch, especially when you want more flexibility, such as changing the hardware, making small modifications to the model architecture, or when sharing models.\n",
        "\n",
        "*   **`new_model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=300, n_hidden2=100, n_classes=10)`**:\n",
        "    *   First, a brand new instance of the `ImageClassifier` model is created. It's crucial that this `new_model` has the **exact same architecture** as the `model` that was originally saved. This ensures that the structure of the weights and biases (`state_dict`) will match when loading.\n",
        "\n",
        "*   **`loaded_weights = torch.load(\"my_fashion_mnist_weights.pt\", weights_only=True)`**:\n",
        "    *   This line loads the saved state dictionary (the collection of learned parameters) from the specified file (`\"my_fashion_mnist_weights.pt\"`).\n",
        "    *   `weights_only=True` is a good practice to explicitly indicate that you are expecting to load only the state dictionary and not the entire model object (which `torch.save(model, ...)` would save).\n",
        "\n",
        "*   **`new_model.load_state_dict(loaded_weights)`**:\n",
        "    *   This is the core operation. The `load_state_dict()` method of the `nn.Module` is used to populate the parameters of `new_model` with the values loaded from `loaded_weights`. PyTorch ensures that the keys (parameter names) and shapes in `loaded_weights` match those of `new_model`.\n",
        "\n",
        "*   **`new_model.eval()`**:\n",
        "    *   Finally, the `new_model` is immediately set to evaluation mode. This is important because, after loading pre-trained weights, you typically want to use the model for inference or further evaluation, and `model.eval()` ensures that layers like `Dropout` and `BatchNorm` behave correctly (e.g., `Dropout` is turned off, `BatchNorm` uses its learned running statistics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "IZWElFCjL5Dg",
        "outputId": "a657b2f7-3bf8-412a-dcfb-5aa0675cbc9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassifier(\n",
              "  (mlp): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "new_model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=300, n_hidden2=100,\n",
        "                            n_classes=10)\n",
        "loaded_weights = torch.load(\"my_fashion_mnist_weights.pt\", weights_only=True)\n",
        "new_model.load_state_dict(loaded_weights)\n",
        "new_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5ccc879"
      },
      "source": [
        "This code cell shows a robust and recommended practice for saving a PyTorch model: combining the model's learned parameters (`state_dict`) with its architectural hyperparameters into a single file.\n",
        "\n",
        "*   **`model_data = { ... }`**:\n",
        "    *   A Python dictionary named `model_data` is created to store all necessary information for saving and later reloading the model.\n",
        "\n",
        "*   **`\"model_state_dict\": model.state_dict()`**:\n",
        "    *   This key-value pair stores the `state_dict` of the trained `model`. The `state_dict` is essentially a Python dictionary that maps each layer to its learnable parameters (weights and biases).\n",
        "\n",
        "*   **`\"model_hyperparameters\": { ... }`**:\n",
        "    *   This nested dictionary stores the hyperparameters that define the architecture of the `ImageClassifier` model.\n",
        "        *   `\"n_inputs\"`, `\"n_hidden1\"`, `\"n_hidden2\"`, `\"n_classes\"`: These are the arguments required to instantiate an `ImageClassifier` object with the correct structure.\n",
        "\n",
        "*   **`torch.save(model_data, \"my_fashion_mnist_model.pt\")`**:\n",
        "    *   This line uses `torch.save()` to serialize the entire `model_data` dictionary into a single file named `\"my_fashion_mnist_model.pt\"`.\n",
        "\n",
        "**Why this approach is beneficial:**\n",
        "*   **Self-contained**: The saved file contains everything needed to reconstruct and load the model (both its architecture and its learned weights) without needing to manually remember or hardcode the architecture details.\n",
        "*   **Flexibility**: When you load this file, you can easily extract the hyperparameters to create a new model instance and then load the `state_dict` into it.\n",
        "*   **Maintainability**: It makes your model saving and loading process more explicit and less error-prone, especially as models become more complex or when collaborating on projects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "CeRG9QAfL5Dg"
      },
      "outputs": [],
      "source": [
        "model_data = {\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"model_hyperparameters\": {\n",
        "        \"n_inputs\": 1 * 28 * 28,\n",
        "        \"n_hidden1\": 300,\n",
        "        \"n_hidden2\": 100,\n",
        "        \"n_classes\": 10,\n",
        "    }\n",
        "}\n",
        "torch.save(model_data, \"my_fashion_mnist_model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc93b870"
      },
      "source": [
        "This code cell demonstrates how to load a complete PyTorch model (both its architecture and learned weights) from a single file, following the robust saving method discussed previously.\n",
        "\n",
        "*   **`loaded_data = torch.load(\"my_fashion_mnist_model.pt\", weights_only=True)`**:\n",
        "    *   This line loads the entire Python dictionary that was previously saved to `\"my_fashion_mnist_model.pt\"`. This dictionary contains both the `\"model_state_dict\"` and the `\"model_hyperparameters\"`.\n",
        "    *   `weights_only=True` is often used to ensure the file is opened in a way suitable for loading `state_dict`s, even though here we are loading a more complex dictionary containing hyperparameters as well. It's a best practice to ensure compatibility, though the content itself is a dictionary not just weights.\n",
        "\n",
        "*   **`new_model = ImageClassifier(**loaded_data[\"model_hyperparameters\"])`**:\n",
        "    *   This is a powerful Python feature. `loaded_data[\"model_hyperparameters\"]` retrieves the dictionary containing all the architectural parameters (like `n_inputs`, `n_hidden1`, etc.).\n",
        "    *   The `**` operator then unpacks this dictionary, passing its key-value pairs as keyword arguments to the `ImageClassifier` constructor. This automatically recreates a new `ImageClassifier` instance with the exact same architecture as the saved model.\n",
        "\n",
        "*   **`new_model.load_state_dict(loaded_data[\"model_state_dict\"])`**:\n",
        "    *   Once the `new_model` (architecture) is instantiated, this line loads the learned parameters (weights and biases) into it. `loaded_data[\"model_state_dict\"]` provides the dictionary mapping parameter names to their saved values, and `load_state_dict()` populates the new model's parameters accordingly.\n",
        "\n",
        "*   **`new_model.eval()`**:\n",
        "    *   Finally, the `new_model` is set to evaluation mode. This is crucial for consistent inference, as it disables layers like `Dropout` and ensures `BatchNorm` uses its learned running statistics rather than batch statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "YTAvwq1zL5Dg",
        "outputId": "7eee27e1-a290-43ca-ddb2-7ad015d9ff06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassifier(\n",
              "  (mlp): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "loaded_data = torch.load(\"my_fashion_mnist_model.pt\", weights_only=True)\n",
        "new_model = ImageClassifier(**loaded_data[\"model_hyperparameters\"])\n",
        "new_model.load_state_dict(loaded_data[\"model_state_dict\"])\n",
        "new_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC_LpFSsL5Dg"
      },
      "source": [
        "# Compiling and Optimizing a PyTorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "o4UunXrlL5Dg"
      },
      "outputs": [],
      "source": [
        "torchscript_model = torch.jit.trace(model, X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "JvArL5J0L5Dg"
      },
      "outputs": [],
      "source": [
        "torchscript_model = torch.jit.script(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "SdvO14kGL5Dg"
      },
      "outputs": [],
      "source": [
        "optimized_model = torch.jit.optimize_for_inference(torchscript_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "uZmlMRJeL5Dg"
      },
      "outputs": [],
      "source": [
        "optimized_model.save(\"my_fashion_mnist_torchscript.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "dparrOjTL5Dg"
      },
      "outputs": [],
      "source": [
        "loaded_torchscript_model = torch.jit.load(\"my_fashion_mnist_torchscript.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "14r-icR-L5Dg",
        "outputId": "bb8674ba-5ee7-473a-f6f7-6909e095df32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -3.3324,  -0.7572,  -4.1671,  -1.9444,  -1.6955,   2.0123,  -3.2624,\n",
              "           8.6379,  -0.5685,   6.2972],\n",
              "        [ -0.1434,  -3.8626,  11.8279,  -0.3164,  17.3995, -13.1888,   7.8158,\n",
              "         -11.8338,  -1.4709,  -7.9412],\n",
              "        [  0.3996,  -2.5537,   7.5992,   0.1775,   6.9748,  -6.1942,   4.8270,\n",
              "          -5.8584,  -1.4327,  -4.3257]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "y_pred_logits = loaded_torchscript_model(X_new)\n",
        "y_pred_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "mvTrlEqAL5Dg"
      },
      "outputs": [],
      "source": [
        "compiled_model = torch.compile(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "eseKV1s4L5Dg",
        "outputId": "85f234c7-7414-468b-f51c-07b7db1c1c43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n",
            "W1226 18:49:25.457000 2340 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        }
      ],
      "source": [
        "if device == \"cuda\":\n",
        "    y_pred_logits = compiled_model(X_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzrPNJ9kL5Dg"
      },
      "source": [
        "# Exercise Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBVM-rK9L5Dg"
      },
      "source": [
        "## Exercises 1. to 12."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LejYEx53L5Dg"
      },
      "source": [
        "1. PyTorch is similar to NumPy is many ways, but it offers some extra features. The main ones are:\n",
        "    * Auto-differentiation\n",
        "    * Support for hardware accelerators\n",
        "    * Includes optimizers and ready-to-use neural net components\n",
        "\n",
        "2. `torch.exp()` returns a copy of the input tensor while `torch.exp_()` modifies it in place. Similarly, `torch.relu()` returns a copy while `torch.relu_()` modifies in place.\n",
        "\n",
        "3. To create a new tensor on the GPU, you can use one of the following methods:\n",
        "     * Set the `device` argument when calling `torch.tensor()`, `torch.rand()`, or other functions that create new tensors. For example, `torch.randn(10, device=\"cuda\")` creates a new tensor on the CUDA GPU, with 10 random elements.\n",
        "     * Create a new tensor on the CPU, then transfer it to the GPU by using calling its `to()` method, for example `torch.randn(10).to(\"cuda\")`. However, it's more efficient to create the tensor directly on the GPU.\n",
        "     * The `*_like()` functions such as `ones_like()` and `zeros_like()` create a new tensor on the same device as another tensor. They also use the same data type.\n",
        "    * Lastly, if you execute an operation on a tensor that lives on the GPU, the result will generally be a new tensor on the GPU (unless you use an in-place operation such as `torch.exp_()`.\n",
        "\n",
        "4. Here are three ways to perform tensor computations without using autograd:\n",
        "    * Manipulate tensors created with `requires_grad=False` (which is the default).\n",
        "    * Run the computations inside a `with torch.no_grad():` block.\n",
        "    * Call the `detach()` method on the tensor you want to manipulate without autograd.\n",
        "\n",
        "5. Here's what happens in each case:\n",
        "    * The first code sample will work fine, it will _not_ cause a `RuntimeError`: indeed, the `cos()` method creates a new (non-leaf) tensor, then `exp_()` modifies it in place. During the backward pass, PyTorch is able to backpropagate through the `exp_()` operation because the derivative of exp(x) is exp(x), so PyTorch doesn't need to know what the input x was, it can just use the output of the forward pass (i.e., exp(x)) during the backward pass.\n",
        "    * If you replace `z = t.cos().exp_()` with `z = t.cos_().exp()` then you will get a `RuntimeError` on that line (\"_a leaf Variable that requires grad is being used in an in-place operation_\"). Indeed, `t` is a leaf tensor (since it was created directly by the user, not the result of any computation) and you cannot apply an in-place operation on a leaf tensor with `requires_grad=True`.\n",
        "    * If you replace `z = t.cos().exp_()` with `z = t.exp().cos_()`, then you will get a `RuntimeError` (\"_one of the variables needed for gradient computation has been modified by an inplace operation_\") during the backward pass. Indeed, the `exp()` operation relies on the fact that the derivative of exp(_t_) is exp(_t_), so it doesn't need to store the tensor `t` for the backward pass, instead it relies on the fact that it can just use the tensor returned by `t.exp()` (let's call it `e`). So far so good. But when we call the `cos_()` operation, it knows that it will need its input during the backward pass (since the derivative of cos(_e_) is –sin(_e_)), so it keeps a copy of its input tensor `e`. Next, it tries to modify the original `e` in-place, and in doing so it notices that this tensor is needed by another operation (`exp()`) for the backward pass, so it knows that something is fishy and it raises a `RuntimeError`.\n",
        "    * The second code example will fail during backpropogation, with a `RuntimeError`. It's a very similar error to the previous one: the `cos()` operation stores a reference to its input tensor `v`, since `v` will be needed during the backward pass. Indeed, the derivative of cos(_v_) is –sin(_v_), so we need to save _v_. Next, the `sin_()` operation creates a copy of its input `v` (since it's an in-place operation, it knows that it must create a copy, not just preserve a reference) then it proceeds to modify the original `v`, but this tensor is needed to compute the gradient of `cos(_v_)`, so PyTorch raises a `RuntimeError`.\n",
        "    * If you replace `w = v.cos() * v.sin_()` with `w = v.cos_() * v.sin()`, then there is no longer any `RuntimeError`. Indeed, the `cos_()` operation creates a copy of its input `v` so it can compute –sin(_v_) during the backward pass. The `sin()` operation is not in-place so in keeps a reference to its input `v`, not a copy. Backprop then runs just fine. However, there's a catch: by the time the `sin()` operation runs, its input `v` is no longer equal to 3.0, but instead it's equal to cos(3.0) since the `cos_()` modified `v` in place. As a result, `w = v.cos() * v.sin_()` does _not_ give the same result as `w = v.cos_() * v.sin()`. The former computes cos(3) * sin(3) while the latter computes cos(3) * sin(cos(3)). And of course the gradients change as well. That's why you should be very careful with in-place operations: they can make your code faster, sure, but they can also make it silently wrong.\n",
        "\n",
        "6. A `Linear(100, 200)` module has 200 neurons: one per output. Its `weight` tensor has a shape of [200, 100] and its `bias` parameter has a shape of [200]. It expects its inputs to have a shape of [..., 100], for example [32, 100], or [32, 64, 100]. It treats all dimensions independently, except for the last one. The output shape is identical to the input shape, except that the last dimension is replaced with 200. For example, if the input shape is [32, 64, 100], then the output shape is [32, 64, 200].\n",
        "\n",
        "7. The main steps of a PyTorch training loop are:\n",
        "    * Prepare a batch of samples from the training set. You can use a `DataLoader` for this.\n",
        "    * Optionally transfer these samples to the GPU (typically using `X_batch.to(device)` and `y_batch.to(device)`).\n",
        "    * Run the inputs through the model, for example `y_pred = model(X_batch)`.\n",
        "    * Compute the loss, for example `loss = criterion(y_pred, y_true)`.\n",
        "    * Backpropagate through the loss using `loss.backward()`.\n",
        "    * Perform an optimizer step: `optimizer.step()`.\n",
        "    * Zero out the gradients: `optimizer.zero_grad()` (alternatively, you can do this before the backward pass, which may be safer if the gradients are non-zero before the training loop starts).\n",
        "    * The whole training loop is often split into epochs, but this is optional.\n",
        "\n",
        "8. It is recommended to create the optimizer _after_ the model is moved to the GPU because most optimizers have some internal state, and this state is usually allocated on the same device as the model parameters.\n",
        "\n",
        "9. To speed up training when using a GPU, you should generally set the following `DataLoader` options:\n",
        "    * Set the data loader's `num_workers` argument to the number of processes you want to use for data loading and preprocessing. This will often speed up training by pre-fetching the next batches on the CPU while the GPU is still working on the current batch. The optimal number depends on your platform, hardware, and workload, so you should experiment with different values.\n",
        "    * Set the data loader's `prefetch_factor` argument to control the number of batches that each worker pre-fetches.\n",
        "    * If spawning and synchronizing workers causes too much overhead (especially on Windows), you can try setting `persistent_workers=True` to reuse the same workers across epochs.\n",
        "\n",
        "10. The main classification losses provided by PyTorch are:\n",
        "    * `nn.CrossEntropyLoss`: this is generally the loss you want to use for multiclass classification, as it's efficient and numerically stable. This loss works directly on logits, not probabilities, so your model must not include the softmax activation function on the output layer. As a result, whenever you need to estimate probabilities, you must call the `F.softmax()` function on the logits output by the model.\n",
        "    * `nn.BCEWithLogitsLoss` (BCE stands for _binary cross-entropy_): this is usually the loss you want to use for binary classification, for the same reason as `nn.CrossEntropyLoss`. Just like the previous loss, it works directly with logits, so your model must not include the sigmoid activation function on the output layer. Whenever you need to estimate probabilities, you must call the `F.sigmoid()` function on the logits output by the model. Note that some people prefer to use `nn.CrossEntropyLoss` even for binary classification, as it makes the code more consistent regardless of the number of classes, at a tiny computational and memory cost.\n",
        "    * `nn.NLLLoss` (NLL stands for _negative log-likelihood_): this is an alternative to `nn.CrossEntropyLoss` for multiclass classification. To use it, your model must output log probabilities rather than logits. This can be done using `nn.LogSoftmax()` or `F.log_softmax()`. This approach is a bit slower than using `CrossEntropyLoss`, but it can be useful if you want your model to output log probabilities rather than logits, or when you wish to tweak the probability distribution before computing the final loss (indeed, it is sometimes easier to modify log probabilities rather than logits). Whenever you need to estimate probabilities, you must call `torch.exp()` on the model's outputs.\n",
        "    * `nn.BCELoss`: this loss is an alternative to `nn.BCEWithLogitsLoss` for binary classification. It assumes that your model outputs probabilities rather than logits, so your model's output layer must use the sigmoid activation function. This can be convenient if you want your model to output probabilities directly, but it's a bit slower and less numerically stable than using `BCEWithLogitsLoss`.\n",
        "\n",
        "11. Calling `model.train()` before training and `model.eval()` before evaluation is important because some layers (such as `nn.Dropout`, `nn.BatchNorm1d` or `nn.BatchNorm2d`) don't behave in the same way during training and evaluation, therefore we must tell the model in which mode it should run.\n",
        "\n",
        "12. Both `torch.jit.trace()` and `torch.jit.script()` attempt to capture your model's computation graph and turn it into TorchScript code that can be optimized, saved, and deployed to various platforms. However, these functions work very differently:\n",
        "    * The `torch.jit.trace()` function runs your model with a tracing tensor that captures which operations are executed. It's quite simple and works well for simple models, but it cannot capture conditionals (e.g., `if`, `elif`, `else`, `match`): it only captures the branch of the conditional that is actually executed during tracing. Similarly, if your model contains a loop (e.g., `for` or `while`) then tracing will not capture the loop itself, it will only capture the repeated operations.\n",
        "    * The`torch.jit.script()` function actually parses your Python code to generate TorchScript code. This allows it to detect conditionals (as long as the conditions are tensors), and also capture loops. However, it only works with a subset of Python: you cannot use global variables, Python generators (`yield`), complex list comprehensions, variable length function arguments (`*args` or `**kwargs`), or `match` statements. Moreover, types must be fixed (a function cannot return an integer in some cases and a float in others), and you can only call other functions if they also respect these rules, so no standard library, no third-party libraries, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8xzfcsyL5Dg"
      },
      "source": [
        "## Exercise 13."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onN95RMTL5Dg"
      },
      "source": [
        "Exercise: _Use autograd to find the gradient vector of f(_x_, _y_) = sin(_x_<sup>2</sup> _y_) at the point (_x_, _y_) = (1.2, 3.4)._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "EOwuothGL5Dg",
        "outputId": "94ad11bf-1d43-4a27-c986-bc1809dbed06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.489864706993103, 0.26291730999946594)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "def f(x, y):\n",
        "    return torch.sin(x ** 2 * y)\n",
        "\n",
        "x = torch.tensor(1.2, requires_grad=True)\n",
        "y = torch.tensor(3.4, requires_grad=True)\n",
        "result = f(x, y)\n",
        "result.backward()\n",
        "\n",
        "x.grad.item(), y.grad.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3fdpKCmL5Dg"
      },
      "source": [
        "Alternatively, we could use a vectorized implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "SxElwFYsL5Dg",
        "outputId": "369db8c3-cf38-4b7a-dcc4-c7fe45fa1709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.4899, 0.2629])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "def f(v):\n",
        "    return torch.sin(v[0] ** 2 * v[1])\n",
        "\n",
        "v = torch.tensor([1.2, 3.4], requires_grad=True)\n",
        "result = f(v)\n",
        "result.backward()\n",
        "\n",
        "v.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1z84sMpL5Dg"
      },
      "source": [
        "We get the same partial derivatives, but this time they are wrapped in a gradient tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tICcPCxSL5Dg"
      },
      "source": [
        "Let's check this result by computing an approximation of the partial derivatives, using the fact that the partial derivative of a function $f(x, y)$ with regard to $x$, at a point $(x_0, y_0)$ is the limit of $\\dfrac{f(x_0 + \\epsilon, y_0) - f(x_0, y0)}{\\epsilon}$ as $\\epsilon$ approaches zero. Similarly, the partial derivative of that function with regard to $y$, at the same point $(x_0, y_0)$, is the limit of $\\dfrac{f(x_0, y_0 + \\epsilon) - f(x_0, y0)}{\\epsilon}$ as $\\epsilon$ approaches zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "ffxiV6eoL5Dg",
        "outputId": "5cec407d-080f-4216-898b-9a1305f2f786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4901161193847656, 0.26226043701171875)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "eps = 0.00005\n",
        "df_dx = (f([x + eps, y]) - f([x, y])) / eps\n",
        "df_dy = (f([x, y + eps]) - f([x, y])) / eps\n",
        "\n",
        "df_dx.item(), df_dy.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiB1nD0dL5Dg"
      },
      "source": [
        "That's close enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCMIVeibL5Dg"
      },
      "source": [
        "We can also derive the equations for the partial derivatives mathematically (see the [calculus tutorial](math_differential_calculus.ipynb) to learn how to do this):\n",
        "* $\\dfrac{\\partial f}{\\partial x} = 2xy \\cos(x^2 y)$\n",
        "* $\\dfrac{\\partial f}{\\partial x} = x^2 \\cos(x^2 y)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "zcbMjuhXL5Dh",
        "outputId": "74dc46db-db74-48e7-ead2-0c30bfb599b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4898648262023926, 0.26291730999946594)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "df_dx = 2 * x * y * torch.cos(x**2 * y)\n",
        "df_dy = x ** 2 * torch.cos(x**2 * y)\n",
        "\n",
        "df_dx.item(), df_dy.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKrwFAG-L5Dh"
      },
      "source": [
        "Perfect!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNjh1_NwL5Dh"
      },
      "source": [
        "## Exercise 14."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOWqfoHsL5Dh"
      },
      "source": [
        "Exercise: _Create a custom `Dense` module that replicates the functionality of an `nn.Linear` module followed by an `nn.ReLU` module. Try implementing it first using the `nn.Linear` and `nn.ReLU` modules, and then reimplement it using `nn.Parameter` and the `relu()` function._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ff693c"
      },
      "source": [
        "This `Dense` class defines a custom PyTorch module that combines the functionality of an `nn.Linear` layer followed by an `nn.ReLU` activation function. Custom modules in PyTorch are created by inheriting from `nn.Module`.\n",
        "\n",
        "*   **`class Dense(nn.Module):`**:\n",
        "    *   Declares a new class `Dense` that inherits from `nn.Module`. This is the base class for all neural network modules in PyTorch, and it provides essential functionality like tracking parameters and managing submodules.\n",
        "\n",
        "*   **`def __init__(self, in_features, out_features):`**:\n",
        "    *   This is the constructor method for the `Dense` module. It takes `in_features` (the number of input features) and `out_features` (the number of output features/neurons) as arguments.\n",
        "    *   **`super().__init__()`**: It's crucial to call the constructor of the parent `nn.Module` class first. This properly initializes the module's internal state.\n",
        "    *   **`self.linear = nn.Linear(in_features, out_features)`**: This line creates an instance of PyTorch's `nn.Linear` module. This module performs a linear transformation (`y = xA^T + b`), which includes weights (`A`) and biases (`b`). It's stored as a submodule of `Dense`.\n",
        "    *   **`self.relu = nn.ReLU()`**: This line creates an instance of PyTorch's `nn.ReLU` (Rectified Linear Unit) activation function. This is also stored as a submodule.\n",
        "\n",
        "*   **`def forward(self, X):`**:\n",
        "    *   This method defines the forward pass of the module. It dictates how input data `X` flows through the module to produce an output.\n",
        "    *   **`return self.relu(self.linear(X))`**: The input `X` is first passed through the `self.linear` layer. The output of the linear layer is then passed through the `self.relu` activation function. The final result is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "GK4X2LR3L5Dh"
      },
      "outputs": [],
      "source": [
        "class Dense(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.relu(self.linear(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqXATMH8L5Dh"
      },
      "source": [
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "28_zK3KYL5Dh",
        "outputId": "291bea15-bb80-483b-c7dd-d7083cf6b8e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "dense = Dense(3, 5)\n",
        "X = torch.randn(2, 3)\n",
        "y_pred = dense(X)\n",
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CGJkthbL5Dh"
      },
      "source": [
        "Looks fine. We can double-check that it gives the right result:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "784643d3"
      },
      "source": [
        "This code cell verifies that the custom `Dense` module's `forward` method produces the same result as manually performing the linear transformation and ReLU activation.\n",
        "\n",
        "*   **`y_pred_check = dense.relu(X @ dense.linear.weight.T + dense.linear.bias)`**:\n",
        "    *   This line manually calculates the expected output of the `Dense` module.\n",
        "        *   `X @ dense.linear.weight.T`: This performs the matrix multiplication of the input `X` with the transpose of the `linear` layer's weight matrix. In PyTorch's `nn.Linear`, the weights are typically stored such that `X @ W.T` is the correct operation.\n",
        "        *   `+ dense.linear.bias`: The bias vector of the `linear` layer is then added to the result of the matrix multiplication. Due to broadcasting rules, this bias is added to each row of the result.\n",
        "        *   `dense.relu(...)`: Finally, the `ReLU` activation function (which was stored as `self.relu` within the `dense` instance) is applied to the entire result.\n",
        "    *   This `y_pred_check` variable holds the output if we were to manually recreate the steps of the `Dense` module's `forward` method.\n",
        "\n",
        "*   **`torch.allclose(y_pred, y_pred_check)`**:\n",
        "    *   `torch.allclose()` is a utility function that compares two tensors element-wise and returns `True` if they are equal within a specified tolerance for floating-point errors. This is the correct way to compare floating-point tensors, as direct equality checks (`==`) can fail due to minute precision differences.\n",
        "    *   The output `True` indicates that the `y_pred` (from `dense(X)`) and `y_pred_check` (from manual calculation) are numerically very close, confirming that the `Dense` module's implementation is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "tNl8_CXXL5Dh",
        "outputId": "eba7fa71-35e4-46f7-ca9f-5941684c8cfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "y_pred_check = dense.relu(X @ dense.linear.weight.T + dense.linear.bias)\n",
        "torch.allclose(y_pred, y_pred_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F80BAMlLL5Dh"
      },
      "source": [
        "Nice. Now let's reimplement the `Dense` class using `nn.Parameter` and `relu()` instead of `nn.Linear` and `nn.ReLU`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "uQdhvvsvL5Dh"
      },
      "outputs": [],
      "source": [
        "class Dense2(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "\n",
        "    def forward(self, X):\n",
        "        z = X @ self.weight.T + self.bias\n",
        "        return F.relu(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPmafmoXL5Dh"
      },
      "source": [
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "veHRa2G1L5Dh",
        "outputId": "dbe1d192-9b59-49ae-b296-726917777381",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "dense2 = Dense2(3, 5)\n",
        "X = torch.randn(2, 3)\n",
        "y_pred2 = dense2(X)\n",
        "y_pred2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGGxZhhRL5Dh"
      },
      "source": [
        "Looks fine. Again, we can double-check that it gives the right result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "8_q9bHs7L5Dh",
        "outputId": "fe2a41b2-4ef7-4e76-d925-389039967215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "y_pred2_check = F.relu(X @ dense2.weight.T + dense2.bias)\n",
        "torch.allclose(y_pred2, y_pred2_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bJNcPiaL5Dh"
      },
      "source": [
        "In Chapter 11, we will see that it's preferable to initialize the weights using Kaiming initialization, when the activation function is ReLU, so let's do that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "mfdWY45cL5Dh"
      },
      "outputs": [],
      "source": [
        "class Dense3(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
        "        nn.init.kaiming_uniform_(self.weight, nonlinearity=\"relu\")\n",
        "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "\n",
        "    def forward(self, X):\n",
        "        z = X @ self.weight.T + self.bias\n",
        "        return F.relu(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "O4C8s10oL5Dh",
        "outputId": "b6da2906-fa0f-44e3-f63a-7882c482b04e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "dense3 = Dense3(3, 5)\n",
        "X = torch.randn(2, 3)\n",
        "y_pred3 = dense3(X)\n",
        "y_pred3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9kYBl_SL5Dh"
      },
      "source": [
        "Still works fine. Again, we can double-check that this module gives the right result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "3NcrQ_OiL5Dh",
        "outputId": "4859563e-8f92-410c-e655-20114a79cafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "y_pred3_check = F.relu(X @ dense3.weight.T + dense3.bias)\n",
        "torch.allclose(y_pred3, y_pred3_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIVU4vj8L5Dh"
      },
      "source": [
        "## Exercise 15."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5dBoqSYL5Dh"
      },
      "source": [
        "Exercise: _Build and train a classification MLP on the CoverType dataset._\n",
        "\n",
        "Step 1: _Load the dataset using `sklearn.datasets.fetch_covtype()` and create a custom PyTorch `Dataset` for this data._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q1pr6SdL5Dh"
      },
      "source": [
        "**Warning**: do not forget to scale the inputs, as gradient descent might not work well otherwise (as we saw in Chapter 4)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30305374"
      },
      "source": [
        "This code cell loads the CoverType dataset, performs essential preprocessing steps, and then wraps the processed data into a PyTorch `TensorDataset`.\n",
        "\n",
        "*   **`from sklearn.datasets import fetch_covtype`** and **`from torch.utils.data import TensorDataset`**:\n",
        "    *   Imports `fetch_covtype` from scikit-learn to easily load the dataset.\n",
        "    *   Imports `TensorDataset` from PyTorch's `utils.data` to create a dataset that can be used with `DataLoader`s.\n",
        "\n",
        "*   **`covtype = fetch_covtype()`**:\n",
        "    *   Loads the CoverType dataset, which is a classification dataset where the goal is to predict the forest cover type from cartographic variables.\n",
        "\n",
        "*   **`X_covtype = torch.tensor(covtype.data, dtype=torch.float32)`**:\n",
        "    *   Converts the feature data (`covtype.data`, which is typically a NumPy array) into a PyTorch tensor of type `torch.float32`. Using `float32` is common in neural networks for efficiency.\n",
        "\n",
        "*   **`means = X_covtype.mean(dim=0, keepdim=True)`** and **`stds = X_covtype.std(dim=0, keepdim=True)`**:\n",
        "    *   These lines calculate the mean and standard deviation for each feature across all samples. This is a crucial step for **standardization**.\n",
        "    *   `dim=0` means the operation is performed along the first dimension (across samples for each feature).\n",
        "    *   `keepdim=True` ensures that the resulting `means` and `stds` tensors retain their original number of dimensions (e.g., a `1xN` shape for `N` features), which is important for broadcasting during the standardization step.\n",
        "\n",
        "*   **`X_standardized_covtype = (X_covtype - means) / stds`**:\n",
        "    *   Applies standardization (Z-score normalization) to the features. This transforms the data so that each feature has a mean of 0 and a standard deviation of 1. Standardization helps gradient-based optimization algorithms converge faster and can improve model performance, especially when features have different scales.\n",
        "\n",
        "*   **`y_covtype = torch.tensor(covtype.target - 1, dtype=torch.long)`**:\n",
        "    *   Converts the target labels (`covtype.target`) into a PyTorch tensor of type `torch.long`. `torch.long` is the standard integer type for classification labels in PyTorch, especially when using loss functions like `nn.CrossEntropyLoss`.\n",
        "    *   **`- 1`**: The original CoverType targets are integers from 1 to 7. However, `nn.CrossEntropyLoss` expects class labels to be 0-indexed (i.e., from 0 to `num_classes - 1`). Subtracting 1 adjusts the labels to the expected range (0 to 6).\n",
        "\n",
        "*   **`covtype_dataset = TensorDataset(X_standardized_covtype, y_covtype)`**:\n",
        "    *   Finally, creates a `TensorDataset` by combining the standardized features (`X_standardized_covtype`) and the adjusted target labels (`y_covtype`). This `TensorDataset` object can now be easily passed to a `DataLoader` to manage batching, shuffling, and iteration during training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "Gf5bVggGL5Dh"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "covtype = fetch_covtype()\n",
        "\n",
        "X_covtype = torch.tensor(covtype.data, dtype=torch.float32)\n",
        "means = X_covtype.mean(dim=0, keepdim=True)\n",
        "stds = X_covtype.std(dim=0, keepdim=True)\n",
        "X_standardized_covtype = (X_covtype - means) / stds\n",
        "\n",
        "y_covtype = torch.tensor(covtype.target - 1, dtype=torch.long)\n",
        "\n",
        "covtype_dataset = TensorDataset(X_standardized_covtype, y_covtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc7TnpPZL5Dh"
      },
      "source": [
        "Note that the targets range from 1 to 7, but the `nn.CrossEntropyLoss` expects it to start at 0, which is why we subtract 1 from the targets. We also convert the inputs from 64-bit floats to 32-bit floats, and the targets to 64-bit integers. These are the default types in PyTorch for floats and integers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ14e91-L5Dh"
      },
      "source": [
        "Let's look at the first instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "VRw9JPBML5Dh",
        "outputId": "a2540fa3-8a6a-4123-99eb-80c9e468c93c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([54]), torch.Size([]))"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "sample0, target0 = covtype_dataset[0]\n",
        "sample0.shape, target0.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltO6IZgOL5Dh"
      },
      "source": [
        "Looks good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEe_DMMWL5Dh"
      },
      "source": [
        "Step 2: _Create data loaders for training, validation, and testing._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agz-9sxUL5Dh"
      },
      "source": [
        "The dataset is not shuffled or split by default, so we shuffle and split it:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "973fdb1b"
      },
      "source": [
        "This code cell splits the `covtype_dataset` into distinct subsets for training, validation, and testing. This is a standard practice in machine learning to properly evaluate a model's generalization performance.\n",
        "\n",
        "\n",
        "*   **`train_size = len(covtype_dataset) * 80 // 100`**:\n",
        "    *   Calculates the size of the training set. It takes 80% of the total samples in `covtype_dataset`. The `//` operator performs integer division.\n",
        "\n",
        "*   **`valid_size = len(covtype_dataset) * 10 // 100`**:\n",
        "    *   Calculates the size of the validation set, taking 10% of the total samples.\n",
        "\n",
        "*   **`test_size = len(covtype_dataset) - train_size - valid_size`**:\n",
        "    *   Calculates the size of the test set. It's determined by subtracting the calculated `train_size` and `valid_size` from the total `covtype_dataset` length. This ensures that all samples are distributed among the three sets.\n",
        "\n",
        "*   **`train_dataset, valid_dataset, test_dataset = random_split(\n",
        "    covtype_dataset,\n",
        "    [train_size, valid_size, test_size])`**:\n",
        "    *   This line performs the actual splitting. `random_split` takes the original `covtype_dataset` and a list of lengths (`[train_size, valid_size, test_size]`) and returns three new `Subset` objects (which behave like `Dataset`s). These subsets contain randomly selected, non-overlapping samples from the original dataset, corresponding to the specified sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "gUnuQOwjL5Di"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "train_size = len(covtype_dataset) * 80 // 100\n",
        "valid_size = len(covtype_dataset) * 10 // 100\n",
        "test_size = len(covtype_dataset) - train_size - valid_size\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = random_split(\n",
        "    covtype_dataset,\n",
        "    [train_size, valid_size, test_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8wNoPrhL5Di"
      },
      "source": [
        "Now let's create the data loaders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "Fu8DHo4yL5Di"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4GScPXVL5Di"
      },
      "source": [
        "Step 3: _Build a custom MLP module to tackle this classification task. You can optionally use the custom `Dense` module from the previous exercise._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbOXpbVTL5Di"
      },
      "source": [
        "There are several ways to do this. Let's look at a few alternatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKIv5P6QL5Di"
      },
      "source": [
        "Since we're building an MLP, which is just a stack of layers, we can just use a `nn.Sequential` module:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d959253"
      },
      "source": [
        "This code cell defines and initializes a Multi-Layer Perceptron (MLP) model for the CoverType classification task using PyTorch's `nn.Sequential` container.\n",
        "\n",
        "*   **`n_inputs = len(covtype.feature_names) # == 54`**:\n",
        "    *   Determines the number of input features for the model. It gets the length of `covtype.feature_names`, which was loaded from the `fetch_covtype()` dataset and is 54.\n",
        "\n",
        "*   **`n_classes = len(set(covtype.target)) # == 7`**:\n",
        "    *   Determines the number of output classes for the classification task. It calculates the number of unique target labels in `covtype.target`, which is 7 for the CoverType dataset.\n",
        "\n",
        "*   **`torch.manual_seed(42)`**:\n",
        "    *   Sets the random seed for PyTorch operations, ensuring that the initialization of the model's weights and biases is reproducible.\n",
        "\n",
        "*   **`covtype_model = nn.Sequential(...)`**:\n",
        "    *   This line constructs the neural network using `nn.Sequential`, which is a convenient way to build models by stacking layers in a linear fashion. The model consists of several `nn.Linear` layers interspersed with `nn.ReLU` activation functions:\n",
        "        *   **`nn.Linear(n_inputs, 200)`**: The input layer. It takes `n_inputs` (54) features and projects them to 200 neurons.\n",
        "        *   **`nn.ReLU()`**: The Rectified Linear Unit activation function, introducing non-linearity.\n",
        "        *   **`nn.Linear(200, 100)`**: The first hidden layer, taking 200 inputs and producing 100 outputs.\n",
        "        *   **`nn.ReLU()`**: Another ReLU activation.\n",
        "        *   **`nn.Linear(100, 50)`**: The second hidden layer, taking 100 inputs and producing 50 outputs.\n",
        "        *   **`nn.ReLU()`**: A third ReLU activation.\n",
        "        *   **`nn.Linear(50, n_classes)`**: The output layer. It takes 50 inputs and produces `n_classes` (7) outputs. For classification tasks using `nn.CrossEntropyLoss` (which will likely be used later), the output layer typically does *not* have an activation function like `softmax`, as `CrossEntropyLoss` expects raw logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "A2W9-4VRL5Di"
      },
      "outputs": [],
      "source": [
        "n_inputs = len(covtype.feature_names)  # == 54\n",
        "n_classes = len(set(covtype.target))  # == 7\n",
        "\n",
        "torch.manual_seed(42)\n",
        "covtype_model = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 200), nn.ReLU(),\n",
        "    nn.Linear(200, 100), nn.ReLU(),\n",
        "    nn.Linear(100, 50), nn.ReLU(),\n",
        "    nn.Linear(50, n_classes)\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfST2F28L5Di"
      },
      "source": [
        "Note that the output layer must not use any activation function since we will use the `nn.CrossEntropyLoss`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yzOFzhfL5Di"
      },
      "source": [
        "Alternatively, we can use the `Dense3` class we defined earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "i7xn4u4fL5Di"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "covtype_model = nn.Sequential(\n",
        "    Dense3(n_inputs, 200),\n",
        "    Dense3(200, 100),\n",
        "    Dense3(100, 50),\n",
        "    nn.Linear(50, n_classes)\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8nZc1BrL5Di"
      },
      "source": [
        "Or we can create a custom module. Let's make it flexible so it accepts a list containing the number of neurons in each hidden layer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c07f271"
      },
      "source": [
        "This code cell defines a custom PyTorch module named `CoverTypeModel` and then initializes an instance of it. This model is designed to be flexible, allowing you to easily specify the architecture of its hidden layers.\n",
        "\n",
        "### `CoverTypeModel` Class Definition:\n",
        "\n",
        "*   **`class CoverTypeModel(nn.Module):`**:\n",
        "    *   Declares a new class `CoverTypeModel` that inherits from `nn.Module`, the base class for all neural network modules in PyTorch.\n",
        "\n",
        "*   **`def __init__(self, n_neurons, n_inputs=n_inputs, n_classes=n_classes):`**:\n",
        "    *   This is the constructor. It takes `n_neurons` (a list specifying the number of neurons in each hidden layer), along with `n_inputs` and `n_classes` (which default to the globally defined values for the CoverType dataset).\n",
        "    *   **`super().__init__()`**: Calls the constructor of the parent `nn.Module` class to ensure proper initialization.\n",
        "    *   **`layers = [...]`**: This is a list comprehension that dynamically constructs the layers of the MLP:\n",
        "        *   **`zip([n_inputs] + n_neurons, n_neurons)`**: This part creates pairs of (input_features, output_features) for each hidden layer.\n",
        "            *   `[n_inputs] + n_neurons`: Creates a list like `[input_features, hidden1_neurons, hidden2_neurons, ...]`.\n",
        "            *   `n_neurons`: The list of hidden layer neuron counts, used as the output features for `Dense3`.\n",
        "            *   The `zip` function then pairs them up: `(n_inputs, n_neurons[0])`, `(n_neurons[0], n_neurons[1])`, etc.\n",
        "        *   **`Dense3(n_in, n_out)`**: For each pair, it creates an instance of the `Dense3` module (which, from previous cells, is a custom module combining a linear layer with Kaiming initialization and a ReLU activation).\n",
        "        *   **`+ [nn.Linear(n_neurons[-1], n_classes)]`**: Finally, it appends the output layer. This `nn.Linear` layer takes the output from the last hidden layer (`n_neurons[-1]`) and maps it to `n_classes` outputs (logits for classification).\n",
        "    *   **`self.mlp = nn.Sequential(*layers)`**: All the constructed layers are then passed to `nn.Sequential` using the `*` operator to unpack the list of layers. This creates a sequential container for the entire MLP.\n",
        "\n",
        "*   **`def forward(self, X):`**:\n",
        "    *   This method defines the forward pass. It simply passes the input `X` through the `self.mlp` sequential module.\n",
        "\n",
        "### Model Initialization:\n",
        "\n",
        "*   **`torch.manual_seed(42)`**:\n",
        "    *   Sets the random seed for reproducibility.\n",
        "\n",
        "*   **`covtype_model = CoverTypeModel([200, 100, 50]).to(device)`**:\n",
        "    *   Creates an instance of `CoverTypeModel`.\n",
        "        *   `[200, 100, 50]`: This list specifies that the model will have three hidden layers with 200, 100, and 50 neurons, respectively.\n",
        "    *   **`.to(device)`**: Moves the entire model to the specified computing `device` (e.g., GPU) for accelerated computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "r-g3MZKlL5Di"
      },
      "outputs": [],
      "source": [
        "class CoverTypeModel(nn.Module):\n",
        "    def __init__(self, n_neurons, n_inputs=n_inputs, n_classes=n_classes):\n",
        "        super().__init__()\n",
        "        layers = [\n",
        "            Dense3(n_in, n_out)\n",
        "            for n_in, n_out in zip([n_inputs] + n_neurons, n_neurons)\n",
        "        ] + [nn.Linear(n_neurons[-1], n_classes)]\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.mlp(X)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "covtype_model = CoverTypeModel([200, 100, 50]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrekV0wgL5Di"
      },
      "source": [
        "Lastly, we could use a `nn.ModuleList` instead of a `nn.Sequential` module, and modify the `forward()` method to explicitly run each layer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58975ee9"
      },
      "source": [
        "This code cell defines another version of the `CoverTypeModel` class. While functionally similar to the previous `nn.Sequential` version, this one demonstrates a more explicit way to manage layers using `nn.ModuleList`.\n",
        "\n",
        "### `CoverTypeModel` Class Definition (with `nn.ModuleList`):\n",
        "\n",
        "*   **`class CoverTypeModel(nn.Module):`**:\n",
        "    *   As before, this declares a custom PyTorch module inheriting from `nn.Module`.\n",
        "\n",
        "*   **`def __init__(self, n_neurons, n_inputs=n_inputs, n_classes=n_classes):`**:\n",
        "    *   The constructor dynamically builds the layers, just like the `nn.Sequential` version, using the `Dense3` custom module for hidden layers and an `nn.Linear` for the output layer.\n",
        "    *   **`self.layers = nn.ModuleList(layers)`**:\n",
        "        *   Instead of `nn.Sequential`, the list of layers is wrapped in `nn.ModuleList`. `nn.ModuleList` is primarily a container for `nn.Module` objects, allowing them to be properly registered as submodules (so their parameters are found by `model.parameters()`) and moved to the correct device (e.g., GPU).\n",
        "        *   Unlike `nn.Sequential`, `nn.ModuleList` does *not* define a `forward` method that automatically passes input through all its contained modules. You have to implement the forward pass manually.\n",
        "\n",
        "*   **`def forward(self, X):`**:\n",
        "    *   This method defines the explicit forward pass:\n",
        "        *   **`for layer in self.layers:`**:\n",
        "            *   It iterates through each `layer` stored in `self.layers`.\n",
        "        *   **`X = layer(X)`**:\n",
        "            *   In each iteration, the current input `X` is passed through the `layer`, and the output becomes the new `X` for the next layer. This manual chaining of operations achieves the same computational graph as `nn.Sequential` but offers more flexibility (e.g., if you wanted to add conditional logic or skip connections between layers).\n",
        "        *   **`return X`**: The final output after passing through all layers is returned.\n",
        "\n",
        "### `nn.ModuleList` vs. `nn.Sequential`:\n",
        "*   **`nn.Sequential`**: Best for simple, feed-forward networks where data flows linearly from one layer to the next without any branching or complex logic. It's concise and automatically defines the `forward` pass.\n",
        "*   **`nn.ModuleList`**: Provides a container for modules when you need more control over the forward pass, such as for implementing recurrent networks, networks with skip connections, or dynamic architectures where layers are chosen or added conditionally. You explicitly define how the data flows through each module in the `forward` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "-o2A9X9LL5Di"
      },
      "outputs": [],
      "source": [
        "class CoverTypeModel(nn.Module):\n",
        "    def __init__(self, n_neurons, n_inputs=n_inputs, n_classes=n_classes):\n",
        "        super().__init__()\n",
        "        layers = [\n",
        "            Dense3(n_in, n_out)\n",
        "            for n_in, n_out in zip([n_inputs] + n_neurons, n_neurons)\n",
        "        ] + [nn.Linear(n_neurons[-1], n_classes)]\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer(X)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJZcnb8oL5Di"
      },
      "source": [
        "Step 4: _Train this model on the GPU, and try to reach 93% accuracy on the test set. For this, you will likely have to perform hyperparameter search to find the right number of layers and neurons per layer, a good learning rate and batch size, and so on. You can optionally use Optuna for this._\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLC7JkbIL5Di"
      },
      "source": [
        "Let's train the model on the GPU. As we saw in Chapter 4, it's often helpful to reduce the learning rate at the end of training, so let's do that. We will train for 6 times 15 epochs, reducing the learning rate each time. The results might vary depending on the platform, but you should get over 94% accuracy on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0af153df"
      },
      "source": [
        "This code cell initiates the training of the `covtype_model` on the GPU, using a phased approach with a decaying learning rate. The goal is to achieve high classification accuracy on the test set.\n",
        "\n",
        "*   **`covtype_model = CoverTypeModel([200, 100, 50]).to(device)`**:\n",
        "    *   Initializes a new instance of the `CoverTypeModel` (with hidden layers of 200, 100, and 50 neurons) and moves it to the specified `device` (e.g., GPU).\n",
        "\n",
        "*   **`for learning_rate in [0.16, 0.08, 0.04, 0.02, 0.01, 0.005]:`**:\n",
        "    *   This is the core of the phased training strategy. The entire training process is broken down into multiple stages, and in each stage, a *different, smaller learning rate* is used.\n",
        "    *   **Why decaying learning rate?** A larger learning rate at the beginning (e.g., 0.16) helps the model quickly explore the loss landscape and converge towards a general area of good performance. As training progresses, smaller learning rates (e.g., 0.005) allow the model to fine-tune its weights more precisely and settle into a deeper, more accurate minimum without overshooting.\n",
        "\n",
        "*   **`n_epochs = 15`**:\n",
        "    *   Within each phase (for each learning rate), the model is trained for 15 epochs.\n",
        "\n",
        "*   **`optimizer = torch.optim.SGD(covtype_model.parameters(), lr=learning_rate)`**:\n",
        "    *   A new `SGD` optimizer is created at the beginning of each phase, using the `covtype_model`'s parameters and the current `learning_rate` for that phase.\n",
        "\n",
        "*   **`criterion = nn.CrossEntropyLoss()`**:\n",
        "    *   The `CrossEntropyLoss` is initialized as the loss function, suitable for multi-class classification.\n",
        "\n",
        "*   **`metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=n_classes).to(device)`**:\n",
        "    *   An `Accuracy` metric from `torchmetrics` is set up for evaluating the model's performance on the 7 classes of the CoverType dataset.\n",
        "\n",
        "*   **`history = train2(covtype_model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs)`**:\n",
        "    *   The `train2` function (defined earlier) is called to train the `covtype_model` for `n_epochs` (15 epochs) using the current phase's `optimizer`, `criterion`, and `metric`. The `history` contains the recorded training and validation metrics for these 15 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "72besH9GL5Di",
        "outputId": "8813ba87-7468-4694-8a44-8e18c6b46e64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, train loss: 0.5829, train metric: 0.7499, valid metric: 0.7913\n",
            "Epoch 2/15, train loss: 0.4607, train metric: 0.8041, valid metric: 0.8177\n",
            "Epoch 3/15, train loss: 0.4075, train metric: 0.8276, valid metric: 0.8295\n",
            "Epoch 4/15, train loss: 0.3709, train metric: 0.8445, valid metric: 0.8393\n",
            "Epoch 5/15, train loss: 0.3450, train metric: 0.8561, valid metric: 0.8611\n",
            "Epoch 6/15, train loss: 0.3239, train metric: 0.8660, valid metric: 0.8691\n",
            "Epoch 7/15, train loss: 0.3081, train metric: 0.8734, valid metric: 0.8697\n",
            "Epoch 8/15, train loss: 0.2945, train metric: 0.8797, valid metric: 0.8834\n",
            "Epoch 9/15, train loss: 0.2826, train metric: 0.8848, valid metric: 0.8784\n",
            "Epoch 10/15, train loss: 0.2733, train metric: 0.8888, valid metric: 0.8857\n",
            "Epoch 11/15, train loss: 0.2638, train metric: 0.8933, valid metric: 0.8916\n",
            "Epoch 12/15, train loss: 0.2563, train metric: 0.8958, valid metric: 0.8875\n",
            "Epoch 13/15, train loss: 0.2496, train metric: 0.8988, valid metric: 0.8980\n",
            "Epoch 14/15, train loss: 0.2436, train metric: 0.9011, valid metric: 0.8936\n",
            "Epoch 15/15, train loss: 0.2387, train metric: 0.9035, valid metric: 0.8956\n",
            "Epoch 1/15, train loss: 0.1999, train metric: 0.9199, valid metric: 0.9140\n",
            "Epoch 2/15, train loss: 0.1952, train metric: 0.9218, valid metric: 0.9167\n",
            "Epoch 3/15, train loss: 0.1921, train metric: 0.9234, valid metric: 0.9149\n",
            "Epoch 4/15, train loss: 0.1893, train metric: 0.9242, valid metric: 0.9189\n",
            "Epoch 5/15, train loss: 0.1877, train metric: 0.9248, valid metric: 0.9212\n",
            "Epoch 6/15, train loss: 0.1856, train metric: 0.9256, valid metric: 0.9200\n",
            "Epoch 7/15, train loss: 0.1833, train metric: 0.9265, valid metric: 0.9165\n",
            "Epoch 8/15, train loss: 0.1817, train metric: 0.9270, valid metric: 0.9203\n",
            "Epoch 9/15, train loss: 0.1803, train metric: 0.9276, valid metric: 0.9238\n",
            "Epoch 10/15, train loss: 0.1784, train metric: 0.9283, valid metric: 0.9233\n",
            "Epoch 11/15, train loss: 0.1765, train metric: 0.9293, valid metric: 0.9190\n",
            "Epoch 12/15, train loss: 0.1749, train metric: 0.9292, valid metric: 0.9177\n",
            "Epoch 13/15, train loss: 0.1740, train metric: 0.9305, valid metric: 0.9183\n",
            "Epoch 14/15, train loss: 0.1724, train metric: 0.9309, valid metric: 0.9250\n",
            "Epoch 15/15, train loss: 0.1714, train metric: 0.9311, valid metric: 0.9243\n",
            "Epoch 1/15, train loss: 0.1473, train metric: 0.9418, valid metric: 0.9351\n",
            "Epoch 2/15, train loss: 0.1449, train metric: 0.9423, valid metric: 0.9328\n",
            "Epoch 3/15, train loss: 0.1436, train metric: 0.9432, valid metric: 0.9340\n",
            "Epoch 4/15, train loss: 0.1424, train metric: 0.9438, valid metric: 0.9364\n",
            "Epoch 5/15, train loss: 0.1417, train metric: 0.9437, valid metric: 0.9354\n",
            "Epoch 6/15, train loss: 0.1409, train metric: 0.9444, valid metric: 0.9363\n",
            "Epoch 7/15, train loss: 0.1402, train metric: 0.9445, valid metric: 0.9356\n",
            "Epoch 8/15, train loss: 0.1398, train metric: 0.9445, valid metric: 0.9363\n",
            "Epoch 9/15, train loss: 0.1411, train metric: 0.9437, valid metric: 0.9379\n",
            "Epoch 10/15, train loss: 0.1388, train metric: 0.9448, valid metric: 0.9353\n",
            "Epoch 11/15, train loss: 0.1379, train metric: 0.9451, valid metric: 0.9344\n",
            "Epoch 12/15, train loss: 0.1374, train metric: 0.9454, valid metric: 0.9377\n",
            "Epoch 13/15, train loss: 0.1367, train metric: 0.9457, valid metric: 0.9393\n",
            "Epoch 14/15, train loss: 0.1358, train metric: 0.9458, valid metric: 0.9384\n",
            "Epoch 15/15, train loss: 0.1352, train metric: 0.9462, valid metric: 0.9394\n",
            "Epoch 1/15, train loss: 0.1219, train metric: 0.9525, valid metric: 0.9436\n",
            "Epoch 2/15, train loss: 0.1205, train metric: 0.9530, valid metric: 0.9446\n",
            "Epoch 3/15, train loss: 0.1199, train metric: 0.9532, valid metric: 0.9430\n",
            "Epoch 4/15, train loss: 0.1195, train metric: 0.9532, valid metric: 0.9441\n",
            "Epoch 5/15, train loss: 0.1189, train metric: 0.9535, valid metric: 0.9421\n",
            "Epoch 6/15, train loss: 0.1184, train metric: 0.9538, valid metric: 0.9436\n",
            "Epoch 7/15, train loss: 0.1180, train metric: 0.9535, valid metric: 0.9440\n",
            "Epoch 8/15, train loss: 0.1177, train metric: 0.9541, valid metric: 0.9440\n",
            "Epoch 9/15, train loss: 0.1172, train metric: 0.9541, valid metric: 0.9431\n",
            "Epoch 10/15, train loss: 0.1167, train metric: 0.9544, valid metric: 0.9424\n",
            "Epoch 11/15, train loss: 0.1165, train metric: 0.9547, valid metric: 0.9453\n",
            "Epoch 12/15, train loss: 0.1160, train metric: 0.9545, valid metric: 0.9444\n",
            "Epoch 13/15, train loss: 0.1156, train metric: 0.9547, valid metric: 0.9434\n",
            "Epoch 14/15, train loss: 0.1151, train metric: 0.9549, valid metric: 0.9443\n",
            "Epoch 15/15, train loss: 0.1149, train metric: 0.9550, valid metric: 0.9461\n",
            "Epoch 1/15, train loss: 0.1081, train metric: 0.9585, valid metric: 0.9472\n",
            "Epoch 2/15, train loss: 0.1073, train metric: 0.9587, valid metric: 0.9477\n",
            "Epoch 3/15, train loss: 0.1069, train metric: 0.9590, valid metric: 0.9475\n",
            "Epoch 4/15, train loss: 0.1067, train metric: 0.9590, valid metric: 0.9476\n",
            "Epoch 5/15, train loss: 0.1065, train metric: 0.9593, valid metric: 0.9479\n",
            "Epoch 6/15, train loss: 0.1061, train metric: 0.9595, valid metric: 0.9476\n",
            "Epoch 7/15, train loss: 0.1060, train metric: 0.9594, valid metric: 0.9476\n",
            "Epoch 8/15, train loss: 0.1057, train metric: 0.9595, valid metric: 0.9483\n",
            "Epoch 9/15, train loss: 0.1056, train metric: 0.9595, valid metric: 0.9483\n",
            "Epoch 10/15, train loss: 0.1052, train metric: 0.9596, valid metric: 0.9481\n",
            "Epoch 11/15, train loss: 0.1052, train metric: 0.9595, valid metric: 0.9484\n",
            "Epoch 12/15, train loss: 0.1048, train metric: 0.9599, valid metric: 0.9480\n",
            "Epoch 13/15, train loss: 0.1047, train metric: 0.9597, valid metric: 0.9470\n",
            "Epoch 14/15, train loss: 0.1043, train metric: 0.9600, valid metric: 0.9493\n",
            "Epoch 15/15, train loss: 0.1043, train metric: 0.9600, valid metric: 0.9479\n",
            "Epoch 1/15, train loss: 0.1008, train metric: 0.9619, valid metric: 0.9495\n",
            "Epoch 2/15, train loss: 0.1004, train metric: 0.9619, valid metric: 0.9491\n",
            "Epoch 3/15, train loss: 0.1002, train metric: 0.9622, valid metric: 0.9502\n",
            "Epoch 4/15, train loss: 0.1001, train metric: 0.9623, valid metric: 0.9494\n",
            "Epoch 5/15, train loss: 0.0999, train metric: 0.9622, valid metric: 0.9501\n",
            "Epoch 6/15, train loss: 0.0998, train metric: 0.9626, valid metric: 0.9497\n",
            "Epoch 7/15, train loss: 0.0996, train metric: 0.9625, valid metric: 0.9497\n",
            "Epoch 8/15, train loss: 0.0995, train metric: 0.9626, valid metric: 0.9499\n",
            "Epoch 9/15, train loss: 0.0994, train metric: 0.9625, valid metric: 0.9495\n",
            "Epoch 10/15, train loss: 0.0992, train metric: 0.9627, valid metric: 0.9497\n",
            "Epoch 11/15, train loss: 0.0993, train metric: 0.9626, valid metric: 0.9498\n",
            "Epoch 12/15, train loss: 0.0991, train metric: 0.9627, valid metric: 0.9499\n",
            "Epoch 13/15, train loss: 0.0991, train metric: 0.9625, valid metric: 0.9502\n",
            "Epoch 14/15, train loss: 0.0988, train metric: 0.9629, valid metric: 0.9502\n",
            "Epoch 15/15, train loss: 0.0987, train metric: 0.9629, valid metric: 0.9497\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "covtype_model = CoverTypeModel([200, 100, 50]).to(device)\n",
        "\n",
        "for learning_rate in [0.16, 0.08, 0.04, 0.02, 0.01, 0.005]:\n",
        "    n_epochs = 15\n",
        "    optimizer = torch.optim.SGD(covtype_model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    metric = torchmetrics.Accuracy(task=\"multiclass\",\n",
        "                                   num_classes=n_classes).to(device)\n",
        "    history = train2(covtype_model, optimizer, criterion, metric, train_loader,\n",
        "                     valid_loader, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "xI7elv-FL5Di",
        "outputId": "97385bf3-7f94-4d6b-ea80-e5434bf41cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9489, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "evaluate_tm(covtype_model, test_loader, metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb97tp8RL5Di"
      },
      "source": [
        "I manually tuned the hyperparameters above through trial and error. It took about 30 minutes of search to achieve over 94% accuracy, so I didn’t need to run a full hyperparameter search. However, you can definitely use Optuna for this task if you want to get even better results. The code below tunes the learning rate, the number of hidden layers, and the number of neurons per hidden layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b95dd5d"
      },
      "source": [
        "This code cell defines the `objective` function for Optuna hyperparameter tuning, specifically tailored for the `CoverTypeModel`.\n",
        "\n",
        "### `objective` Function Breakdown:\n",
        "\n",
        "*   **`def objective(trial):`**:\n",
        "    *   This is the function Optuna will call for each trial. The `trial` object suggests hyperparameters and reports intermediate results.\n",
        "\n",
        "*   **`learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 1.0, log=True)`**:\n",
        "    *   Optuna suggests a floating-point value for the learning rate within the range `[0.01, 1.0]`. `log=True` means the sampling occurs on a logarithmic scale, which is typical for learning rates.\n",
        "\n",
        "*   **`n_layers = trial.suggest_int(\"n_layers\", 1, 3)`**:\n",
        "    *   Optuna suggests an integer for the number of hidden layers, between 1 and 3 (inclusive).\n",
        "\n",
        "*   **`n_hidden = trial.suggest_int(\"n_hidden\", 30, 150)`**:\n",
        "    *   Optuna suggests an integer for the number of neurons in each hidden layer, between 30 and 150 (inclusive). Note that `CoverTypeModel`'s `__init__` takes `[n_hidden] * n_layers`, meaning all hidden layers will have the same number of neurons for a given trial.\n",
        "\n",
        "*   **`covtype_model = CoverTypeModel([n_hidden] * n_layers).to(device)`**:\n",
        "    *   A `CoverTypeModel` is instantiated using the suggested `n_hidden` and `n_layers`. It's then moved to the appropriate `device`.\n",
        "\n",
        "*   **`optimizer = torch.optim.SGD(covtype_model.parameters(), lr=learning_rate)`**:\n",
        "    *   An `SGD` optimizer is initialized for the `covtype_model` using the suggested `learning_rate`.\n",
        "\n",
        "*   **`xentropy = nn.CrossEntropyLoss()`** and **`accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=n_classes).to(device)`**:\n",
        "    *   The loss function (`CrossEntropyLoss`) and evaluation metric (`Accuracy`) are set up, consistent with multiclass classification for the CoverType dataset.\n",
        "\n",
        "*   **`best_validation_accuracy = 0.0`**:\n",
        "    *   A variable to keep track of the best validation accuracy achieved during the current trial's training.\n",
        "\n",
        "*   **`for epoch in range(n_epochs):`**:\n",
        "    *   This loop orchestrates the training for each trial across multiple epochs. The `n_epochs` here refers to the global variable (likely `15`), determining the maximum number of epochs a trial will run if not pruned.\n",
        "\n",
        "*   **`history = train2(covtype_model, optimizer, xentropy, accuracy, train_loader, valid_loader, n_epochs=1)`**:\n",
        "    *   The `train2` helper function is called to perform **one epoch** of training. This is crucial for enabling pruning.\n",
        "\n",
        "*   **`validation_accuracy = max(history[\"valid_metrics\"])`**:\n",
        "    *   The validation accuracy from this single epoch is retrieved.\n",
        "\n",
        "*   **`if validation_accuracy > best_validation_accuracy: best_validation_accuracy = validation_accuracy`**:\n",
        "    *   Updates the `best_validation_accuracy` if the current epoch's performance is better.\n",
        "\n",
        "*   **`trial.report(validation_accuracy, step=epoch)`**:\n",
        "    *   This line reports the current validation accuracy and the current epoch number to Optuna. This is essential for the pruner to monitor the trial's performance over time.\n",
        "\n",
        "*   **`if trial.should_prune(): raise optuna.TrialPruned()`**:\n",
        "    *   After reporting, the pruner checks if this trial is performing poorly compared to others. If it is, `trial.should_prune()` returns `True`, and a `TrialPruned` exception is raised, stopping the current trial early to save computational resources.\n",
        "\n",
        "*   **`return best_validation_accuracy`**:\n",
        "    *   If the trial completes all epochs without being pruned, it returns the best validation accuracy achieved during its run. Optuna uses this value to determine the overall best hyperparameter set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "z__M_PlML5Di"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 1.0, log=True)\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    n_hidden = trial.suggest_int(\"n_hidden\", 30, 150)\n",
        "    covtype_model = CoverTypeModel([n_hidden] * n_layers).to(device)\n",
        "    optimizer = torch.optim.SGD(covtype_model.parameters(), lr=learning_rate)\n",
        "    xentropy = nn.CrossEntropyLoss()\n",
        "    accuracy = torchmetrics.Accuracy(task=\"multiclass\",\n",
        "                                     num_classes=n_classes).to(device)\n",
        "    best_validation_accuracy = 0.0\n",
        "    for epoch in range(n_epochs):\n",
        "        history = train2(covtype_model, optimizer, xentropy, accuracy,\n",
        "                         train_loader, valid_loader, n_epochs=1)\n",
        "        validation_accuracy = max(history[\"valid_metrics\"])\n",
        "        if validation_accuracy > best_validation_accuracy:\n",
        "            best_validation_accuracy = validation_accuracy\n",
        "        trial.report(validation_accuracy, step=epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "    return best_validation_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzYJve4vL5Di"
      },
      "source": [
        "**Note**: I’ve set `n_trials=2` so you can run a quick test, but if you want to actually tune the hyperparameters, you should increase this to at least 50—and ideally to several hundred, but it will take several hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03fddceb"
      },
      "source": [
        "This code cell sets up and initiates the hyperparameter optimization study using Optuna, incorporating a pruning strategy to accelerate the search.\n",
        "\n",
        "*   **`torch.manual_seed(42)`**:\n",
        "    *   Sets the random seed for PyTorch, ensuring reproducibility of model training within each trial.\n",
        "\n",
        "*   **`sampler = optuna.samplers.TPESampler(seed=42)`**:\n",
        "    *   Initializes a `TPESampler` (Tree-structured Parzen Estimator). This sampling algorithm intelligently proposes new hyperparameter combinations based on the performance of previously evaluated trials. The `seed=42` ensures reproducible sampling.\n",
        "\n",
        "*   **`pruner = optuna.pruners.MedianPruner()`**:\n",
        "    *   A `MedianPruner` is initialized. Pruners are strategies that Optuna uses to **stop unpromising trials early** during the optimization process.\n",
        "\n",
        "*   **`study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)`**:\n",
        "    *   Creates an Optuna `Study` object, integrating the `pruner` for early stopping.\n",
        "        *   **`direction=\"maximize\"`**: Specifies that Optuna should try to maximize the objective function's return value (validation accuracy).\n",
        "        *   **`sampler=sampler`**: Assigns the `TPESampler` to guide hyperparameter suggestions.\n",
        "        *   **`pruner=pruner`**: Integrates the `MedianPruner` into the study.\n",
        "\n",
        "*   **`study.optimize(objective, n_trials=2)`**:\n",
        "    *   Starts the hyperparameter optimization process.\n",
        "        *   **`objective`**: The `objective` function is called repeatedly.\n",
        "        *   **`n_trials=2`**: Optuna will attempt to run only 2 trials. As noted in the original notebook, this small number is primarily for a quick test or demonstration. For actual hyperparameter tuning, this value would typically be much higher (e.g., 50 or several hundred) to allow Optuna to thoroughly explore the hyperparameter space and converge on optimal values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "R9xFlEyEL5Di",
        "outputId": "d50aaeed-7fe4-4712-cdcd-e5614876fa80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 19:01:45,925] A new study created in memory with name: no-name-d20abe46-523b-4427-9a47-cea24a066437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.6380, train metric: 0.7309, valid metric: 0.7675\n",
            "Epoch 1/1, train loss: 0.5247, train metric: 0.7761, valid metric: 0.7925\n",
            "Epoch 1/1, train loss: 0.4781, train metric: 0.7977, valid metric: 0.8016\n",
            "Epoch 1/1, train loss: 0.4443, train metric: 0.8131, valid metric: 0.8176\n",
            "Epoch 1/1, train loss: 0.4184, train metric: 0.8249, valid metric: 0.8187\n",
            "Epoch 1/1, train loss: 0.3973, train metric: 0.8344, valid metric: 0.8435\n",
            "Epoch 1/1, train loss: 0.3794, train metric: 0.8424, valid metric: 0.8473\n",
            "Epoch 1/1, train loss: 0.3626, train metric: 0.8499, valid metric: 0.8365\n",
            "Epoch 1/1, train loss: 0.3483, train metric: 0.8570, valid metric: 0.8578\n",
            "Epoch 1/1, train loss: 0.3374, train metric: 0.8615, valid metric: 0.8682\n",
            "Epoch 1/1, train loss: 0.3256, train metric: 0.8664, valid metric: 0.8697\n",
            "Epoch 1/1, train loss: 0.3164, train metric: 0.8707, valid metric: 0.8718\n",
            "Epoch 1/1, train loss: 0.3067, train metric: 0.8753, valid metric: 0.8705\n",
            "Epoch 1/1, train loss: 0.3009, train metric: 0.8774, valid metric: 0.8421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 19:03:38,690] Trial 0 finished with value: 0.8718094229698181 and parameters: {'learning_rate': 0.05611516415334506, 'n_layers': 3, 'n_hidden': 118}. Best is trial 0 with value: 0.8718094229698181.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.2921, train metric: 0.8812, valid metric: 0.8715\n",
            "Epoch 1/1, train loss: 0.6367, train metric: 0.7331, valid metric: 0.7502\n",
            "Epoch 1/1, train loss: 0.5669, train metric: 0.7583, valid metric: 0.7629\n",
            "Epoch 1/1, train loss: 0.5448, train metric: 0.7674, valid metric: 0.7767\n",
            "Epoch 1/1, train loss: 0.5295, train metric: 0.7747, valid metric: 0.7790\n",
            "Epoch 1/1, train loss: 0.5189, train metric: 0.7787, valid metric: 0.7722\n",
            "Epoch 1/1, train loss: 0.5111, train metric: 0.7828, valid metric: 0.7893\n",
            "Epoch 1/1, train loss: 0.5050, train metric: 0.7857, valid metric: 0.7893\n",
            "Epoch 1/1, train loss: 0.4998, train metric: 0.7877, valid metric: 0.7916\n",
            "Epoch 1/1, train loss: 0.4956, train metric: 0.7889, valid metric: 0.7943\n",
            "Epoch 1/1, train loss: 0.4918, train metric: 0.7910, valid metric: 0.7893\n",
            "Epoch 1/1, train loss: 0.4887, train metric: 0.7927, valid metric: 0.8006\n",
            "Epoch 1/1, train loss: 0.4849, train metric: 0.7940, valid metric: 0.7938\n",
            "Epoch 1/1, train loss: 0.4839, train metric: 0.7953, valid metric: 0.7902\n",
            "Epoch 1/1, train loss: 0.4794, train metric: 0.7967, valid metric: 0.7862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-26 19:05:18,933] Trial 1 finished with value: 0.8006230592727661 and parameters: {'learning_rate': 0.15751320499779725, 'n_layers': 1, 'n_hidden': 48}. Best is trial 0 with value: 0.8718094229698181.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, train loss: 0.4759, train metric: 0.7982, valid metric: 0.7913\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "pruner = optuna.pruners.MedianPruner()\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=sampler,\n",
        "                            pruner=pruner)\n",
        "study.optimize(objective, n_trials=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "41d0pkwbL5Di",
        "outputId": "48d0061b-ee04-47e1-91fa-0304186ad2cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8718094229698181"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "1X_15ou3L5Di",
        "outputId": "ee430af0-7c41-4373-d109-dd37d7d065fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.05611516415334506, 'n_layers': 3, 'n_hidden': 118}"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azgmf0Y7L5Di"
      },
      "source": [
        "Hope you enjoyed this chapter!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}